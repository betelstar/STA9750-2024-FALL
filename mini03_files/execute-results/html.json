{
  "hash": "1c74bd74b18d39685115d3b9639b28b8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"{{< var course.short >}} Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?\"\nformat:\n  html:\n    code-link: true\necho: true\n---\n\n\n\n## Introduction\n\nWelcome to Mini-Project #03! In this project, you will write a *political fact-check*, that most iconic form of our current journalistic era. Specifically, you will investigate the claim that the [US Electoral College](https://en.wikipedia.org/wiki/United_States_Electoral_College) systematically biases election results away from the *vox populi*. As you dive in to the world of political data, we'll also learn a bit more about the mechanics of US federal elections.\n\nIn this Mini-Project, you will:\n\n-   Integrate data from disparate governmental and academic sources\n-   Learn to work with spatial data formats\n-   Create *many* plots\n-   Use spatial and animated visualizations to make your argument\n\nNote that - as with all these mini-projects - there isn't a single \"*right*\" answer to the questions posed herein. You may have different views about the relative importance of federalism, direct democratic structures, adherence to the formal structures of the US Constitution, *etc.* than your classmates. Please make sure to make your argument respectfully and, when we reach the peer-evaluation stage, read and comment respectfully. All grading will be done solely on the quality of the code, the writing, the visualizations, and the argument - not on the political implications of what you may or may not find.\n\nAlso note that this mini-project is intended to be markedly less demanding than [Mini-Project #02](./mini02.html). At this point in the course, you should be diving into your [Course Project](../project.html), which should consume the majority of your out-of-class time dedicated to this course for the remainder of the semester.\n\n## Background\n\nThe [US Constitution](https://constitution.congress.gov/constitution/) sets the basic rules of electing the President in [Section 1 of Article II](https://constitution.congress.gov/constitution/article-2/#article-2-section-1-clause-2), which we quote here in part:\n\n> Each State shall appoint, in such Manner as the Legislature thereof may direct, a Number of Electors, equal to the whole Number of Senators and Representatives to which the State may be entitled in the Congress: but no Senator or Representative, or Person holding an Office of Trust or Profit under the United States, shall be appointed an Elector.\n>\n> The Electors shall meet in their respective States, and vote by Ballot for two Persons, of whom one at least shall not be an Inhabitant of the same State with themselves. And they shall make a List of all the Persons voted for, and of the Number of Votes for each; which List they shall sign and certify, and transmit sealed to the Seat of the Government of the United States, directed to the President of the Senate. The President of the Senate shall, in the Presence of the Senate and House of Representatives, open all the Certificates, and the Votes shall then be counted. The Person having the greatest Number of Votes shall be the President, if such Number be a Majority of the whole Number of Electors appointed; and if there be more than one who have such Majority, and have an equal Number of Votes, then the House of Representatives shall immediately chuse by Ballot one of them for President; and if no Person have a Majority, then from the five highest on the List the said House shall in like Manner chuse the President. But in chusing the President, the Votes shall be taken by States, the Representation from each State having one Vote; A quorum for this Purpose shall consist of a Member or Members from two thirds of the States, and a Majority of all the States shall be necessary to a Choice. In every Case, after the Choice of the President, the Person having the greatest Number of Votes of the Electors shall be the Vice President. But if there should remain two or more who have equal Votes, the Senate shall chuse from them by Ballot the Vice President.\n\nThough the details have varied over time due to amendment, statue, and technology, this basic outline of this allocation scheme remains unchanged:\n\n-   Each state gets $R + 2$ electoral college votes, where $R$ is the number of Representatives that state has in the US House of Representatives\n-   States can allocate those votes however they wish\n-   The president is the candidate who receives a majority of electoral college votes\n\nNotably, the Constitution sets essentially no rules on how the $R + 2$ electoral college votes (ECVs) for a particular state are allocated. At different points in history, different states have elected to use each of the following:\n\n-   Direct allocation of ECVs by state legislature (no vote)\n-   Allocation of all ECVs to winner of state-wide popular vote\n-   Allocation of all ECVs to winner of [nation-wide popular vote](https://en.wikipedia.org/wiki/National_Popular_Vote_Interstate_Compact)\n-   Allocation of $R$ ECVs to popular vote winner by congressional district + allocation of remaining $2$ ECVs to the state-wide popular vote winner\n\nCurrently, only Maine and Nebraska use the final option; the other 48 states and the District of Columbia award all $R+2$ ECVs to the winner of their state-wide popular vote. We emphasize here that \"statewide winner-take-all\" is a *choice* made by the individual states, not dictated by the US constitution, and that states have the power to change it should they wish.[^1]\n\n[^1]: I am not aware of \"official\" reasons from any state on why they select \"winner-take-all\" allocation. States clearly compete for attention in presidential elections and it seems reasonable to assume that competitive states select \"winner-take-all\" allocation to attract presidential candidates who will make promises to that state's voters. By contrast, states whose legislature is dominated by a single party, *e.g.*, New York, may be motivated to award all their votes to the more popular party in that state, denying any ECVs to the other candidate, even if a sizeable minority votes for them. If you find a history of how states select their ECV allocation strategies, I would be interested in reading it.\n\nTo my knowledge, no US state uses true *proportionate* state-wide representation, though I believe such a ECV-allocation scheme would be consistent with the US Constitution. For example, if a state with 5 ECVs had 60,000 votes for Candidate A and 40,000 cast for Candidate B, it could award 3 ECVs to A and 2 to B, regardless of the spatial distribution of those votes within the state.\n\n## Mini-Project Objectives\n\nIn this project, you will use historical congressional election data to see how the outcome of US presidential elections would have changed under different allocation rules. Like any *retrodiction*[^2] task, this analysis has limitations. Notably, if the \"rules\" had been different, politicians may have run different campaigns and received different vote counts. Still, it is my hope that this is an interesting and informative exercise.\n\n[^2]: Making predictions about a counter-factual past.\n\nAs noted above, your final submission should take the form of a \"Fact Check\":\n\n-   Take a statement from a well-known politician or political commentator describing (claimed) bias of the electoral college system\n-   Analyze presidential election results under different allocations for presence or abscence of bias (however you define it - see below)\n-   Summarize your *retrodictive* findings\n-   Award a \"truthfulness\" score to the claim you evaluated. (You may use the scale of an existing political fact-check operation or create your own.)\n\n## Student Responsbilities\n\nRecall our basic analytic workflow and table of student responsibilities:\n\n-   Data Ingest and Cleaning: Given a single data source, read it into `R` and transform it to a reasonably useful standardized format.\n-   Data Combination and Alignment: Combine multiple data sources to enable insights not possible from a single source.\n-   Descriptive Statistical Analysis: Take a data table and compute informative summary statistics from both the entire population and relevant subgroups\n-   Data Visualization: Generate insightful data visualizations to spur insights not attainable from point statistics\n-   Inferential Statistical Analysis and Modeling: Develop relevant predictive models and statistical analyses to generate insights about the *underlying population* and not simply the data at hand.\n\n+----------------------+---------------------+---------------------------+----------------------------------+---------------+\n|                      | Ingest and Cleaning | Combination and Alignment | Descriptive Statistical Analysis | Visualization |\n+:====================:+:===================:+:=========================:+:================================:+:=============:+\n| **Mini-Project #01** |                     |                           | **✓**                            |               |\n+----------------------+---------------------+---------------------------+----------------------------------+---------------+\n| **Mini-Project #02** |                     | **✓**                     | **✓**                            | **½**         |\n+----------------------+---------------------+---------------------------+----------------------------------+---------------+\n| **Mini-Project #03** | **½**               | **✓**                     | **✓**                            | **✓**         |\n+----------------------+---------------------+---------------------------+----------------------------------+---------------+\n| **Mini-Project #04** | **✓**               | **✓**                     | **✓**                            | **✓**         |\n+----------------------+---------------------+---------------------------+----------------------------------+---------------+\n\n: Students' Responsibilities in Mini-Project Analyses {.hover}\n\nIn this mini-project, you will be working with relatively \"clean\" electoral data and your main focus should be on the analysis and visualization supporting your fact check. As an analysis of political data, I expect your final submission to have quite a few \"red state/blue state\" maps.[^3] Data cleaning and import will play a larger role in Mini-Project #04.\n\n[^3]: Historically, the \"Republicans Red / Democrats Blue\" convention was not particularly strong in American journalism. It become standardized during coverage of the [2000 Presidential Election and subsequent Florida recount battles](https://en.wikipedia.org/wiki/2000_United_States_presidential_election_recount_in_Florida) and has not materially changed since. For purposes of this mini-project, we will apply \"Republican Red / Democrat Blue\" consistently.\n\nIn this project, I am no longer providing code to download and read the necessary data files. The data files I have selected for this mini-project are relatively easy to work with and should not provide a significant challenge, particularly after our in-class discussion of Data Import. See the modified rubric below which now includes a grade for data import.\n\n### Rubric\n\n{{< var course.short >}} Mini-Projects are evaluated using *peer grading* with *meta-review* by the course GTAs. Specifically, variants of the following rubric will be used for the mini-projects:\n\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n| Course Element        | Excellent (9-10)                                                                                                                                                                            | Great (7-8)                                                                                                                                                     | Good (5-6)                                                                                            | Adequate (3-4)                                                                                                                                             | Needs Improvement (1-2)                                                                             | Extra Credit                                                                                   |\n+=======================+=============================================================================================================================================================================================+=================================================================================================================================================================+=======================================================================================================+============================================================================================================================================================+=====================================================================================================+================================================================================================+\n| Written Communication | Report is well-written and flows naturally. Motivation for key steps is clearly explained to reader without excessive detail. Key findings are highlighted and appropriately given context. | Report has no grammatical or writing issues. Writing is accessible and flows naturally. Key findings are highlighted, but lack suitable motivation and context. | Report has no grammatical or writing issues. Key findings are present but insufficiently highlighted. | Writing is intelligible, but has some grammatical errors. Key findings are obscured.                                                                       | Report exhibits significant weakness in written communication. Key points are difficult to discern. | Report includes extra context beyond instructor provided information.                          |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n| Project Skeleton      | Code completes all instructor-provided tasks correctly. Responses to open-ended tasks are particularly insightful and creative.                                                             | Code completes all instructor-provided tasks satisfactorially.                                                                                                  | Response to one instructor provided task is skipped, incorrect, or otherwise incomplete.              | Responses to two instructor provided tasks are skipped, incorrect, or otherwise incomplete.                                                                | Response to three or ore instructor provided tasks are skipped, incorrect, or otherwise incomplete. | Report exhibits particularly creative insights drawn from thorough student-initiated analyses. |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n| Formatting & Display  | Tables and figures are full 'publication-quality'.                                                                                                                                          | Tables have well-formatted column names, suitable numbers of digits, and attractive presentation.                                                               | Tables are well-formatted, but still have room for improvement.                                       | Tables lack significant 'polish' and need improvement in substance (filtering and down-selecting of presented data) or style.                              | Unfiltered 'data dump' instead of curated table.                                                    | Report includes interactive (not just animated) visual elements.                               |\n|                       |                                                                                                                                                                                             |                                                                                                                                                                 |                                                                                                       |                                                                                                                                                            |                                                                                                     |                                                                                                |\n|                       | Report includes at least one animated visualization designed to effectively communicate findings.                                                                                           | Figures are 'publication-quality', with suitable axis labels, well-chosen structure, attractive color schemes, titles, subtitles, and captions, *etc.*          | Figures are above 'exploratory-quality', but do not reach full 'publication-quality'.                 | Figures are suitable to support claims made, but are 'exploratory-quality', reflecting minimal effort to customize and 'polish' beyond `ggplot2` defaults. | Baseline figures that do not fully support claims made.                                             |                                                                                                |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n| Code Quality          | Code is (near) flawless.                                                                                                                                                                    | Comments give context of the analysis, not simply defining functions used in a particular line.                                                                 | Code has well-chosen variable names and basic comments.                                               | Code executes properly, but is difficult to read.                                                                                                          | Code fails to execute properly.                                                                     | Code takes advantage of advanced `Quarto` features to improve presentation of results.         |\n|                       |                                                                                                                                                                                             |                                                                                                                                                                 |                                                                                                       |                                                                                                                                                            |                                                                                                     |                                                                                                |\n|                       | Code passes all `styler` and `lintr` type analyses without issue.                                                                                                                           |                                                                                                                                                                 |                                                                                                       |                                                                                                                                                            |                                                                                                     |                                                                                                |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n| Data Preparation      | Data import is fully-automated and efficient, taking care to only download from web-sources if not available locally.                                                                       | Data is imported and prepared effectively, in an automated fashion with minimal hard-coding of URLs and file paths.                                             | Data is imported and prepared effectively, though source and destination file names are hard-coded.   | Data is imported in a manner likely to have errors.                                                                                                        | Data is hard-coded and not imported from an external source.                                        | Report uses additional data sources in a way that creates novel insights.                      |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n\n: Mini-Project Grading Rubric\n\nNote that this rubric is designed with copious opportunities for extra credit if students go *above and beyond* the instructor-provided scaffolding. Students pursuing careers in data analytics are strongly encouraged to go beyond the strict ambit of the mini-projects to i) further refine their skills; ii) learn additional techniques that can be used in the final course project; and iii) develop a more impressive professional portfolio.\n\nBecause students are encouraged to use {{< var course.short >}} mini-projects as the basis for a professional portfolio, the basic skeleton of each project will be released under a fairly permissive usage license. Take advantage of it!\n\nOnce the submission deadline passes, the instructor will tag classmates for peer feedback in this issue thread.\n\n*Additionally*, a PDF export of this report should be submitted on Brightspace. To create a PDF from the uploaded report, simply use your browser's 'Print to PDF' functionality.\n\n**NB**: The analysis outline below specifies key *tasks* you need to perform within your write up. Your peer evaluators will check that you complete these. You are encouraged to do extra analysis, but the bolded **Tasks** are *mandatory*.\n\n**NB**: Your final submission should look like a *report*, not simply a list of facts answering questions. Add introductions, conclusions, and your own commentary. You should be practicing both raw *coding* skills and written *communication* in all mini-projects. There is little value in data points stated without context or motivation.\n\n## Set-Up and Initial Exploration\n\n### Data I: US House Election Votes from 1976 to 2022\n\nThe [MIT Election Data Science Lab](https://electionlab.mit.edu/) collects\nvotes from all biennial congressional races in all 50 states\n[here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2).\nDownload this data as a CSV file using your web browser. Note that you will need\nto provide your contact info and agree to cite this data set in your\nfinal report.[^4] Make sure to include this citation!\n\n[^4]: While it may be possible to automate the browser to automatically fill\nin this pop-up as part of the download process, that's beyond the scope of\nthis assignment.\n\nAdditionally, download statewide presidential vote counts from 1976 to 2022 [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX). As before, it will likely be easiest to download this data by hand using your web browser.\n\n### Data II: Congressional Boundary Files 1976 to 2012\n\nJeffrey B. Lewis, Brandon DeVine, Lincoln Pritcher, and Kenneth C. Martis\nhave created *shapefiles* for all US congressional districts from 1789 to 2012;\nthey generously make these available [here](https://cdmaps.polisci.ucla.edu/).\n\n::: {.callout-tip title=\"Task 1: Download Congressional Shapefiles 1976-2012\"}\nDownload congressional shapefiles from Lewis *et al.* for all US Congresses[^5]\nfrom 1976 to 2012.\n\nYour download code should:\n\n1)  Be fully automated (no \"hand-downloading\");\n2)  Download files with a systematic and interpretable naming convention\n3)  Only download files as needed out of courtesy for the data provider's web\n    sever. That is, if you already have a copy of the file, do not re-download\n    it repeatedly.\n\n**As with the other Mini-Projects, make sure you do not store these data\nfiles in `git`. It will be sufficient to include the `qmd` file with the\ndownload code.**\n:::\n\n[^5]: It may be useful to recall that each two year cycle is called \"a congress\" for district mapping purposes. The 2022 US Election, selecting Representatives to serve 2023-2025, corresponds to the 118th Congress. The upcoming (November 2024) election will select members for the 119th Congress.\n\nNote that the shape files are distributed as `zip` folders, containing several\nfiles in a directory structure. We will be interested in the `shp` files within\neach `zip`.\n\n### Data III: Congressional Boundary Files 2014 to Present\n\nTo get district boundaries for more recent congressional elections, we can turn\nto the US Census Bureau. Unfortunately, these data - while authoritative and\nhighly detailed - are not in quite the same format as our previous congressional\nboundary files. We can review the US Census Bureau shapefiles [online](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). \nTo download them automatically, I recommend exploring the `FTP Archive`\nlink near the bottom of the page. In Census-jargon, the `CD` directory will have\nshapefiles for **C**ongressional **D**istricts for each year.[^6]\n\n[^6]: The other shapefiles in this FTP archive may be useful for your\nfinal projects.\n\n::: {.callout-tip title=\"Task 2: Download Congressional Shapefiles 1976-2012\"}\nDownload congressional shapefiles from the US Census Bureau for all US\nCongresses from 2014 to 2024.\n\nYour download code should:\n\n1)  Be fully automated (no \"hand-downloading\");\n2)  Download files with a systematic and interpretable naming convention\n3)  Only download files as needed out of courtesy for the data provider's web sever. That is, if you already have a copy of the file, do not re-download it repeatedly.\n\n**As with the other Mini-Projects, make sure you do not store these data\nfiles in `git`. It will be sufficient to include the `qmd` file with the\ndownload code.**\n:::\n\n### Initial Exploration of Vote Count Data\n\n::: {.callout-tip title=\"Task 3: Exploration of Vote Count Data\"}\nAnswer the following using the vote count data files from the MIT Election\nData Science Lab. You may answer each with a table or plot as you feel is\nappropriate.\n\n1. Which states have gained and lost the most seats in the US House of\n   Representatives between 1976 and 2022?\n\n2. New York State has a unique \"fusion\" voting system where one candidate can\n   appear on multiple \"lines\" on the ballot and their vote counts are totaled. \n   For instance, in 2022, Jerrold Nadler appeared on both the Democrat and \n   Working Families party lines for NYS' 12th Congressional District. He received\n   200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily\n   defeating Michael Zumbluskas, who received 44,173 votes across three party\n   lines (Republican, Conservative, and Parent).\n\n   Are there any elections in our data where the election would have had a\n   different outcome if the \"fusion\" system was not used and candidates only\n   received the votes their received from their \"major party line\" (Democrat\n   or Republican) and not their total number of votes across all lines?\n\n3. Do presidential candidates tend to run ahead of or run behind congressional\n   candidates in the same state? That is, does a Democratic candidate for\n   president tend to get more votes in a given state than all Democratic\n   congressional candidates in the same state?\n\n   Does this trend differ over time? Does it differ across states or across\n   parties? Are any presidents particularly more or less popular than their\n   co-partisans?\n:::\n\n### Importing and Plotting Shape File Data\n\nAs mentioned above, the shape files you downloaded above are distributed\nin `zip` archives, with several files. We only need the `shp` file within\neach archive. In this section, we'll practice extracting the `shp` file,\nreading it, and using it to create a plot. The key library we need is the\n`sf` (\"simple features\") library. It provides the `read_sf()` function\nwhich we can use to read it into `R`. I download how this works below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.3.1; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\", \n              method=\"curl\")\n}\n\n##-\ntd <- tempdir(); \nzip_contents <- unzip(\"nyc_borough_boundaries.zip\", \n                      exdir = td)\n    \nfname_shp <- zip_contents[grepl(\"shp$\", zip_contents)]\nnyc_sf <- read_sf(fname_shp)\nnyc_sf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 5\n  boro_code boro_name      shape_area shape_leng                        geometry\n      <dbl> <chr>               <dbl>      <dbl>              <MULTIPOLYGON [°]>\n1         3 Brooklyn      1934142776.    728147. (((-73.86327 40.58388, -73.863…\n2         5 Staten Island 1623618684.    325910. (((-74.05051 40.56642, -74.050…\n3         1 Manhattan      636646082.    360038. (((-74.01093 40.68449, -74.011…\n4         2 Bronx         1187174772.    463181. (((-73.89681 40.79581, -73.896…\n5         4 Queens        3041418004.    888197. (((-73.82645 40.59053, -73.826…\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Task 4: Automate Zip File Extraction\"}\nAdapt the code after the `##-` symbol above into a *function* \n`read_shp_from_zip()` which takes in a file name, pulls out the `.shp` \nfile contained there in, and reads it into `R` using `read_sf()`.\n:::\n\nThe result of this is a particular sort of data frame. The most important\ncolumn for us is the `geometry` column which is of type `MULTIPOLYGON`. This is,\nessentially, a list of GPS coordinates which outline a spatial region. Here,\neach row corresponds to a Borough of NYC. We can pass the `geometry` column\nto `ggplot2` to make a map:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(nyc_sf, \n       aes(geometry=geometry)) + \n    geom_sf()\n```\n\n::: {.cell-output-display}\n![](mini03_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nHere, we use the `sf` `geom` to get the shape outlines. The `sf` `geom`\nplays well with the `fill` aesthetic.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(nyc_sf, \n       aes(geometry=geometry, \n           fill = shape_area)) + \n    geom_sf()\n```\n\n::: {.cell-output-display}\n![](mini03_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis type of plot is called a [Chloropleth\nMap](https://en.wikipedia.org/wiki/Choropleth_map) and it is commonly used to\ndepict election results.\n\n::: {.callout-tip title=\"Task 5: Chloropleth Visualization of 2000 Electoral College Results\"}\nUsing the data you downloaded earlier, create a *chloropleth* visualization of the 2000 electoral college results, coloring each state by the party that won the most votes in that state. Your result should look something like this:\n\n![](https://upload.wikimedia.org/wikipedia/commons/1/19/ElectoralCollege2000.svg)\n\n**Taken from [Wikipedia](https://en.wikipedia.org/wiki/2000_United_States_presidential_election)**\n\nIt is not required, but to make the very best plot, you may want to look up:\n\n1)  How to \"inset\" Alaska and Hawaii instead of plotitng their true map locations.\n2)  How to add labels to a chloropleth in `ggplot2`\n3)  How to label the small states in the North-East\n\nbut these steps are not required as they are a bit advanced.\n:::\n\n::: {.callout-tip title=\"Task 6: Advanced Chloropleth Visualization of Electoral College Results\"}\nModify your previous code to make either an  *animated* version\nshowing election results over time.\n:::\n\nThe following example may be useful for you:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gganimate)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\n#| label: \"chloropleth_animated_example\"\n#| cache: true\n## Animated Chloropleth using gganimate\n\n## Add some time \"structure\" to our data for \n## demonstration purposes only\nnyc_sf_repeats <- bind_rows(\n    nyc_sf |> mutate(value = rnorm(5), \n                     frame = 1), \n    nyc_sf |> mutate(value = rnorm(5), \n                     frame = 2), \n    nyc_sf |> mutate(value = rnorm(5), \n                     frame = 3), \n    nyc_sf |> mutate(value = rnorm(5), \n                     frame = 4), \n    nyc_sf |> mutate(value = rnorm(5), \n                     frame = 5))\n\nlibrary(gganimate)\nggplot(nyc_sf_repeats, \n       aes(geometry=geometry, \n           fill = value)) + \n    geom_sf() + \n    transition_time(frame)\n```\n\n::: {.cell-output-display}\n![](mini03_files/figure-html/unnamed-chunk-4-1.gif)\n:::\n:::\n\n\nNow that we have finished exploring our data and building some tools for\nplots, we are ready to dig into our main question.\n\n## Comparing the Effects of ECV Allocation Rules\n\nGo through the historical voting data and assign each state's ECVs according\nto various strategies:\n\n1. State-Wide Winner-Take-All\n2. District-Wide Winner-Take-All + State-Wide \"At Large\" Votes\n3. State-Wide Proportional\n4. National Proportional\n\nBased on these allocation strategies, compare the \nwinning presidential candidate with the actual historical winner. \n\nWhat patterns do you see? Are the results generally \nconsistent or are one or more methods systematically\nmore favorable to one party? \n\nFor the district-level winner-take-all, you may assume\nthat the presidential candidate of the same party as\nthe congressional representative wins that election. \n\n::: {.callout-tip title=\"Task 7: Evaluating Fairness of ECV Allocation Schemes\"}\n\nWrite a fact check evaluating the fairness of the \ndifferent ECV electoral allocation schemes. \n\nTo do so, you should first determine which allocation\nscheme you consider \"fairest\". You should then see\nwhich schemes give different results,  if they ever\ndo. To make your fact check more compelling, select\none election where the ECV scheme had the largest\nimpact--if one exists--and explain how the results\nwould have been different under a different ECV\nscheme.\n\nAs you perform your analysis, you may assume that \nthe District of Columbia has three ECVs, which are\nallocated to the Democratic candidate under all\nschemes except possibly national popular vote.[^8]\n\n:::\n\n\nThroughout all of this, note that we are not varying\nthe $R+2$ ECV allocation scheme specified by the\nconstitution. Our concern here is only what individual\nstates can do to address \"fairness\" in presidential\nelections. If we allow the possibility of\nconstitutional amendment, the possibilities are\nendless. The $R+2$ rule has several interesting\neffects; some are well-known, such as the Senate's\nequal treatment of small and large states, while\nothers are less well-known, including the fact that \ncongressional representation is based on population, \nnot counts of voters.[^9] \n\n[^8]: The District of Columbia is _very_ Democratic. \n\n[^9]: This latter effect is admittedly quite small if\nwe assume political affiliation is unrelated to\nprobability of voting. The relationship between voting\nlikelihood and political leanings is an important one\nfor campaign strategists and actively debated by\nacademics.\n\n## Extra Credit Opportunity\n\n::: {.callout-note title=\"Extra Credit Opportunity\"}\n\nFor extra credit, extend your analysis to 2024\nelectoral results. You will have to find a reliable\nsource of 2024 state- or district-wide vote counts.\nIf the 2024 election is close, this may not be easy\nto do between the election and the date this\nmini-project is due.\n\n:::\n\n------------------------------------------------------------------------\n\n\n",
    "supporting": [
      "mini03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}