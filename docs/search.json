[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Transit Data Analysis",
    "section": "",
    "text": "This document contains code to load, process, and analyze transit data.\n\n\nLet’s begin by clearing the environment and setting the working directory."
  },
  {
    "objectID": "mp01.html#setup",
    "href": "mp01.html#setup",
    "title": "Transit Data Analysis",
    "section": "",
    "text": "Let’s begin by clearing the environment and setting the working directory."
  },
  {
    "objectID": "mp01.html#task-6-farebox-recovery-among-major-systems",
    "href": "mp01.html#task-6-farebox-recovery-among-major-systems",
    "title": "Transit Data Analysis",
    "section": "Task 6: Farebox Recovery Among Major Systems",
    "text": "Task 6: Farebox Recovery Among Major Systems"
  },
  {
    "objectID": "mini02.html",
    "href": "mini02.html",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "install.packages(“tinytex”) tinytex::install_tinytex()"
  },
  {
    "objectID": "mini02.html#mini-project-02",
    "href": "mini02.html#mini-project-02",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "Mini-Project #02",
    "text": "Mini-Project #02\n\nData\nFor this project, we will use data from the Internet Movie Database (IMDb). Specifically, we will use the tables from the IMDb non-commercial release. These files are made freely available by IMDb for non-commercial use.\nThe following code will automatically download and load these files into R:\n\n\nShow Code\n# Reset everything\n# rm(list = ls())\n\n\n\n#| label: 'imdb_name_basics'\n#| message: false \n#| warning: false\n#| cache: true\nget_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS      &lt;- get_imdb_file(\"name.basics\")\n\n\nRows: 13870775 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (6): nconst, primaryName, birthYear, deathYear, primaryProfession, known...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nShow Code\nTITLE_BASICS     &lt;- get_imdb_file(\"title.basics\")\n\n\n\n\nShow Code\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\n\n\n\n\nShow Code\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\n\n\n\n\nShow Code\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\n\n\n\n\nShow Code\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\n\nNote that these are large files and it will take some time for them to download the first time. Because these files are so large, it will also take a little while to read them. If you want to speed up this stage, you can cache the code chunk that reads the files. This will ‘save’ the result of the chunk and only require it to be re-executed when it is changed.\n\n\nData Sub-Sampling\nThis data is large enough that we’re going to need to immediately start down-selecting to get to a data set that we can analyze fluidly. For our NAME_BASICS table, we’ll restrict our attention to people with at least two “known for” credits.[^1]\n\n\nShow Code\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\n\n\nIMDb has a long tail of obscure movies:\n\n\nShow Code\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n\n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\n\nTo keep our computers from working too hard, let’s throw out any title with less than 100 ratings. It’s not too hard to see that this drops about 75% of the entire data set:\n\n\nShow Code\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n\n     0%     25%     50%     75%    100% \n      5      11      26     101 2951083 \n\n\nApplying this drop, we significantly reduce the size of our data set:\n\n\nShow Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n\n\nWe want to perform the same filtering on our other TITLE_* tables. This is a rare use for the semi_join. Recall that a semi_join returns only values which have a match,but doesn’t actually add columns.\n\n\nShow Code\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\nAt this point, we’ve filtered down our data significantly and are ready to begin analysis in earnest. Note that our sub-sampling may induce some ‘dangling’ references: some of the people dropped from the NAME_BASICS table may only appear in one famous movie, and we’ve likely lost their info.\n\n\n\n\n\n\nProcessing Large Data\n\n\n\nEven with this processing, this a non-trivial amount of data, requiring approximately 2 GB of memory. If your computer is significantly struggling to perform this pre-processing, the instructor may be able to provide smaller data files upon request. (Even on my quite modern laptop, the initial processing phase takes a few minutes: by ‘significant struggling’, I’m referring to processing taking upwards of half an hour or exhausting all available memory.) Please contact the instructor and TA through the course discussion board to discuss this possibility.\nProcessing large data sets is a skill, however, so we’re starting with the large data set to help you practice it.\n\n\n\n\n\n\n\n\nPre-Processed Data\n\n\n\n\n\nExports of the pre-processed data can be found on the course GitHub repo. If your computer is struggling to handle the full data set, you may choose to use these instead. The readr::read_csv files handles zip compression transparently, but you will need to modify get_imdb_file above to:\n\nPoint to my GitHub instead of the IMDB archive\nUse .csv.zip files instead of .tsv.gz\n\nNote also that, to get the compressed files small enough to store on GitHub, I had to apply more filtering than the code above uses. Make sure to note if you are using this extra-filtered extract so that a reader knows why you might be getting different answers.\n\n\n\n\n\nInitial Exploration\nAt this point, let’s start examining our data more closely. Use the glimpse function to examine each table, taking care to note the type or mode of each column. For this data set, most columns appear to be read in as character (string) vectors, even when they should be numeric. This can occur when “null” values are represented in some non-standard way. For instance, in these files, we see that missing values are represented as \\\\N. R does not know that these are NA values and so retains them as strings.[^2]\nTo fix this, we need to use:\n\nthe mutate command, since we’re changing the type of a column\nthe as.numeric command to change the type of the column.\n\nWe can clean the NAMES_BASIC command as follows:\n\n\nShow Code\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\n\n\n\n\n\n\n\nTask 1: Column Type Correction\n\n\n\nCorrect the column types of the TITLE tables using a combination of mutate and the coercion functions as.numeric and as.logical.\n\n\nAnother non-tidy aspect of this data is that it combines multiple pieces of information in a single cell separated by commas. We already saw a bit of this in the NAME_BASICS table, where both the primaryProfession and knownForTitles columns combine multiple values.\n\n\nShow Code\nglimpse(NAME_BASICS)\n\n\nRows: 3,187,037\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\n\nWe can use the separate_longer_delim function to break these into multiple rows: for example\n\n\nShow Code\nNAME_BASICS |&gt; separate_longer_delim(knownForTitles, \",\") |&gt; slice_head(n=10)\n\n\n      nconst     primaryName birthYear deathYear\n1  nm0000001    Fred Astaire      1899      1987\n2  nm0000001    Fred Astaire      1899      1987\n3  nm0000001    Fred Astaire      1899      1987\n4  nm0000001    Fred Astaire      1899      1987\n5  nm0000002   Lauren Bacall      1924      2014\n6  nm0000002   Lauren Bacall      1924      2014\n7  nm0000002   Lauren Bacall      1924      2014\n8  nm0000002   Lauren Bacall      1924      2014\n9  nm0000003 Brigitte Bardot      1934        NA\n10 nm0000003 Brigitte Bardot      1934        NA\n                    primaryProfession knownForTitles\n1        actor,miscellaneous,producer      tt0072308\n2        actor,miscellaneous,producer      tt0050419\n3        actor,miscellaneous,producer      tt0053137\n4        actor,miscellaneous,producer      tt0027125\n5  actress,soundtrack,archive_footage      tt0037382\n6  actress,soundtrack,archive_footage      tt0075213\n7  actress,soundtrack,archive_footage      tt0117057\n8  actress,soundtrack,archive_footage      tt0038355\n9   actress,music_department,producer      tt0057345\n10  actress,music_department,producer      tt0049189\n\n\nTo preserve flexibility, let’s not fully separate NAME_BASICS just yet, but you will need to use separate_longer_delim to answer various questions.\nUsing your knowledge of dplyr functionality, answer the following questions\n\n\n\n\n\n\nTask 2: Instructor-Provided Questions\n\n\n\n\nHow many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nShow Code\n# Filter and count the number of movies, TV series, and TV episodes\nmovies_series_episodes_counts &lt;- filter(count(TITLE_BASICS, titleType), \n                                        titleType == \"movie\" | titleType == \"tvSeries\" | titleType == \"tvEpisode\")\n\n# Display the result in a formatted sentence\ncat(\"There are a total of\", \n    movies_series_episodes_counts[movies_series_episodes_counts$titleType == \"movie\", \"n\"], \"movies,\",\n    movies_series_episodes_counts[movies_series_episodes_counts$titleType == \"tvSeries\", \"n\"], \"TV series, and\",\n    movies_series_episodes_counts[movies_series_episodes_counts$titleType == \"tvEpisode\", \"n\"], \"TV episodes in our data set.\")\n\n\nThere are a total of 132193 movies, 29965 TV series, and 156637 TV episodes in our data set.\n\n\n\nWho is the oldest living person in our data set?\n\n\n\nShow Code\n# Filter for the oldest living person (who has no death year) and find the minimum birth year\noldest_living_person &lt;- NAME_BASICS |&gt;\n  filter(is.na(deathYear)) |&gt;\n  slice_min(birthYear)\n\n# Display the result in a formatted sentence\ncat(\"The oldest living person in the data set was born in\", \n    oldest_living_person$birthYear, \"and their name is\", \n    oldest_living_person$primaryName, \".\")\n\n\nThe oldest living person in the data set was born in 1625 and their name is Traudl Lessing .\n\n\n\nThere is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\n\n\n\nShow Code\nperfect_episode &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10, numVotes &gt;= 200000) |&gt;  # At least 200,000 votes\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;  # Join to get title information\n  inner_join(TITLE_EPISODES, by = \"tconst\") |&gt;  # Episode information\n  select(tconst, primaryTitle, originalTitle, titleType, numVotes) |&gt;  # Include identifier\n  slice_head(n = 1)  # Select the first episode that meets the criteria\n\n# Display the result in a formatted sentence\ncat(\"The episode with a perfect rating of 10/10 and more than 200,000 votes is\",\n    perfect_episode$primaryTitle, \"with\", perfect_episode$numVotes, \"votes. The identifier (tconst) is\", perfect_episode$tconst, \".\")\n\n\nThe episode with a perfect rating of 10/10 and more than 200,000 votes is Ozymandias with 229589 votes. The identifier (tconst) is tt2301451 .\n\n\n\n\nShow Code\n# Set a CRAN mirror before installing any packages\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n# Install magick if necessary\nif (!require(\"magick\")) {\n  install.packages(\"magick\")\n}\n\n\nLoading required package: magick\n\n\nLinking to ImageMagick 6.9.12.98\nEnabled features: cairo, freetype, fftw, ghostscript, heic, lcms, pango, raw, rsvg, webp\nDisabled features: fontconfig, x11\n\n\nShow Code\n# Load libraries\nlibrary(dplyr)\nlibrary(magick)\n\n# Your existing code to find the perfect episode\nperfect_episode &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10, numVotes &gt;= 200000) |&gt;  # At least 200,000 votes\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;  # Join to get title information\n  inner_join(TITLE_EPISODES, by = \"tconst\") |&gt;  # Episode information\n  select(tconst, primaryTitle, originalTitle, titleType, numVotes) |&gt;  # Include identifier\n  slice_head(n = 1)  # Select the first episode that meets the criteria\n\n# Display the result in a formatted sentence\ncat(\"The episode with a perfect rating of 10/10 and more than 200,000 votes is\",\n    perfect_episode$primaryTitle, \"with\", perfect_episode$numVotes, \"votes. The identifier (tconst) is\", perfect_episode$tconst, \".\")\n\n\nThe episode with a perfect rating of 10/10 and more than 200,000 votes is Ozymandias with 229589 votes. The identifier (tconst) is tt2301451 .\n\n\nShow Code\n# Load the image from your local path\nimg_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Image Breaking Bad.jpg\"  # Path to your local image\nimg &lt;- image_read(img_path)\n\n# Display the image\nprint(img)\n\n\n# A tibble: 1 × 7\n  format width height colorspace matte filesize density\n  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n1 JPEG     500    281 sRGB       FALSE    14709 72x72  \n\n\n\n\n\n\n\n\n\nShow Code\n# Optionally, you can annotate it with text\n#image_annotate(img, \"Breaking Bad Scene\", size = 30, color = \"white\", location = \"+20+20\") |&gt; print()\n\n\n\nWhat four projects is the actor Mark Hamill most known for?\n\n\n\nShow Code\n# Get the four projects Mark Hamill is most known for\nmark_hamill_projects &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  separate_rows(knownForTitles, sep = \",\") |&gt;\n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  slice(1:4)  # Limit to the first 4 projects\n\n# Display the result in a formatted sentence\ncat(\"Mark Hamill is most known for these four projects:\\n\",\n    paste(mark_hamill_projects$primaryTitle, collapse = \", \"), \".\")\n\n\nMark Hamill is most known for these four projects:\n Star Wars: Episode IV - A New Hope, Star Wars: Episode VIII - The Last Jedi, Star Wars: Episode V - The Empire Strikes Back, Star Wars: Episode VI - Return of the Jedi .\n\n\n\nWhat TV series, with more than 12 episodes, has the highest average rating?\n\nFind the highest average rating among these series\n\n\nShow Code\n# Count episodes per series and filter for series with more than 12 episodes\nepisode_counts &lt;- TITLE_EPISODES |&gt;\n  count(parentTconst) |&gt; \n  filter(n &gt; 12)\n\n# Find the highest average rating among these series\nbest_series &lt;- TITLE_RATINGS |&gt; \n  inner_join(episode_counts, by = c(\"tconst\" = \"parentTconst\")) |&gt; \n  arrange(desc(averageRating)) |&gt; \n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt; \n  slice(1) |&gt; \n  select(primaryTitle, averageRating)\n\n# Display the result in a formatted sentence\ncat(\"The TV series with the highest average rating is\", best_series$primaryTitle, \n    \"with an average rating of\", best_series$averageRating, \".\")\n\n\nThe TV series with the highest average rating is Craft Games with an average rating of 9.7 .\n\n\n\nThe TV series Happy Days (1974-1984) gives us the common idiom “jump the shark”. The phrase comes from a controversial fifth season episode (aired in 1977) in which a lead character literally jumped over a shark on water skis. Idiomatically, it is used to refer to the moment when a once-great show becomes ridiculous and rapidly looses quality.\nIs it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\n\n\n\nShow Code\n# Step 1: Find the IMDb ID for Happy Days\nhappy_days &lt;- TITLE_BASICS |&gt;\n  filter(primaryTitle == \"Happy Days\" & titleType == \"tvSeries\")\nhappy_days_id &lt;- happy_days$tconst[1]  # Select the first IMDb ID\n\n# Step 2: Get all episodes of Happy Days and their ratings\nhappy_days_episodes &lt;- TITLE_EPISODES |&gt;\n  filter(parentTconst == happy_days_id) |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  mutate(seasonNumber = as.numeric(seasonNumber)) |&gt;  # Convert seasonNumber to numeric\n  select(seasonNumber, averageRating)\n\n# Step 3: Calculate average rating by season, sorted by seasonNumber\naverage_ratings_by_season &lt;- happy_days_episodes |&gt;\n  group_by(seasonNumber) |&gt;\n  summarize(avg_rating = mean(averageRating, na.rm = TRUE)) |&gt;\n  arrange(seasonNumber)\n\n# Output: Print the IMDb ID and the average ratings by season\ncat(\"The IMDb ID for 'Happy Days' is:\", happy_days_id, \"\\n\\n\")\n\n\nThe IMDb ID for 'Happy Days' is: tt0070992 \n\n\nShow Code\ncat(\"Average ratings by season:\\n\")\n\n\nAverage ratings by season:\n\n\nShow Code\nprint(average_ratings_by_season)\n\n\n# A tibble: 11 × 2\n   seasonNumber avg_rating\n          &lt;dbl&gt;      &lt;dbl&gt;\n 1            1       7.58\n 2            2       7.69\n 3            3       7.7 \n 4            4       7.43\n 5            5       7   \n 6            6       7.02\n 7            7       6.33\n 8            8       5.3 \n 9            9       6.4 \n10           10       6.7 \n11           11       7.33\n\n\nHint: It may be useful to create a “map” of which columns map to which tables before attempting these questions. While these can be quite formal, even some basic sketches on a scratch piece of paper are often quite clarifying.\n\n\n\n\nQuantifying Success\nOur goal is to proposal successful new movies. To do so, we need a way of measuring the success of a movie given only IMDb ratings.[^3] While there’s no “magic number” for success, it is logical to assume that a successful project will have both a high average IMDb rating, indicating quality, and a large number of ratings, indicating broad awareness in the public.\n\n\n\n\n\n\nTask 3: Custom Success Metric\n\n\n\nDesign a ‘success’ measure for IMDb entries, reflecting both quality and broad popular awareness. Implement your success metric using a mutate operator to add a new column to the TITLE_RATINGS table.\nValidate your success metric as follows:\n\nChoose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\n\n\n\nShow Code\n# Step 1: Calculate the success metric and get the top 10 movies\ntop_movies &lt;- TITLE_RATINGS |&gt;\n  mutate(success = averageRating * log(numVotes)) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\") |&gt;\n  top_n(10, success) |&gt;\n  select(primaryTitle, success)\n\n# Step 2: Display the top 10 movies in a simple format\ncat(\"Top 10 movies based on success metric:\\n\")\n\n\nTop 10 movies based on success metric:\n\n\nShow Code\ncat(top_movies$primaryTitle, sep = \"\\n\")\n\n\nThe Godfather\nSchindler's List\nForrest Gump\nPulp Fiction\nThe Shawshank Redemption\nThe Lord of the Rings: The Fellowship of the Ring\nFight Club\nThe Lord of the Rings: The Return of the King\nThe Dark Knight\nInception\n\n\n\nChoose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\n\n\n\nShow Code\n# Step 1: Filter movies with votes and calculate the success metric\njoined_data &lt;- TITLE_RATINGS |&gt;\n  filter(numVotes &gt; 0) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\") |&gt;\n  mutate(success = averageRating * log(numVotes))\n\n# Step 2: Select the bottom 5 movies with high vote counts and low success\nlow_quality_movies &lt;- joined_data |&gt;\n  filter(numVotes &gt; 100000) |&gt;\n  arrange(success) |&gt;           # Sort by the success metric (ascending)\n  slice_head(n = 5) |&gt;\n  select(primaryTitle, numVotes, averageRating, success)\n\n# Step 3: Display the result\ncat(\"Bottom 5 movies by success with more than 100,000 votes:\\n\")\n\n\nBottom 5 movies by success with more than 100,000 votes:\n\n\nShow Code\nfor (i in 1:nrow(low_quality_movies)) {\n  cat(i, \". \", low_quality_movies$primaryTitle[i], \n      \" | Votes: \", low_quality_movies$numVotes[i], \n      \" | Rating: \", low_quality_movies$averageRating[i], \n      \" | Success: \", round(low_quality_movies$success[i], 2), \"\\n\", sep = \"\")\n}\n\n\n1. Radhe | Votes: 180234 | Rating: 1.9 | Success: 22.99\n2. Epic Movie | Votes: 110309 | Rating: 2.4 | Success: 27.87\n3. Adipurush | Votes: 134356 | Rating: 2.7 | Success: 31.88\n4. Meet the Spartans | Votes: 112308 | Rating: 2.8 | Success: 32.56\n5. 365 Days | Votes: 100866 | Rating: 3.3 | Success: 38.02\n\n\n\nChoose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\n\n\n\nShow Code\n# Step 1: Get Milla Jovovich's ID\nmilla &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Milla Jovovich\")\n\n# Step 2: Get all titles associated with Milla Jovovich (her nconst)\nmilla_titles &lt;- TITLE_PRINCIPALS |&gt;\n  filter(nconst == milla$nconst) |&gt;\n  select(tconst)\n\n# Step 3: Join Milla's titles with movie ratings and info, and calculate success\nmilla_movies &lt;- milla_titles |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\") |&gt;\n  mutate(success = averageRating * log(numVotes)) |&gt;\n  select(primaryTitle, averageRating, numVotes, success) |&gt;\n  arrange(desc(success))  # Sort by success\n\n# Step 4: Show the top 5 successful movies with numVotes and averageRating\ntop_milla_movies &lt;- milla_movies |&gt; slice_head(n = 5)\n\n# Step 5: Display the result\ncat(\"Top 5 movies starring Milla Jovovich based on success metric:\\n\")\n\n\nTop 5 movies starring Milla Jovovich based on success metric:\n\n\nShow Code\nfor (i in 1:nrow(top_milla_movies)) {\n  cat(i, \". \", top_milla_movies$primaryTitle[i], \n      \" | Votes: \", top_milla_movies$numVotes[i], \n      \" | Rating: \", top_milla_movies$averageRating[i], \n      \" | Success: \", round(top_milla_movies$success[i], 2), \"\\n\", sep = \"\")\n}\n\n\n1. The Fifth Element | Votes: 515828 | Rating: 7.6 | Success: 99.97\n2. Dazed and Confused | Votes: 203820 | Rating: 7.6 | Success: 92.91\n3. Resident Evil | Votes: 293614 | Rating: 6.6 | Success: 83.09\n4. Zoolander | Votes: 298411 | Rating: 6.5 | Success: 81.94\n5. Resident Evil: Extinction | Votes: 207893 | Rating: 6.2 | Success: 75.92\n\n\n\nPerform at least one other form of ‘spot check’ validation.\n\n\n\nShow Code\n# Step 1: Load necessary libraries\ninstall.packages(\"dplyr\")\n\n\nWarning: package 'dplyr' is in use and will not be installed\n\n\nShow Code\nlibrary(dplyr)\n\n# Step 2: Retrieve all Resident Evil movies from the database, excluding films with less than 200 votes\nresident_evil_movies &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  filter(grepl(\"Resident Evil\", primaryTitle, ignore.case = TRUE), numVotes &gt;= 200) |&gt;  # Search for \"Resident Evil\" and filter votes\n  select(primaryTitle, averageRating, numVotes)\n\n# Step 3: Perform a spot check for Milla Jovovich's Resident Evil movies, excluding films with less than 200 votes\nmilla_movies_spot_check &lt;- TITLE_PRINCIPALS |&gt;\n  filter(nconst == \"nm0000170\") |&gt;  # Milla Jovovich's nconst\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt; \n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  filter(grepl(\"Resident Evil\", primaryTitle, ignore.case = TRUE), numVotes &gt;= 200) |&gt;  # Filter votes &gt;= 200\n  select(primaryTitle, averageRating, numVotes)\n\n# Step 4: Display the result of the spot check for Resident Evil movies\ncat(\"Spot check for Milla Jovovich's Resident Evil movies:\\n\")\n\n\nSpot check for Milla Jovovich's Resident Evil movies:\n\n\nShow Code\napply(milla_movies_spot_check, 1, function(row) {\n  cat(row[\"primaryTitle\"], \"| Rating:\", row[\"averageRating\"], \"| Votes:\", row[\"numVotes\"], \"\\n\")\n})\n\n\nResident Evil | Rating: 6.6 | Votes: 293614 \nResident Evil: Apocalypse | Rating: 6.1 | Votes: 212646 \nResident Evil: Extinction | Rating: 6.2 | Votes: 207893 \nResident Evil: Afterlife | Rating: 5.8 | Votes: 181137 \nResident Evil: Retribution | Rating: 5.3 | Votes: 152062 \nResident Evil: The Final Chapter | Rating: 5.5 | Votes: 102720 \nResident Evil: The Final Chapter | Rating: 5.5 | Votes: 102720 \n\n\nNULL\n\n\nShow Code\n# Extra Check: Overall Average Rating Comparison\n# Step 5: Calculate Milla Jovovich's average rating across all movies\nmilla_movies_all &lt;- TITLE_PRINCIPALS |&gt;\n  filter(nconst == \"nm0000170\") |&gt;  # Milla Jovovich's nconst\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt; \n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  summarise(overall_avg_rating = mean(averageRating, na.rm = TRUE))\n\n# Step 6: Compare the spot-checked movies' average rating to her overall average\nspot_check_avg_rating &lt;- mean(milla_movies_spot_check$averageRating, na.rm = TRUE)\n\n# Step 7: Display final comparison with extra audience details\ncat(\"\\nSpot Check Average Rating for Resident Evil movies:\", round(spot_check_avg_rating, 2), \n    \"\\nOverall Average Rating for Milla Jovovich movies:\", round(milla_movies_all$overall_avg_rating, 2), \"\\n\")\n\n\n\nSpot Check Average Rating for Resident Evil movies: 5.86 \nOverall Average Rating for Milla Jovovich movies: 6.07 \n\n\nShow Code\n# Additional explanation\ncat(\"\\nHuge Audience: These films have hundreds of thousands of votes, showing they are fan favorites, especially the first Resident Evil with almost 300,000 votes.\\n\",\n    \"Strong Appeal: Milla led the series for six movies over 14 years, proving her ability to keep audiences interested.\\n\",\n    \"Action Icon: She made Alice a well-loved character in the action-horror genre, turning the Resident Evil series into a lasting success.\\n\")\n\n\n\nHuge Audience: These films have hundreds of thousands of votes, showing they are fan favorites, especially the first Resident Evil with almost 300,000 votes.\n Strong Appeal: Milla led the series for six movies over 14 years, proving her ability to keep audiences interested.\n Action Icon: She made Alice a well-loved character in the action-horror genre, turning the Resident Evil series into a lasting success.\n\n\nSpot Check Validation\nTask: Perform at least one other form of ‘spot check’ validation.\nTo further validate Milla Jovovich’s impact in action films, here’s a spot check of her Resident Evil movies, showcasing how these popular films performed:\n\nResident Evil | Rating: 6.6 | Votes: 293,614\nResident Evil: Apocalypse | Rating: 6.1 | Votes: 212,646\nResident Evil: Extinction | Rating: 6.2 | Votes: 207,893\nResident Evil: Afterlife | Rating: 5.8 | Votes: 181,137\nResident Evil: Retribution | Rating: 5.3 | Votes: 152,062\nResident Evil: The Final Chapter | Rating: 5.5 | Votes: 102,720\n\nThe Resident Evil series showcases Milla’s consistent presence in high-action roles, with a strong fan base despite varying ratings. This confirms her staying power in the genre.\n\nCome up with a numerical threshold for a project to be a ‘success’; that is, determine a value \\(v\\) such that movies above \\(v\\) are all “solid” or better.\n\n\n\nShow Code\n# Step 1: Define a numerical threshold for success\nthreshold_rating &lt;- 7.5  # Movies with ratings 7.5 and above\nthreshold_votes &lt;- 100000  # Movies with at least 100,000 votes\n\n# Step 2: Join with TITLE_BASICS and filter for highly rated movies based on thresholds\nsolid_movies &lt;- TITLE_RATINGS |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  filter(averageRating &gt;= threshold_rating, numVotes &gt;= threshold_votes) |&gt;  \n  select(primaryTitle, averageRating, numVotes) |&gt;\n  slice_head(n = 10)  # Get the top 10 movies\n\n# Step 3: Display the top solid movies\ncat(\"Top 10 solid movies (IMDb rating &gt;= \", threshold_rating, \" and votes &gt;= \", threshold_votes, \"):\\n\", sep = \"\")\n\n\nTop 10 solid movies (IMDb rating &gt;= 7.5 and votes &gt;= 1e+05):\n\n\nShow Code\nfor (i in 1:nrow(solid_movies)) {\n  cat(i, \". \", solid_movies$primaryTitle[i], \n      \" | Rating: \", solid_movies$averageRating[i], \n      \" | Votes: \", solid_movies$numVotes[i], \"\\n\", sep = \"\")\n}\n\n\n1. The Kid | Rating: 8.2 | Votes: 137306\n2. Nosferatu: A Symphony of Horror | Rating: 7.8 | Votes: 108133\n3. The Gold Rush | Rating: 8.1 | Votes: 120482\n4. Metropolis | Rating: 8.3 | Votes: 188795\n5. City Lights | Rating: 8.5 | Votes: 199528\n6. M | Rating: 8.3 | Votes: 171568\n7. It Happened One Night | Rating: 8.1 | Votes: 114467\n8. Modern Times | Rating: 8.5 | Votes: 264133\n9. Snow White and the Seven Dwarfs | Rating: 7.6 | Votes: 219387\n10. Gone with the Wind | Rating: 8.2 | Votes: 338994\n\n\n\n\nShow Code\n# Check if the dataset exists and show the structure of the dataset\n\n\n\n\nYou will use your success metric and threshold to complete the rest of this Mini-Project. You may, if you wish, restrict your attention to movies for the remainder of your analysis, though a good development executive should also consider making TV series.\n\n\nExamining Success by Genre and Decade\nNow that you have a working proxy for success, it’s time to look at trends in success over time. Answer the following questions. Your responses should include at least 2 graphics.\n::: {.callout-tip} #### Task 4: Trends in Success Over Time Using questions like the following, identify a good “genre” for your next film. You do not need to answer these questions precisely, but these are may help guide your thinking.\n\nWhat was the genre with the most “successes” in each decade?\n\n\n\nShow Code\n# Normalize by the number of movies in each genre\nmost_successes_in_each_decade &lt;- TITLE_RATINGS |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\", as.numeric(startYear) &gt;= 1900) |&gt;\n  mutate(decade = 10 * (as.numeric(startYear) %/% 10)) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(total_votes = sum(numVotes), movie_count = n(), .groups = 'drop') |&gt;\n  mutate(votes_per_movie = total_votes / movie_count) |&gt;  # Normalize by number of movies\n  slice_max(votes_per_movie, by = decade, n = 1)\n\n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `as.numeric(startYear) &gt;= 1900`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nShow Code\n# Display the results\nprint(most_successes_in_each_decade)\n\n\n# A tibble: 14 × 5\n   decade genres    total_votes movie_count votes_per_movie\n    &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;       &lt;int&gt;           &lt;dbl&gt;\n 1   1900 Action            934           1            934 \n 2   1900 Adventure         934           1            934 \n 3   1910 War             36865          22           1676.\n 4   1920 Sci-Fi         199734          13          15364.\n 5   1930 Animation      226698           6          37783 \n 6   1940 Animation      652550          24          27190.\n 7   1950 Animation      835315          27          30938.\n 8   1960 Biography     1598637         124          12892.\n 9   1970 Sci-Fi        4583331         286          16026.\n10   1980 Adventure    22142548         904          24494.\n11   1990 Adventure    30413695         843          36078.\n12   2000 Adventure    83901964        1487          56424.\n13   2010 Sci-Fi       64998234        1492          43564.\n14   2020 Adventure    28750456        1153          24935.\n\n\n\n\nShow Code\n# Load necessary libraries\nlibrary(ggplot2)\n\n# Plot the results: Votes per movie by genre and decade\nggplot(most_successes_in_each_decade, aes(x = factor(decade), y = votes_per_movie, fill = genres)) +\n  geom_col(show.legend = FALSE) +  # Use geom_col to create a bar plot\n  geom_text(aes(label = genres), vjust = -0.5, size = 3.5) +  # Add genre labels on top of bars\n  labs(\n    title = \"Top Genre by Decade (Normalized by Votes per Movie)\",\n    x = \"Decade\",\n    y = \"Votes per Movie\"\n  ) +\n  theme_minimal(base_size = 14) +  # Use a clean theme\n  scale_y_continuous(labels = scales::comma) +  # Format y-axis for better readability\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better visibility"
  },
  {
    "objectID": "mini02.html#putting-it-together",
    "href": "mini02.html#putting-it-together",
    "title": "?var:course.short Mini-Project #02: The Business of Show Business",
    "section": "Putting It Together",
    "text": "Putting It Together\n\n\n\n\n\n\nTask 7: Write and Deliver Your Pitch\n\n\n\nNow that you have completed your analysis, write an “elevator pitch” of approximately 200-250 words for your proposed Hollywood project. This is the pitch you will bring to the studio head (your boss); if the studio head likes your pitch, you will be given a small sum of money to start securing the story rights and locking down tentative deals with key talent.\nYour pitch needs to synthesize the analysis above into two to three quick and compelling points. (E.g., “The market for animated young adult horror musicals has grown 200% in the past decade” or “Over 90% of Director D’s movies are successes.”) You need to present the strongest argument for each element of your pitch, including genre, director, actors, and story.\nIf your boss approves the pitch, you will need to have a brief trailer ready for the next quarterly earnings call. The marketing department has asked that you prepare a classic 90’s style teaser for them. Adapt the following cliched formula for your pitch.\n\nFrom director D, the visionary mind between N1; and From actor A, beloved star of N2; and From actor A2, Hollywood icon of genre G, Comes the timeless tail N3 A story of TOPIC, TOPIC, and TOPIC Coming soon to a theater near you.\n\nIf you’re creatively-minded, you could have some fun here using Generative tools to draft a script or mock up a movie poster for your pitch."
  },
  {
    "objectID": "mini02.html#general-remarks",
    "href": "mini02.html#general-remarks",
    "title": "?var:course.short Mini-Project #02: The Business of Show Business",
    "section": "General Remarks",
    "text": "General Remarks\nAs you approach this project, recall there are no right or wrong answers. You are exploring data looking for exciting and actionable findings. You have several key decisions to make and you can support them with data, but the decisions are ultimately yours. This project is an exercise both in the “nuts-and-bolts” of analyzing a large data set and in using data to inform and refine what is ultimately still a “gut feeling” qualitative business decision.\nAs you iterate on this project, you will see that seemingly small different choices can produce very different results. That’s ok! As data analysts, we are constantly faced with small and essentially arbitrary decisions. An important “meta-skill” is knowing which of these decisions radically change our findings and which are meaningless. (An arbitrary decision with no impact on the bottom line is harmless; an arbitrary decision that could entirely change the plan for the next ten years is a problem.) Our responsibility is to clearly communicate these choices to our partners and clients: then we can receive their feedback on which way they would like to proceed.\nWorking in tools like Quarto and R helps here: if we provide clean and reproducible code, it should be easy to modify to see how our final conclusions are changed. Graphics also play an essential role in this form of clear communication: a ‘point estimate’ like “Action A is the best” is far less interpretable than a chart showing the predicted outcomes of several different actions.\nAs you approach this project, focus on justifying and communicating the choices you make. Structure your argument to communicate both key findings and uncertainties around them. Think about how you can use both document structure (headings vs subsections) and graphics to communicate with both clarity and nuance.\nGood luck!\n\nThis work ©2024 by Michael Weylandt is licensed under a Creative Commons BY-NC-SA 4.0 license."
  },
  {
    "objectID": "mini02.html#footnotes",
    "href": "mini02.html#footnotes",
    "title": "?var:course.short Mini-Project #02: The Business of Show Business",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt’s not entirely transparent who IMDb decides what projects an actor or director is “known for”. Still, it’s a reasonable filter that leaves us with more than enough to work with for this project.↩︎\nRecall that strings can contain essentially any data type and so are a safe fall-back. For instance, a column containing 1 and a can be losslessly represented by the string vector c(\"1\", \"a\") but coercion to the numeric vector c(1, NA) is lossy. R tries very hard not to destroy any information and so it doesn’t perform this conversion for us unless we explicitly request it.↩︎\nSadly, I couldn’t find permissively licensed movie box office data. If you are aware of some, please let me know!↩︎"
  },
  {
    "objectID": "mini02.html#genre-with-the-most-successes-in-each-decade",
    "href": "mini02.html#genre-with-the-most-successes-in-each-decade",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "Genre with the Most “Successes” in Each Decade",
    "text": "Genre with the Most “Successes” in Each Decade\nWhen looking at the number of votes per movie, the most successful genre has changed over the decades. This shows how people’s tastes in movies have changed over time:\n\nIn the 1920s, Sci-Fi was the most popular genre.\nIn the 1930s and 1940s, Animation was the top genre, with many successful movies during these years.\nBy the 1980s and 1990s, Adventure movies became the favorite, continuing to be the most successful genre in the 2000s.\nIn the 2010s, Sci-Fi came back as the most successful genre.\nIn the 2020s, Adventure is still very popular and leads in success.\n\nThis shows how different genres have been the most successful at different times, depending on what audiences preferred during each decade.\n\nWhat genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\n\n\n\nShow Code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Suppress warnings globally\noptions(warn = -1)\n\n# Step 1: Define the rating threshold for successful movies\nthreshold_rating &lt;- 7.5\n\n# Step 2: Filter the data to include only successful movies from 1990 onwards\nsuccessful_movies &lt;- TITLE_RATINGS %&gt;%\n  inner_join(TITLE_BASICS, by = \"tconst\") %&gt;%\n  filter(averageRating &gt;= threshold_rating, as.numeric(startYear) &gt;= 1990)\n\n# Step 3: Group by genre and year, calculate cumulative count\nsuccessful_movies_by_genre &lt;- successful_movies %&gt;%\n  mutate(startYear = as.numeric(startYear)) %&gt;%\n  separate_rows(genres, sep = \",\") %&gt;%\n  group_by(genres, startYear) %&gt;%\n  summarize(success_count = n(), .groups = 'drop') %&gt;%\n  arrange(genres, startYear) %&gt;%\n  group_by(genres) %&gt;%\n  mutate(cumulative_success = cumsum(success_count))\n\n# Step 4: Select top genres based on cumulative success\ntop_genres &lt;- successful_movies_by_genre %&gt;%\n  group_by(genres) %&gt;%\n  summarize(total_cumulative_success = max(cumulative_success)) %&gt;%\n  arrange(desc(total_cumulative_success)) %&gt;%\n  slice(1:5) %&gt;%\n  pull(genres)\n\n# Step 5: Filter the data for the top 5 genres and plot\nplot_data_top_genres &lt;- successful_movies_by_genre %&gt;%\n  filter(genres %in% top_genres)\n\n# Step 6: Create a clearer plot\nggplot(plot_data_top_genres, aes(x = startYear, y = cumulative_success, color = genres, group = genres)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 2, shape = 21, fill = \"white\", stroke = 0.5) +\n  geom_text(data = plot_data_top_genres %&gt;% group_by(genres) %&gt;% filter(startYear == max(startYear)),\n            aes(label = genres), vjust = -0.5, size = 3.5) +  # Add genre labels only at the end\n  labs(\n    title = \"Cumulative Number of Successful Movies by Top 5 Genres (1990-2000)\",\n    x = \"Year\",\n    y = \"Cumulative Count of Successful Movies\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5),  # Center title\n    legend.position = \"none\"  # Remove legend since labels are used\n  ) +\n  scale_color_viridis_d(option = \"plasma\")\n\n\n\n\n\n\n\n\n\n\nSummary of Genre Success Over Time\nHistorical Genre Successes by Decade: - Animation dominated from the 1930s to 1950s but has fallen out of favor in recent decades. - Biography was successful in the 1960s, while Sci-Fi gained prominence in the 1970s. - Adventure has led from the 1980s to the 2020s, with Sci-Fi showing growth since the 2000s.\nCurrent Genre Performance (Since 2010): - Drama has produced the most movies but has an average success rate. - Biography has a higher success rate per movie, despite fewer productions. - Thriller shows strong success per movie, even with fewer releases than Drama.\nGenre That Fell Out of Favor: - Animation, which was once a dominant genre, especially in the mid-20th century, has seen its influence decline in recent years.\nConclusions: - Adventure has consistently produced successes across decades. - Animation, despite its early dominance, has fallen out of favor. - Sci-Fi has risen in popularity, especially in recent decades.\nThis overview highlights Adventure’s long-standing success, Animation’s decline, and Sci-Fi’s modern rise.\n\nWhat genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\n\n\n\nShow Code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define a rating threshold for successful movies\nthreshold_rating &lt;- 7.5\n\n# Step 1: Filter the data to include only successful movies from any year onwards\nsuccessful_movies &lt;- TITLE_RATINGS %&gt;%\n  inner_join(TITLE_BASICS, by = \"tconst\") %&gt;%\n  filter(averageRating &gt;= threshold_rating)\n\n# Step 2: Group by genre and year, calculate cumulative count of successful movies\nsuccessful_movies_by_genre &lt;- successful_movies %&gt;%\n  mutate(startYear = as.numeric(startYear)) %&gt;%   # Ensure startYear is numeric\n  separate_rows(genres, sep = \",\") %&gt;%            # Split multiple genres into separate rows\n  group_by(genres, startYear) %&gt;%\n  summarize(success_count = n(), .groups = 'drop') %&gt;%  # Count successful movies per genre and year\n  arrange(genres, startYear) %&gt;%\n  group_by(genres) %&gt;%\n  mutate(cumulative_success = cumsum(success_count))    # Calculate cumulative sum for each genre\n\n# Step 3: Capture cumulative value up to 1990 for each genre\ncumulative_up_to_1990 &lt;- successful_movies_by_genre %&gt;%\n  filter(startYear &lt; 1990) %&gt;%\n  group_by(genres) %&gt;%\n  summarize(total_up_to_1990 = max(cumulative_success, na.rm = TRUE))\n\n# Step 4: Filter data from 1990 onwards and add the cumulative value up to 1990\nsuccessful_movies_1990_onwards &lt;- successful_movies_by_genre %&gt;%\n  filter(startYear &gt;= 1990) %&gt;%\n  left_join(cumulative_up_to_1990, by = \"genres\") %&gt;%\n  mutate(cumulative_success = cumulative_success + total_up_to_1990)\n\n# Step 5: Rank genres by total cumulative success from 1990 onwards\nfinal_cumulative_success &lt;- successful_movies_1990_onwards %&gt;%\n  group_by(genres) %&gt;%\n  summarize(total_cumulative_success = max(cumulative_success)) %&gt;%\n  arrange(desc(total_cumulative_success))\n\n# Step 6: Split the genres into three equal groups based on cumulative success\nn &lt;- nrow(final_cumulative_success)\nsplit_size &lt;- floor(n / 3)\n\n# Top-performing genres\ntop_genres &lt;- final_cumulative_success %&gt;% \n  slice(1:split_size) %&gt;% \n  pull(genres)\n\n# Middle-performing genres\nmiddle_genres &lt;- final_cumulative_success %&gt;%\n  slice((split_size + 1):(2 * split_size)) %&gt;% \n  pull(genres)\n\n# Lower-performing genres\nlower_genres &lt;- final_cumulative_success %&gt;%\n  slice((2 * split_size + 1):n) %&gt;%\n  pull(genres)\n\n# Step 7: Plot the three groups of genres separately, starting from 1990\n\n# Plot 1: Top-performing genres\ntop_genres_plot &lt;- ggplot(successful_movies_1990_onwards %&gt;% filter(genres %in% top_genres), \n       aes(x = startYear, y = cumulative_success, color = genres, group = genres)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Yearly Growth of Successful Movies - Top Genres (1990 Onwards)\",\n    x = \"Year\",\n    y = \"Cumulative Count of Successful Movies\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n# Plot 2: Middle-performing genres\nmiddle_genres_plot &lt;- ggplot(successful_movies_1990_onwards %&gt;% filter(genres %in% middle_genres), \n       aes(x = startYear, y = cumulative_success, color = genres, group = genres)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Yearly Growth of Successful Movies - Middle Genres (1990 Onwards)\",\n    x = \"Year\",\n    y = \"Cumulative Count of Successful Movies\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n# Plot 3: Lower-performing genres\nlower_genres_plot &lt;- ggplot(successful_movies_1990_onwards %&gt;% filter(genres %in% lower_genres), \n       aes(x = startYear, y = cumulative_success, color = genres, group = genres)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Yearly Growth of Successful Movies - Lower Genres (1990 Onwards)\",\n    x = \"Year\",\n    y = \"Cumulative Count of Successful Movies\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Display the plots\ntop_genres_plot\n\n\n\n\n\n\n\n\n\nShow Code\nmiddle_genres_plot\n\n\n\n\n\n\n\n\n\nShow Code\nlower_genres_plot"
  },
  {
    "objectID": "mini02.html#successes-since-2010",
    "href": "mini02.html#successes-since-2010",
    "title": "?var:course.short Mini-Project #02: The Business of Show Business",
    "section": "Successes Since 2010",
    "text": "Successes Since 2010\nDrama has produced the most successful movies since 2010, mainly because there are so many Drama films made. However, Drama doesn’t have the highest success rate, meaning that while there are a lot of Drama movies, individual films perform about the same as those in other genres.\nGenres like Thriller and Biography have fewer movies, but they tend to perform better on average. This means that while Drama dominates in terms of the total number of successful movies, its success comes from the quantity rather than the quality of each film.\nBased on your findings, select a genre for your next project. Note that you may wish to avoid an “oversatured” genre; you just need to make the argument that your proposal is a good investment, not necessarily the most studio-produced focus-grouped committee-designed generic satisfying choice, so feel free to lean in to your own artistic preferences, as long as you can make an argument for them.\n\nSuccessful Personnel in the Genre\nNow that you have selected a target genre, identify two actors and one director who will anchor your project. You want to identify key personnel who have worked in the genre before, with at least modest success, and who have at least one major success to their credit.\nAs you develop your team, you may want to consider the following possibilities:\n\nAn older established actor and an up-and-coming actor\nAn actor/director pair who have been successful together\nAn actor/director pair who are both highly successful but have never worked together\nA pair of established actors who have had success in many genres\n\nAs you select your key personnel, consider what IMDb says they are known for; this will be useful in developing your marketing materials.\n\n\n\n\n\n\nTask 5: Key Personnel\n\n\n\nIdentify (at least) two actors and one director who you will target as the key talent for your movie. Write a short “pitch” as to why they are likely to be successful. You should support your pitch with at least one graphic and one table.\n\n\n\n\nNostalgia and Remakes\nNow that you have found a target genre and key talent for your project, you need a story. Like any good development executive, your first instinct should be to produce a remake of a classic film in the genre.\n\n\n\n\n\n\nTask 6: Finding a Classic Movie to Remake\n\n\n\nFind a classic movie to remake with your key talent. The original should have a large number of IMDb ratings, a high average rating, and not have been remade in the past 25 years.4\nOnce you have found your classic movie to remake, confirm whether key actors, directors, or writers from the original are still alive. If so, you need to contact your legal department to ensure they can secure the rights to the project. You may also want to include the classic actors as “fan service.”"
  },
  {
    "objectID": "mini02.html#genre-successes-since-2010",
    "href": "mini02.html#genre-successes-since-2010",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "Genre Successes Since 2010",
    "text": "Genre Successes Since 2010\nSince 2010, Drama has produced the most successful movies, mainly due to the large number of productions in this genre. However, the success rate (average success per movie) for Drama is moderate, comparable to genres like Thriller and Biography.\nOn the other hand, Biography has fewer productions but a significantly higher success rate per movie. This means that, while there are fewer Biography films, they tend to perform better individually compared to Drama films.\nIn conclusion, while Drama leads in terms of the total number of successful movies, other genres like Biography and Thriller achieve higher success rates, indicating that the number of movies is not always reflective of individual success.\n\nWhat genre has become more popular in recent years?\n\n\n\nShow Code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define success threshold and filter the data for successful movies only\nthreshold_rating &lt;- 7.5\n\n# Updated valid genres list, now including \"Documentary\"\nvalid_genres &lt;- c(\"Action\", \"Adventure\", \"Animation\", \"Biography\", \"Comedy\", \n                  \"Crime\", \"Documentary\", \"Drama\", \"Family\", \"Fantasy\", \n                  \"Film-Noir\", \"History\", \"Horror\", \"Music\", \"Musical\", \n                  \"Mystery\", \"Romance\", \"Sci-Fi\", \"Sport\", \"Thriller\", \n                  \"War\", \"Western\")\n\n# Function to filter movies for the selected time period and valid genres\nfilter_movies &lt;- function(start_year, end_year) {\n  TITLE_BASICS %&gt;%\n    filter(titleType == \"movie\", !is.na(startYear), as.numeric(startYear) &gt;= start_year, as.numeric(startYear) &lt;= end_year) %&gt;%\n    inner_join(TITLE_RATINGS, by = \"tconst\") %&gt;%\n    separate_rows(genres, sep = \",\") %&gt;%\n    filter(genres %in% valid_genres)  # Filter valid genres\n}\n\n# Function to plot average success rate for each period\nplot_success_rate &lt;- function(period_name, start_year, end_year) {\n  successful_movies &lt;- filter_movies(start_year, end_year)\n  \n  # Calculate total number of movies and successful movies in each genre\n  genre_summary &lt;- successful_movies %&gt;%\n    group_by(genres) %&gt;%\n    summarize(total_movies = n(),\n              successful_movies = sum(averageRating &gt;= threshold_rating)) %&gt;%\n    mutate(success_rate = successful_movies / total_movies) %&gt;%\n    arrange(desc(success_rate)) %&gt;%\n    filter(total_movies &gt; 0) %&gt;%  # Ensure at least one movie in the genre\n    slice_head(n = 10)  # Select top 10 genres\n  \n  # Plot\n  ggplot(genre_summary, aes(x = reorder(genres, -success_rate), y = success_rate, fill = genres)) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = scales::percent(success_rate, accuracy = 0.1)), vjust = -0.5) +\n    labs(\n      title = paste(\"Average Success Rate for Top 10 Genres (\", period_name, \")\"),\n      x = \"Genres\",\n      y = \"Average Success Rate\"\n    ) +\n    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n    theme_minimal(base_size = 14) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n}\n\n# Periods to analyze\nperiods &lt;- list(\n  \"1900-1950\" = c(1900, 1950),\n  \"1950-1980\" = c(1950, 1980),\n  \"1980-2000\" = c(1980, 2000),\n  \"2000-2020\" = c(2000, 2020)\n)\n\n# Generate plots for all periods and display them\nfor (period_name in names(periods)) {\n  period &lt;- periods[[period_name]]\n  print(plot_success_rate(period_name, period[1], period[2]))\n}"
  },
  {
    "objectID": "mini02.html#to-1950",
    "href": "mini02.html#to-1950",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "1900 to 1950",
    "text": "1900 to 1950\nBetween 1900 and 1950, Animation (19.4%) and Documentary (18.6%) were the most successful genres. Audiences enjoyed both animated films and factual storytelling, showing a mix of entertainment and learning."
  },
  {
    "objectID": "mini02.html#to-1980",
    "href": "mini02.html#to-1980",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "1950 to 1980",
    "text": "1950 to 1980\nFrom 1950 to 1980, genres like Western (46.7%) and War (44.1%) were at the top. People were drawn to action-packed stories about the frontier and war, reflecting an era of adventure and heroism."
  },
  {
    "objectID": "mini02.html#to-2000",
    "href": "mini02.html#to-2000",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "1980 to 2000",
    "text": "1980 to 2000\nIn the 1980 to 2000 period, Documentary (39.9%) became the most successful, with History and Music also doing well. Audiences started to focus more on real-life stories and educational content."
  },
  {
    "objectID": "mini02.html#to-2020",
    "href": "mini02.html#to-2020",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "2000 to 2020",
    "text": "2000 to 2020\nBetween 2000 and 2020, Documentary (34.8%) and Biography (30.3%) continued to grow in popularity. These genres show a clear shift toward real-life and factual storytelling. On the other hand, Animation and Drama, which used to be popular, are now less successful."
  },
  {
    "objectID": "mini02.html#conclusion-which-genre-has-grown-in-popularity",
    "href": "mini02.html#conclusion-which-genre-has-grown-in-popularity",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "Conclusion: Which Genre Has Grown in Popularity?",
    "text": "Conclusion: Which Genre Has Grown in Popularity?\nIn recent years, Documentary and Biography have clearly become more popular, leading the success charts from 2000 to 2020. Audiences are showing a strong preference for content that tells real-world stories and explores real lives, while genres like Animation and Drama have seen a drop in success."
  },
  {
    "objectID": "mini02.html#task-choose-a-prestige-actor-or-director-and-confirm-that-they-have-many-projects-with-high-scores-on-your-success-metric.",
    "href": "mini02.html#task-choose-a-prestige-actor-or-director-and-confirm-that-they-have-many-projects-with-high-scores-on-your-success-metric.",
    "title": "?var:course.short Mini-Project #02: The Business of Show Business",
    "section": "Task: Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.",
    "text": "Task: Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\nFor this task, Milla Jovovich has been selected as the prestige actor. Below is a list of her top 5 movies based on the success metric (combining IMDb votes and ratings):\n\nThe Fifth Element | Votes: 515,828 | Rating: 7.6 | Success: 99.97\nDazed and Confused | Votes: 203,820 | Rating: 7.6 | Success: 92.91\nResident Evil | Votes: 293,614 | Rating: 6.6 | Success: 83.09\nZoolander | Votes: 298,411 | Rating: 6.5 | Success: 81.94\nResident Evil: Extinction | Votes: 207,893 | Rating: 6.2 | Success: 75.92\n\nMilla Jovovich has starred in a mix of action and comedy movies, proving her versatility and strength in the action genre."
  },
  {
    "objectID": "mini02.html#task-perform-at-least-one-other-form-of-spot-check-validation.",
    "href": "mini02.html#task-perform-at-least-one-other-form-of-spot-check-validation.",
    "title": "?var:course.short Mini-Project #02: The Business of Show Business",
    "section": "Task: Perform at least one other form of ‘spot check’ validation.",
    "text": "Task: Perform at least one other form of ‘spot check’ validation.\nTo further validate Milla Jovovich’s impact in action films, here’s a spot check of her Resident Evil movies, showcasing how these popular films performed:\n\nResident Evil | Rating: 6.6 | Votes: 293,614\nResident Evil: Apocalypse | Rating: 6.1 | Votes: 212,646\nResident Evil: Extinction | Rating: 6.2 | Votes: 207,893\nResident Evil: Afterlife | Rating: 5.8 | Votes: 181,137\nResident Evil: Retribution | Rating: 5.3 | Votes: 152,062\nResident Evil: The Final Chapter | Rating: 5.5 | Votes: 102,720\n\nThe Resident Evil series showcases Milla’s consistent presence in high-action roles, with a strong fan base despite varying ratings. This confirms her staying power in the genre.\n\n\nCome up with a numerical threshold for a project to be a ‘success’; that is, determine a value \\(v\\) such that movies above \\(v\\) are all “solid” or better.\n\n\n\nShow Code\n# Step 1: Define a numerical threshold for success\nthreshold_rating &lt;- 7.5  # Movies with ratings 7.5 and above\nthreshold_votes &lt;- 100000  # Movies with at least 100,000 votes\n\n# Step 2: Join with TITLE_BASICS and filter for highly rated movies based on thresholds\nsolid_movies &lt;- TITLE_RATINGS |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  filter(averageRating &gt;= threshold_rating, numVotes &gt;= threshold_votes) |&gt;  \n  select(primaryTitle, averageRating, numVotes) |&gt;\n  slice_head(n = 10)  # Get the top 10 movies\n\n# Step 3: Display the top solid movies\ncat(\"Top 10 solid movies (IMDb rating &gt;= \", threshold_rating, \" and votes &gt;= \", threshold_votes, \"):\\n\", sep = \"\")\n\n\nTop 10 solid movies (IMDb rating &gt;= 7.5 and votes &gt;= 1e+05):\n\n\nShow Code\nfor (i in 1:nrow(solid_movies)) {\n  cat(i, \". \", solid_movies$primaryTitle[i], \n      \" | Rating: \", solid_movies$averageRating[i], \n      \" | Votes: \", solid_movies$numVotes[i], \"\\n\", sep = \"\")\n}\n\n\n1. The Kid | Rating: 8.2 | Votes: 137306\n2. Nosferatu: A Symphony of Horror | Rating: 7.8 | Votes: 108133\n3. The Gold Rush | Rating: 8.1 | Votes: 120482\n4. Metropolis | Rating: 8.3 | Votes: 188795\n5. City Lights | Rating: 8.5 | Votes: 199528\n6. M | Rating: 8.3 | Votes: 171568\n7. It Happened One Night | Rating: 8.1 | Votes: 114467\n8. Modern Times | Rating: 8.5 | Votes: 264133\n9. Snow White and the Seven Dwarfs | Rating: 7.6 | Votes: 219387\n10. Gone with the Wind | Rating: 8.2 | Votes: 338994\n\n\n\n\nShow Code\n# Check if the dataset exists and show the structure of the dataset"
  },
  {
    "objectID": "mini03_files/mini03.html",
    "href": "mini03_files/mini03.html",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "Welcome to Mini-Project #03! In this project, you will write a political fact-check, that most iconic form of our current journalistic era. Specifically, you will investigate the claim that the US Electoral College systematically biases election results away from the vox populi. As you dive in to the world of political data, we’ll also learn a bit more about the mechanics of US federal elections.\nIn this Mini-Project, you will:\n\nIntegrate data from disparate governmental and academic sources\nLearn to work with spatial data formats\nCreate many plots\nUse spatial and animated visualizations to make your argument\n\nNote that - as with all these mini-projects - there isn’t a single “right” answer to the questions posed herein. You may have different views about the relative importance of federalism, direct democratic structures, adherence to the formal structures of the US Constitution, etc. than your classmates. Please make sure to make your argument respectfully and, when we reach the peer-evaluation stage, read and comment respectfully. All grading will be done solely on the quality of the code, the writing, the visualizations, and the argument - not on the political implications of what you may or may not find.\nAlso note that this mini-project is intended to be markedly less demanding than Mini-Project #02. At this point in the course, you should be diving into your Course Project, which should consume the majority of your out-of-class time dedicated to this course for the remainder of the semester."
  },
  {
    "objectID": "mini03_files/mini03.html#introduction",
    "href": "mini03_files/mini03.html#introduction",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "Welcome to Mini-Project #03! In this project, you will write a political fact-check, that most iconic form of our current journalistic era. Specifically, you will investigate the claim that the US Electoral College systematically biases election results away from the vox populi. As you dive in to the world of political data, we’ll also learn a bit more about the mechanics of US federal elections.\nIn this Mini-Project, you will:\n\nIntegrate data from disparate governmental and academic sources\nLearn to work with spatial data formats\nCreate many plots\nUse spatial and animated visualizations to make your argument\n\nNote that - as with all these mini-projects - there isn’t a single “right” answer to the questions posed herein. You may have different views about the relative importance of federalism, direct democratic structures, adherence to the formal structures of the US Constitution, etc. than your classmates. Please make sure to make your argument respectfully and, when we reach the peer-evaluation stage, read and comment respectfully. All grading will be done solely on the quality of the code, the writing, the visualizations, and the argument - not on the political implications of what you may or may not find.\nAlso note that this mini-project is intended to be markedly less demanding than Mini-Project #02. At this point in the course, you should be diving into your Course Project, which should consume the majority of your out-of-class time dedicated to this course for the remainder of the semester."
  },
  {
    "objectID": "mini03_files/mini03.html#background",
    "href": "mini03_files/mini03.html#background",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Background",
    "text": "Background\nThe US Constitution sets the basic rules of electing the President in Section 1 of Article II, which we quote here in part:\n\nEach State shall appoint, in such Manner as the Legislature thereof may direct, a Number of Electors, equal to the whole Number of Senators and Representatives to which the State may be entitled in the Congress: but no Senator or Representative, or Person holding an Office of Trust or Profit under the United States, shall be appointed an Elector.\nThe Electors shall meet in their respective States, and vote by Ballot for two Persons, of whom one at least shall not be an Inhabitant of the same State with themselves. And they shall make a List of all the Persons voted for, and of the Number of Votes for each; which List they shall sign and certify, and transmit sealed to the Seat of the Government of the United States, directed to the President of the Senate. The President of the Senate shall, in the Presence of the Senate and House of Representatives, open all the Certificates, and the Votes shall then be counted. The Person having the greatest Number of Votes shall be the President, if such Number be a Majority of the whole Number of Electors appointed; and if there be more than one who have such Majority, and have an equal Number of Votes, then the House of Representatives shall immediately chuse by Ballot one of them for President; and if no Person have a Majority, then from the five highest on the List the said House shall in like Manner chuse the President. But in chusing the President, the Votes shall be taken by States, the Representation from each State having one Vote; A quorum for this Purpose shall consist of a Member or Members from two thirds of the States, and a Majority of all the States shall be necessary to a Choice. In every Case, after the Choice of the President, the Person having the greatest Number of Votes of the Electors shall be the Vice President. But if there should remain two or more who have equal Votes, the Senate shall chuse from them by Ballot the Vice President.\n\nThough the details have varied over time due to amendment, statue, and technology, this basic outline of this allocation scheme remains unchanged:\n\nEach state gets \\(R + 2\\) electoral college votes, where \\(R\\) is the number of Representatives that state has in the US House of Representatives\nStates can allocate those votes however they wish\nThe president is the candidate who receives a majority of electoral college votes\n\nNotably, the Constitution sets essentially no rules on how the \\(R + 2\\) electoral college votes (ECVs) for a particular state are allocated. At different points in history, different states have elected to use each of the following:\n\nDirect allocation of ECVs by state legislature (no vote)\nAllocation of all ECVs to winner of state-wide popular vote\nAllocation of all ECVs to winner of nation-wide popular vote\nAllocation of \\(R\\) ECVs to popular vote winner by congressional district + allocation of remaining \\(2\\) ECVs to the state-wide popular vote winner\n\nCurrently, only Maine and Nebraska use the final option; the other 48 states and the District of Columbia award all \\(R+2\\) ECVs to the winner of their state-wide popular vote. We emphasize here that “statewide winner-take-all” is a choice made by the individual states, not dictated by the US constitution, and that states have the power to change it should they wish.1\nTo my knowledge, no US state uses true proportionate state-wide representation, though I believe such a ECV-allocation scheme would be consistent with the US Constitution. For example, if a state with 5 ECVs had 60,000 votes for Candidate A and 40,000 cast for Candidate B, it could award 3 ECVs to A and 2 to B, regardless of the spatial distribution of those votes within the state."
  },
  {
    "objectID": "mini03_files/mini03.html#mini-project-objectives",
    "href": "mini03_files/mini03.html#mini-project-objectives",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Mini-Project Objectives",
    "text": "Mini-Project Objectives\nIn this project, you will use historical congressional election data to see how the outcome of US presidential elections would have changed under different allocation rules. Like any retrodiction2 task, this analysis has limitations. Notably, if the “rules” had been different, politicians may have run different campaigns and received different vote counts. Still, it is my hope that this is an interesting and informative exercise.\nAs noted above, your final submission should take the form of a “Fact Check”:\n\nTake a statement from a well-known politician or political commentator describing (claimed) bias of the electoral college system\nAnalyze presidential election results under different allocations for presence or abscence of bias (however you define it - see below)\nSummarize your retrodictive findings\nAward a “truthfulness” score to the claim you evaluated. (You may use the scale of an existing political fact-check operation or create your own.)"
  },
  {
    "objectID": "mini03_files/mini03.html#student-responsbilities",
    "href": "mini03_files/mini03.html#student-responsbilities",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Student Responsbilities",
    "text": "Student Responsbilities\nRecall our basic analytic workflow and table of student responsibilities:\n\nData Ingest and Cleaning: Given a single data source, read it into R and transform it to a reasonably useful standardized format.\nData Combination and Alignment: Combine multiple data sources to enable insights not possible from a single source.\nDescriptive Statistical Analysis: Take a data table and compute informative summary statistics from both the entire population and relevant subgroups\nData Visualization: Generate insightful data visualizations to spur insights not attainable from point statistics\nInferential Statistical Analysis and Modeling: Develop relevant predictive models and statistical analyses to generate insights about the underlying population and not simply the data at hand.\n\n\nStudents’ Responsibilities in Mini-Project Analyses\n\n\n\n\n\n\n\n\n\n\nIngest and Cleaning\nCombination and Alignment\nDescriptive Statistical Analysis\nVisualization\n\n\n\n\nMini-Project #01\n\n\n✓\n\n\n\nMini-Project #02\n\n✓\n✓\n½\n\n\nMini-Project #03\n½\n✓\n✓\n✓\n\n\nMini-Project #04\n✓\n✓\n✓\n✓\n\n\n\nIn this mini-project, you will be working with relatively “clean” electoral data and your main focus should be on the analysis and visualization supporting your fact check. As an analysis of political data, I expect your final submission to have quite a few “red state/blue state” maps.3 Data cleaning and import will play a larger role in Mini-Project #04.\nIn this project, I am no longer providing code to download and read the necessary data files. The data files I have selected for this mini-project are relatively easy to work with and should not provide a significant challenge, particularly after our in-class discussion of Data Import. See the modified rubric below which now includes a grade for data import.\n\nRubric\n?var:course.short Mini-Projects are evaluated using peer grading with meta-review by the course GTAs. Specifically, variants of the following rubric will be used for the mini-projects:\n\nMini-Project Grading Rubric\n\n\n\n\n\n\n\n\n\n\n\nCourse Element\nExcellent (9-10)\nGreat (7-8)\nGood (5-6)\nAdequate (3-4)\nNeeds Improvement (1-2)\nExtra Credit\n\n\n\n\nWritten Communication\nReport is well-written and flows naturally. Motivation for key steps is clearly explained to reader without excessive detail. Key findings are highlighted and appropriately given context.\nReport has no grammatical or writing issues. Writing is accessible and flows naturally. Key findings are highlighted, but lack suitable motivation and context.\nReport has no grammatical or writing issues. Key findings are present but insufficiently highlighted.\nWriting is intelligible, but has some grammatical errors. Key findings are obscured.\nReport exhibits significant weakness in written communication. Key points are difficult to discern.\nReport includes extra context beyond instructor provided information.\n\n\nProject Skeleton\nCode completes all instructor-provided tasks correctly. Responses to open-ended tasks are particularly insightful and creative.\nCode completes all instructor-provided tasks satisfactorially.\nResponse to one instructor provided task is skipped, incorrect, or otherwise incomplete.\nResponses to two instructor provided tasks are skipped, incorrect, or otherwise incomplete.\nResponse to three or ore instructor provided tasks are skipped, incorrect, or otherwise incomplete.\nReport exhibits particularly creative insights drawn from thorough student-initiated analyses.\n\n\nFormatting & Display\nTables and figures are full ‘publication-quality’.\nReport includes at least one animated visualization designed to effectively communicate findings.\nTables have well-formatted column names, suitable numbers of digits, and attractive presentation.\nFigures are ‘publication-quality’, with suitable axis labels, well-chosen structure, attractive color schemes, titles, subtitles, and captions, etc.\nTables are well-formatted, but still have room for improvement.\nFigures are above ‘exploratory-quality’, but do not reach full ‘publication-quality’.\nTables lack significant ‘polish’ and need improvement in substance (filtering and down-selecting of presented data) or style.\nFigures are suitable to support claims made, but are ‘exploratory-quality’, reflecting minimal effort to customize and ‘polish’ beyond ggplot2 defaults.\nUnfiltered ‘data dump’ instead of curated table.\nBaseline figures that do not fully support claims made.\nReport includes interactive (not just animated) visual elements.\n\n\nCode Quality\nCode is (near) flawless.\nCode passes all styler and lintr type analyses without issue.\nComments give context of the analysis, not simply defining functions used in a particular line.\nCode has well-chosen variable names and basic comments.\nCode executes properly, but is difficult to read.\nCode fails to execute properly.\nCode takes advantage of advanced Quarto features to improve presentation of results.\n\n\nData Preparation\nData import is fully-automated and efficient, taking care to only download from web-sources if not available locally.\nData is imported and prepared effectively, in an automated fashion with minimal hard-coding of URLs and file paths.\nData is imported and prepared effectively, though source and destination file names are hard-coded.\nData is imported in a manner likely to have errors.\nData is hard-coded and not imported from an external source.\nReport uses additional data sources in a way that creates novel insights.\n\n\n\nNote that this rubric is designed with copious opportunities for extra credit if students go above and beyond the instructor-provided scaffolding. Students pursuing careers in data analytics are strongly encouraged to go beyond the strict ambit of the mini-projects to i) further refine their skills; ii) learn additional techniques that can be used in the final course project; and iii) develop a more impressive professional portfolio.\nBecause students are encouraged to use ?var:course.short mini-projects as the basis for a professional portfolio, the basic skeleton of each project will be released under a fairly permissive usage license. Take advantage of it!\nOnce the submission deadline passes, the instructor will tag classmates for peer feedback in this issue thread.\nAdditionally, a PDF export of this report should be submitted on Brightspace. To create a PDF from the uploaded report, simply use your browser’s ‘Print to PDF’ functionality.\nNB: The analysis outline below specifies key tasks you need to perform within your write up. Your peer evaluators will check that you complete these. You are encouraged to do extra analysis, but the bolded Tasks are mandatory.\nNB: Your final submission should look like a report, not simply a list of facts answering questions. Add introductions, conclusions, and your own commentary. You should be practicing both raw coding skills and written communication in all mini-projects. There is little value in data points stated without context or motivation."
  },
  {
    "objectID": "mini03_files/mini03.html#set-up-and-initial-exploration",
    "href": "mini03_files/mini03.html#set-up-and-initial-exploration",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Set-Up and Initial Exploration",
    "text": "Set-Up and Initial Exploration\n\nData I: US House Election Votes from 1976 to 2022\nThe MIT Election Data Science Lab collects votes from all biennial congressional races in all 50 states here. Download this data as a CSV file using your web browser. Note that you will need to provide your contact info and agree to cite this data set in your final report.4 Make sure to include this citation!\nAdditionally, download statewide presidential vote counts from 1976 to 2022 here. As before, it will likely be easiest to download this data by hand using your web browser.\n\n\nData II: Congressional Boundary Files 1976 to 2012\nJeffrey B. Lewis, Brandon DeVine, Lincoln Pritcher, and Kenneth C. Martis have created shapefiles for all US congressional districts from 1789 to 2012; they generously make these available here.\n\n\n\n\n\n\nTask 1: Download Congressional Shapefiles 1976-2012\n\n\n\nDownload congressional shapefiles from Lewis et al. for all US Congresses5 from 1976 to 2012.\nYour download code should:\n\nBe fully automated (no “hand-downloading”);\nDownload files with a systematic and interpretable naming convention\nOnly download files as needed out of courtesy for the data provider’s web sever. That is, if you already have a copy of the file, do not re-download it repeatedly.\n\nAs with the other Mini-Projects, make sure you do not store these data files in git. It will be sufficient to include the qmd file with the download code.\n\n\nNote that the shape files are distributed as zip folders, containing several files in a directory structure. We will be interested in the shp files within each zip.\n\n\nData III: Congressional Boundary Files 2014 to Present\nTo get district boundaries for more recent congressional elections, we can turn to the US Census Bureau. Unfortunately, these data - while authoritative and highly detailed - are not in quite the same format as our previous congressional boundary files. We can review the US Census Bureau shapefiles online. To download them automatically, I recommend exploring the FTP Archive link near the bottom of the page. In Census-jargon, the CD directory will have shapefiles for Congressional Districts for each year.6\n\n\n\n\n\n\nTask 2: Download Congressional Shapefiles 1976-2012\n\n\n\nDownload congressional shapefiles from the US Census Bureau for all US Congresses from 2014 to 2024.\nYour download code should:\n\nBe fully automated (no “hand-downloading”);\nDownload files with a systematic and interpretable naming convention\nOnly download files as needed out of courtesy for the data provider’s web sever. That is, if you already have a copy of the file, do not re-download it repeatedly.\n\nAs with the other Mini-Projects, make sure you do not store these data files in git. It will be sufficient to include the qmd file with the download code.\n\n\n\n\nInitial Exploration of Vote Count Data\n\n\n\n\n\n\nTask 3: Exploration of Vote Count Data\n\n\n\nAnswer the following using the vote count data files from the MIT Election Data Science Lab. You may answer each with a table or plot as you feel is appropriate.\n\nWhich states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\nNew York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).\nAre there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\nDo presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\nDoes this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n\n\n\n\nImporting and Plotting Shape File Data\nAs mentioned above, the shape files you downloaded above are distributed in zip archives, with several files. We only need the shp file within each archive. In this section, we’ll practice extracting the shp file, reading it, and using it to create a plot. The key library we need is the sf (“simple features”) library. It provides the read_sf() function which we can use to read it into R. I download how this works below:\n\nlibrary(ggplot2)\nlibrary(sf)\n\nLinking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.3.1; sf_use_s2() is TRUE\n\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\", \n              method=\"curl\")\n}\n\n##-\ntd &lt;- tempdir(); \nzip_contents &lt;- unzip(\"nyc_borough_boundaries.zip\", \n                      exdir = td)\n    \nfname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\nnyc_sf &lt;- read_sf(fname_shp)\nnyc_sf\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 5\n  boro_code boro_name      shape_area shape_leng                        geometry\n      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;              &lt;MULTIPOLYGON [°]&gt;\n1         3 Brooklyn      1934142776.    728147. (((-73.86327 40.58388, -73.863…\n2         5 Staten Island 1623618684.    325910. (((-74.05051 40.56642, -74.050…\n3         1 Manhattan      636646082.    360038. (((-74.01093 40.68449, -74.011…\n4         2 Bronx         1187174772.    463181. (((-73.89681 40.79581, -73.896…\n5         4 Queens        3041418004.    888197. (((-73.82645 40.59053, -73.826…\n\n\n\n\n\n\n\n\nTask 4: Automate Zip File Extraction\n\n\n\nAdapt the code after the ##- symbol above into a function read_shp_from_zip() which takes in a file name, pulls out the .shp file contained there in, and reads it into R using read_sf().\n\n\nThe result of this is a particular sort of data frame. The most important column for us is the geometry column which is of type MULTIPOLYGON. This is, essentially, a list of GPS coordinates which outline a spatial region. Here, each row corresponds to a Borough of NYC. We can pass the geometry column to ggplot2 to make a map:\n\nggplot(nyc_sf, \n       aes(geometry=geometry)) + \n    geom_sf()\n\n\n\n\n\n\n\n\nHere, we use the sf geom to get the shape outlines. The sf geom plays well with the fill aesthetic.\n\nggplot(nyc_sf, \n       aes(geometry=geometry, \n           fill = shape_area)) + \n    geom_sf()\n\n\n\n\n\n\n\n\nThis type of plot is called a Chloropleth Map and it is commonly used to depict election results.\n\n\n\n\n\n\nTask 5: Chloropleth Visualization of 2000 Electoral College Results\n\n\n\nUsing the data you downloaded earlier, create a chloropleth visualization of the 2000 electoral college results, coloring each state by the party that won the most votes in that state. Your result should look something like this:\n\nTaken from Wikipedia\nIt is not required, but to make the very best plot, you may want to look up:\n\nHow to “inset” Alaska and Hawaii instead of plotitng their true map locations.\nHow to add labels to a chloropleth in ggplot2\nHow to label the small states in the North-East\n\nbut these steps are not required as they are a bit advanced.\n\n\n\n\n\n\n\n\nTask 6: Advanced Chloropleth Visualization of Electoral College Results\n\n\n\nModify your previous code to make either an animated version showing election results over time.\n\n\nThe following example may be useful for you:\n\nlibrary(gganimate)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#| label: \"chloropleth_animated_example\"\n#| cache: true\n## Animated Chloropleth using gganimate\n\n## Add some time \"structure\" to our data for \n## demonstration purposes only\nnyc_sf_repeats &lt;- bind_rows(\n    nyc_sf |&gt; mutate(value = rnorm(5), \n                     frame = 1), \n    nyc_sf |&gt; mutate(value = rnorm(5), \n                     frame = 2), \n    nyc_sf |&gt; mutate(value = rnorm(5), \n                     frame = 3), \n    nyc_sf |&gt; mutate(value = rnorm(5), \n                     frame = 4), \n    nyc_sf |&gt; mutate(value = rnorm(5), \n                     frame = 5))\n\nlibrary(gganimate)\nggplot(nyc_sf_repeats, \n       aes(geometry=geometry, \n           fill = value)) + \n    geom_sf() + \n    transition_time(frame)\n\n\n\n\n\n\n\n\nNow that we have finished exploring our data and building some tools for plots, we are ready to dig into our main question."
  },
  {
    "objectID": "mini03_files/mini03.html#comparing-the-effects-of-ecv-allocation-rules",
    "href": "mini03_files/mini03.html#comparing-the-effects-of-ecv-allocation-rules",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Comparing the Effects of ECV Allocation Rules",
    "text": "Comparing the Effects of ECV Allocation Rules\nGo through the historical voting data and assign each state’s ECVs according to various strategies:\n\nState-Wide Winner-Take-All\nDistrict-Wide Winner-Take-All + State-Wide “At Large” Votes\nState-Wide Proportional\nNational Proportional\n\nBased on these allocation strategies, compare the winning presidential candidate with the actual historical winner.\nWhat patterns do you see? Are the results generally consistent or are one or more methods systematically more favorable to one party?\nFor the district-level winner-take-all, you may assume that the presidential candidate of the same party as the congressional representative wins that election.\n\n\n\n\n\n\nTask 7: Evaluating Fairness of ECV Allocation Schemes\n\n\n\nWrite a fact check evaluating the fairness of the different ECV electoral allocation schemes.\nTo do so, you should first determine which allocation scheme you consider “fairest”. You should then see which schemes give different results, if they ever do. To make your fact check more compelling, select one election where the ECV scheme had the largest impact–if one exists–and explain how the results would have been different under a different ECV scheme.\nAs you perform your analysis, you may assume that the District of Columbia has three ECVs, which are allocated to the Democratic candidate under all schemes except possibly national popular vote.7\n\n\nThroughout all of this, note that we are not varying the \\(R+2\\) ECV allocation scheme specified by the constitution. Our concern here is only what individual states can do to address “fairness” in presidential elections. If we allow the possibility of constitutional amendment, the possibilities are endless. The \\(R+2\\) rule has several interesting effects; some are well-known, such as the Senate’s equal treatment of small and large states, while others are less well-known, including the fact that congressional representation is based on population, not counts of voters.8"
  },
  {
    "objectID": "mini03_files/mini03.html#extra-credit-opportunity",
    "href": "mini03_files/mini03.html#extra-credit-opportunity",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Extra Credit Opportunity",
    "text": "Extra Credit Opportunity\n\n\n\n\n\n\nExtra Credit Opportunity\n\n\n\nFor extra credit, extend your analysis to 2024 electoral results. You will have to find a reliable source of 2024 state- or district-wide vote counts. If the 2024 election is close, this may not be easy to do between the election and the date this mini-project is due.\n\n\n\nThis work ©2024 by Michael Weylandt is licensed under a Creative Commons BY-NC-SA 4.0 license."
  },
  {
    "objectID": "mini03_files/mini03.html#footnotes",
    "href": "mini03_files/mini03.html#footnotes",
    "title": "?var:course.short Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI am not aware of “official” reasons from any state on why they select “winner-take-all” allocation. States clearly compete for attention in presidential elections and it seems reasonable to assume that competitive states select “winner-take-all” allocation to attract presidential candidates who will make promises to that state’s voters. By contrast, states whose legislature is dominated by a single party, e.g., New York, may be motivated to award all their votes to the more popular party in that state, denying any ECVs to the other candidate, even if a sizeable minority votes for them. If you find a history of how states select their ECV allocation strategies, I would be interested in reading it.↩︎\nMaking predictions about a counter-factual past.↩︎\nHistorically, the “Republicans Red / Democrats Blue” convention was not particularly strong in American journalism. It become standardized during coverage of the 2000 Presidential Election and subsequent Florida recount battles and has not materially changed since. For purposes of this mini-project, we will apply “Republican Red / Democrat Blue” consistently.↩︎\nWhile it may be possible to automate the browser to automatically fill in this pop-up as part of the download process, that’s beyond the scope of this assignment.↩︎\nIt may be useful to recall that each two year cycle is called “a congress” for district mapping purposes. The 2022 US Election, selecting Representatives to serve 2023-2025, corresponds to the 118th Congress. The upcoming (November 2024) election will select members for the 119th Congress.↩︎\nThe other shapefiles in this FTP archive may be useful for your final projects.↩︎\nThe District of Columbia is very Democratic.↩︎\nThis latter effect is admittedly quite small if we assume political affiliation is unrelated to probability of voting. The relationship between voting likelihood and political leanings is an important one for campaign strategists and actively debated by academics.↩︎"
  },
  {
    "objectID": "Hw mini 03.html",
    "href": "Hw mini 03.html",
    "title": "My Quarto Analysis",
    "section": "",
    "text": "This is a sample Quarto document created in a text editor.\n#| label: setup #| echo: true library(ggplot2)"
  },
  {
    "objectID": "Hw mini 03.html#introduction",
    "href": "Hw mini 03.html#introduction",
    "title": "My Quarto Analysis",
    "section": "",
    "text": "This is a sample Quarto document created in a text editor.\n#| label: setup #| echo: true library(ggplot2)"
  },
  {
    "objectID": "Hw mini 03.html#task-1-download-congressional-shapefiles-1976-2012",
    "href": "Hw mini 03.html#task-1-download-congressional-shapefiles-1976-2012",
    "title": "Congressional and Election Data Analysis",
    "section": "Task 1: Download Congressional Shapefiles 1976-2012",
    "text": "Task 1: Download Congressional Shapefiles 1976-2012\n\n# Define download function for 1976–2012 congressional shapefiles\ndownload_congress_shapefiles &lt;- function(start_congress, end_congress, base_url, output_dir) {\n  if (!dir.exists(output_dir)) dir.create(output_dir)\n  \n  for (congress_num in start_congress:end_congress) {\n    zip_filename &lt;- file.path(output_dir, sprintf(\"congress_%03d.zip\", congress_num))\n    shapefile_dir &lt;- file.path(output_dir, sprintf(\"congress_%03d\", congress_num))\n    \n    # Skip if already downloaded\n    if (dir.exists(shapefile_dir)) {\n      message(sprintf(\"Congress %d shapefiles already downloaded.\", congress_num))\n      next\n    }\n    \n    # Download and unzip\n    url &lt;- sprintf(base_url, congress_num)\n    response &lt;- httr::GET(url)\n    \n    if (httr::status_code(response) == 200) {\n      writeBin(httr::content(response, \"raw\"), zip_filename)\n      unzip(zip_filename, exdir = shapefile_dir)\n      message(sprintf(\"Downloaded and extracted shapefiles for Congress %d.\", congress_num))\n    } else {\n      warning(sprintf(\"Failed to download Congress %d data.\", congress_num))\n    }\n  }\n}\n\n# Set parameters and call function\ndownload_congress_shapefiles(\n  start_congress = 94,\n  end_congress = 112,\n  base_url = \"https://cdmaps.polisci.ucla.edu/shp/districts%03d.zip\",\n  output_dir = \"congress_shapefiles\"\n)\n\nCongress 94 shapefiles already downloaded.\n\n\nCongress 95 shapefiles already downloaded.\n\n\nCongress 96 shapefiles already downloaded.\n\n\nCongress 97 shapefiles already downloaded.\n\n\nCongress 98 shapefiles already downloaded.\n\n\nCongress 99 shapefiles already downloaded.\n\n\nCongress 100 shapefiles already downloaded.\n\n\nCongress 101 shapefiles already downloaded.\n\n\nCongress 102 shapefiles already downloaded.\n\n\nCongress 103 shapefiles already downloaded.\n\n\nCongress 104 shapefiles already downloaded.\n\n\nCongress 105 shapefiles already downloaded.\n\n\nCongress 106 shapefiles already downloaded.\n\n\nCongress 107 shapefiles already downloaded.\n\n\nCongress 108 shapefiles already downloaded.\n\n\nCongress 109 shapefiles already downloaded.\n\n\nCongress 110 shapefiles already downloaded.\n\n\nCongress 111 shapefiles already downloaded.\n\n\nCongress 112 shapefiles already downloaded.\n\n\n\n# Load required package\nif (!requireNamespace(\"httr\", quietly = TRUE)) install.packages(\"httr\")\nif (!requireNamespace(\"utils\", quietly = TRUE)) install.packages(\"utils\")\n\n# Define download function for 1976–2012 congressional shapefiles\ndownload_congress_shapefiles &lt;- function(start_congress, end_congress, base_url, output_dir) {\n  # Create the output directory if it doesn't exist\n  if (!dir.exists(output_dir)) dir.create(output_dir)\n  \n  for (congress_num in start_congress:end_congress) {\n    zip_filename &lt;- file.path(output_dir, sprintf(\"congress_%03d.zip\", congress_num))\n    shapefile_dir &lt;- file.path(output_dir, sprintf(\"congress_%03d\", congress_num))\n    \n    # Skip if shapefiles are already downloaded\n    if (dir.exists(shapefile_dir)) {\n      message(sprintf(\"Congress %d shapefiles already downloaded.\", congress_num))\n      next\n    }\n    \n    # Construct the download URL\n    url &lt;- sprintf(base_url, congress_num)\n    message(sprintf(\"Attempting to download shapefiles for Congress %d...\", congress_num))\n    \n    # Make the GET request to download the file\n    response &lt;- httr::GET(url)\n    \n    if (httr::status_code(response) == 200) {\n      # Save the zip file and extract it\n      writeBin(httr::content(response, \"raw\"), zip_filename)\n      unzip(zip_filename, exdir = shapefile_dir)\n      message(sprintf(\"Downloaded and extracted shapefiles for Congress %d.\", congress_num))\n      \n      # Optionally delete the zip file after extraction to save space\n      file.remove(zip_filename)\n    } else {\n      warning(sprintf(\"Failed to download Congress %d data. Status code: %d\", congress_num, httr::status_code(response)))\n    }\n  }\n}\n\n# Set parameters and call the function to download only missing files (Congress 104 to 112)\ndownload_congress_shapefiles(\n  start_congress = 104,\n  end_congress = 112,\n  base_url = \"https://cdmaps.polisci.ucla.edu/shp/districts%03d.zip\",\n  output_dir = \"congress_shapefiles\"\n)\n\nCongress 104 shapefiles already downloaded.\n\n\nCongress 105 shapefiles already downloaded.\n\n\nCongress 106 shapefiles already downloaded.\n\n\nCongress 107 shapefiles already downloaded.\n\n\nCongress 108 shapefiles already downloaded.\n\n\nCongress 109 shapefiles already downloaded.\n\n\nCongress 110 shapefiles already downloaded.\n\n\nCongress 111 shapefiles already downloaded.\n\n\nCongress 112 shapefiles already downloaded."
  },
  {
    "objectID": "Hw mini 03.html#task-2-download-congressional-shapefiles-2014-2022",
    "href": "Hw mini 03.html#task-2-download-congressional-shapefiles-2014-2022",
    "title": "Congressional and Election Data Analysis",
    "section": "Task 2: Download Congressional Shapefiles 2014-2022",
    "text": "Task 2: Download Congressional Shapefiles 2014-2022\n\n# Define years and state FIPS codes\nyears &lt;- c(2014, 2016, 2018, 2020, 2022)\nstate_codes &lt;- sprintf(\"%02d\", 1:56)  # Generate FIPS codes from 01 to 56\n\n# Base URL for the Census Bureau's TIGER/Line FTP archive\nbase_url &lt;- \"https://ftp2.census.gov/geo/tiger/TIGER%s/CD/\"\n\n# Define output directory for shapefiles\noutput_dir &lt;- \"census_congressional_shapefiles\"\nif (!dir.exists(output_dir)) dir.create(output_dir)\n\n# Function to download and extract shapefiles by year and state\ndownload_census_shapefiles &lt;- function(year, state_code) {\n  url &lt;- sprintf(\"%s/tl_%s_%s_cd.zip\", sprintf(base_url, year), year, state_code)\n  zip_filename &lt;- file.path(output_dir, sprintf(\"cd_%s_%s.zip\", year, state_code))\n  shapefile_dir &lt;- file.path(output_dir, sprintf(\"cd_%s_%s\", year, state_code))\n  \n  # Skip if already downloaded\n  if (dir.exists(shapefile_dir)) {\n    message(sprintf(\"Shapefiles for %s %s already downloaded.\", year, state_code))\n    return(NULL)\n  }\n  \n  # Download the ZIP file\n  response &lt;- GET(url)\n  \n  # Check if download was successful\n  if (status_code(response) == 200) {\n    writeBin(content(response, \"raw\"), zip_filename)\n    \n    # Extract only the .shp file\n    temp_dir &lt;- tempdir()\n    zip_contents &lt;- unzip(zip_filename, exdir = temp_dir)\n    shp_file &lt;- zip_contents[grepl(\"\\\\.shp$\", zip_contents)]\n    \n    # Create target directory and move .shp file\n    if (length(shp_file) &gt; 0) {\n      dir.create(shapefile_dir, showWarnings = FALSE)\n      file.copy(shp_file, shapefile_dir)\n      message(sprintf(\"Downloaded and extracted shapefiles for year %s and state %s.\", year, state_code))\n    } else {\n      warning(\"No .shp file found in ZIP archive for year \", year, \" and state \", state_code)\n    }\n  } else {\n    warning(sprintf(\"Failed to download data for year %s and state %s.\", year, state_code))\n  }\n}\n\n# Loop over each year and state\nfor (year in years) {\n  for (state_code in state_codes) {\n    download_census_shapefiles(year, state_code)\n  }\n}\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 56"
  },
  {
    "objectID": "Hw mini 03.html#task-3-exploration-of-vote-count-data",
    "href": "Hw mini 03.html#task-3-exploration-of-vote-count-data",
    "title": "Congressional and Election Data Analysis",
    "section": "Task 3: Exploration of Vote Count Data",
    "text": "Task 3: Exploration of Vote Count Data\nAnswer the following questions using the vote count data files from the MIT Election Data Science Lab.\n\nIdentify states that have gained and lost the most seats in the US House of Representatives between 1976 and 2022.\nInvestigate instances of “fusion” voting systems, especially in New York, to see if any election outcomes would differ without fusion voting.\nCompare presidential and congressional candidate performance within states and over time, looking at trends in party support.\n\n\n# Load a sample shapefile, e.g., for Alabama in 2014 (replace \"filename.shp\" with actual filename)\nsample_shapefile &lt;- file.path(output_dir, \"cd_2014_01\", \"filename.shp\")\n\nif (file.exists(sample_shapefile)) {\n  sample_data &lt;- st_read(sample_shapefile)\n  print(sample_data)\n  plot(st_geometry(sample_data))\n} else {\n  warning(\"Sample shapefile not found. Check if download completed successfully.\")\n}\n\nWarning: Sample shapefile not found. Check if download completed successfully.\n\n# Example code to load and summarize house_votes and presidential_votes data:\nhead(house_votes)\n\n# A tibble: 6 × 20\n   year state   state_po state_fips state_cen state_ic office   district stage\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;\n1  1976 ALABAMA AL                1        63       41 US HOUSE        1 GEN  \n2  1976 ALABAMA AL                1        63       41 US HOUSE        1 GEN  \n3  1976 ALABAMA AL                1        63       41 US HOUSE        1 GEN  \n4  1976 ALABAMA AL                1        63       41 US HOUSE        2 GEN  \n5  1976 ALABAMA AL                1        63       41 US HOUSE        2 GEN  \n6  1976 ALABAMA AL                1        63       41 US HOUSE        2 GEN  \n# ℹ 11 more variables: runoff &lt;lgl&gt;, special &lt;lgl&gt;, candidate &lt;chr&gt;,\n#   party &lt;chr&gt;, writein &lt;lgl&gt;, mode &lt;chr&gt;, candidatevotes &lt;dbl&gt;,\n#   totalvotes &lt;dbl&gt;, unofficial &lt;lgl&gt;, version &lt;dbl&gt;, fusion_ticket &lt;lgl&gt;\n\nhead(presidential_votes)\n\n# A tibble: 6 × 15\n   year state   state_po state_fips state_cen state_ic office       candidate   \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;       \n1  1976 ALABAMA AL                1        63       41 US PRESIDENT \"CARTER, JI…\n2  1976 ALABAMA AL                1        63       41 US PRESIDENT \"FORD, GERA…\n3  1976 ALABAMA AL                1        63       41 US PRESIDENT \"MADDOX, LE…\n4  1976 ALABAMA AL                1        63       41 US PRESIDENT \"BUBAR, BEN…\n5  1976 ALABAMA AL                1        63       41 US PRESIDENT \"HALL, GUS\" \n6  1976 ALABAMA AL                1        63       41 US PRESIDENT \"MACBRIDE, …\n# ℹ 7 more variables: party_detailed &lt;chr&gt;, writein &lt;lgl&gt;,\n#   candidatevotes &lt;dbl&gt;, totalvotes &lt;dbl&gt;, version &lt;dbl&gt;, notes &lt;lgl&gt;,\n#   party_simplified &lt;chr&gt;"
  },
  {
    "objectID": "HW mini 03 v2.html",
    "href": "HW mini 03 v2.html",
    "title": "STA 9750 2024 Submission Material",
    "section": "",
    "text": "Here’s a structured approach to help you set up and work through this project step-by-step. I’ve organized the tasks to simplify downloading, setting up, exploring, and analyzing the data.\n\n\nSetup and Initial Exploration\n\n1. Downloading Data\n\nData I: US House Election Votes and Presidential Vote Counts (1976-2022)\n\nTask: Download the US House Election Votes data (1976-2022) and the statewide presidential vote counts (1976-2022).\nInstructions: Visit the MIT Election Data Science Lab and download the data manually by following the prompts (you will need to provide contact information and agree to cite this data).\nCitation: Ensure you include the correct citation in your report as per the MIT Lab’s instructions.\n\nData II: Congressional Boundary Files (1976-2012)\n\nTask: Write automated code to download shapefiles for US congressional boundaries from 1976-2012.\nSource: Visit Lewis et al. Congressional Shapefiles to find the dataset.\nAutomated Code:\n\nRequirements: The code should:\n\nBe fully automated, avoiding manual downloads.\nUse an interpretable naming convention.\nAvoid repeated downloads for files already present.\n\nTips: Save files in a systematic directory and ensure not to store these files in version control (like Git).\n\n\nData III: Congressional Boundary Files (2014-Present)\n\nTask: Write code to download recent shapefiles for congressional districts from the Census Bureau FTP server (2014-2022).\nInstructions:\n\nUse the Census Bureau’s FTP Archive link for the CD directory (Congressional Districts).\nEnsure files have a consistent naming convention and prevent redownloads if files are already present.\n\n\n\n\n\nCode for Automated Download of Congressional Shapefiles (1976-2022)\nUse the sample code below for an automated download setup. Ensure you’ve specified the correct URLs and file paths based on the file structure of each data source.\n# Load required packages\nlibrary(httr)\nlibrary(sf)\n\n# Base URLs for downloading shapefiles\nbase_url_1976_2012 &lt;- \"http://cdmaps.polisci.ucla.edu/\"\nbase_url_2014_2022 &lt;- \"https://ftp2.census.gov/geo/tiger/TIGER%s/CD/\"\n\n# Function to download and save shapefiles\ndownload_shapefiles &lt;- function(year, state_code, base_url, output_dir) {\n  # Construct file path and download if file does not exist\n  file_path &lt;- file.path(output_dir, sprintf(\"congress_%s_%s.zip\", year, state_code))\n  if (!file.exists(file_path)) {\n    download_url &lt;- sprintf(\"%s%s.zip\", base_url, year)\n    download.file(download_url, file_path)\n    message(sprintf(\"Downloaded %s\", file_path))\n  } else {\n    message(sprintf(\"File %s already exists. Skipping download.\", file_path))\n  }\n}\n\n# Run the download for specific years\nyears &lt;- c(1976:2012, 2014:2022)\nfor (year in years) {\n  download_shapefiles(year, state_code, base_url_1976_2012, \"output_directory\")\n}\n\n\n\n\nTask 3: Exploration of Vote Count Data\n\nIdentify States with Changing Seats in the House of Representatives:\n\nGoal: Find states that gained or lost the most seats between 1976 and 2022.\nMethod: Calculate the change in the number of seats over time for each state.\n\nAnalyze New York’s Fusion Voting System:\n\nGoal: Identify elections where outcomes would have changed without fusion voting.\nMethod: Compare vote totals under fusion and non-fusion scenarios to see if removing minor party lines changes the election result.\n\nCompare Presidential vs. Congressional Candidate Performance:\n\nGoal: Check if presidential candidates perform better or worse than congressional candidates of the same party in the same state.\nMethod: Compare presidential votes with combined congressional votes for each party by state and year.\n\n\n\n\n\nTask 4: Automate Zip File Extraction\n\nDefine Function to Extract Shapefiles:\n\nFunction: read_shp_from_zip() will extract .shp files from a ZIP archive and load them into R as sf objects.\nExample Code:\nlibrary(sf)\n\nread_shp_from_zip &lt;- function(zip_file) {\n  temp_dir &lt;- tempdir()\n  unzip(zip_file, exdir = temp_dir)\n  shp_file &lt;- list.files(temp_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n  sf_obj &lt;- read_sf(shp_file)\n  return(sf_obj)\n}\n\n\n\n\n\nTask 5: Chloropleth Map of the 2000 Presidential Election\n\nLoad the Shapefile Data:\n\nUse the sf package to read in the congressional district boundaries for the year 2000.\n\nMap Electoral College Results:\n\nGoal: Create a chloropleth map showing states by the winning presidential candidate in 2000.\nExample Code:\nggplot(election_results, aes(geometry = geometry, fill = party)) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"2000 Presidential Election Results\", fill = \"Winning Party\")\n\n\n\n\n\nTask 6: Animated Chloropleth Visualization of Electoral College Results\n\nCreate an Animated Map:\n\nUse gganimate to show changes in electoral college results over multiple election years.\n\nlibrary(gganimate)\n\nggplot(election_results_time, aes(geometry = geometry, fill = party)) +\n  geom_sf() +\n  transition_time(year) +\n  labs(title = \"Presidential Election Results: {frame_time}\",\n       fill = \"Winning Party\")\n\n\n\n\nTask 7: Comparing ECV Allocation Schemes\n\nDevelop and Compare Allocation Schemes:\n\nCalculate election outcomes based on different allocation rules (e.g., state-wide winner-take-all, district-level, proportional).\nCompare outcomes across different methods and years to see if certain schemes favor one party consistently.\n\nWrite a Fact Check:\n\nIdentify which allocation scheme appears the fairest and explain why.\nUse an election year with significant impact from a different scheme to illustrate your point.\n\n\n\n\n\nAdditional Notes\n\nInclude Citations: Remember to cite all data sources (MIT Lab, Census Bureau, Lewis et al.) in your final report.\nAvoid Git Storage: Make sure large data files aren’t stored in Git, only the code (e.g., .qmd files).\nVisualization: Use ggplot2 and sf for creating maps and visualizations to effectively communicate findings.\n\nLet me know if you need further details on any specific section!"
  },
  {
    "objectID": "HW mini 03 v2.html#task-1-download-congressional-shapefiles-1976-2012",
    "href": "HW mini 03 v2.html#task-1-download-congressional-shapefiles-1976-2012",
    "title": "Congressional and Election Data Analysis",
    "section": "Task 1: Download Congressional Shapefiles 1976-2012",
    "text": "Task 1: Download Congressional Shapefiles 1976-2012\n\n# Define download function for 1976–2012 congressional shapefiles\ndownload_congress_shapefiles &lt;- function(start_congress, end_congress, base_url, output_dir) {\n  if (!dir.exists(output_dir)) dir.create(output_dir)\n  \n  for (congress_num in start_congress:end_congress) {\n    zip_filename &lt;- file.path(output_dir, sprintf(\"congress_%03d.zip\", congress_num))\n    shapefile_dir &lt;- file.path(output_dir, sprintf(\"congress_%03d\", congress_num))\n    \n    # Skip if already downloaded\n    if (dir.exists(shapefile_dir)) {\n      message(sprintf(\"Congress %d shapefiles already downloaded.\", congress_num))\n      next\n    }\n    \n    # Download and unzip\n    url &lt;- sprintf(base_url, congress_num)\n    response &lt;- httr::GET(url)\n    \n    if (httr::status_code(response) == 200) {\n      writeBin(httr::content(response, \"raw\"), zip_filename)\n      unzip(zip_filename, exdir = shapefile_dir)\n      message(sprintf(\"Downloaded and extracted shapefiles for Congress %d.\", congress_num))\n    } else {\n      warning(sprintf(\"Failed to download Congress %d data.\", congress_num))\n    }\n  }\n}\n\n# Set parameters and call function\ndownload_congress_shapefiles(\n  start_congress = 94,\n  end_congress = 112,\n  base_url = \"https://cdmaps.polisci.ucla.edu/shp/districts%03d.zip\",\n  output_dir = \"congress_shapefiles\"\n)\n\nCongress 94 shapefiles already downloaded.\n\n\nCongress 95 shapefiles already downloaded.\n\n\nCongress 96 shapefiles already downloaded.\n\n\nCongress 97 shapefiles already downloaded.\n\n\nCongress 98 shapefiles already downloaded.\n\n\nCongress 99 shapefiles already downloaded.\n\n\nCongress 100 shapefiles already downloaded.\n\n\nCongress 101 shapefiles already downloaded.\n\n\nCongress 102 shapefiles already downloaded.\n\n\nCongress 103 shapefiles already downloaded.\n\n\nCongress 104 shapefiles already downloaded.\n\n\nCongress 105 shapefiles already downloaded.\n\n\nCongress 106 shapefiles already downloaded.\n\n\nCongress 107 shapefiles already downloaded.\n\n\nCongress 108 shapefiles already downloaded.\n\n\nCongress 109 shapefiles already downloaded.\n\n\nCongress 110 shapefiles already downloaded.\n\n\nCongress 111 shapefiles already downloaded.\n\n\nCongress 112 shapefiles already downloaded."
  },
  {
    "objectID": "HW mini 03 v2.html#task-2-download-congressional-shapefiles-2014-2022",
    "href": "HW mini 03 v2.html#task-2-download-congressional-shapefiles-2014-2022",
    "title": "Congressional and Election Data Analysis",
    "section": "Task 2: Download Congressional Shapefiles 2014-2022",
    "text": "Task 2: Download Congressional Shapefiles 2014-2022\n\n# Define years and state FIPS codes\nyears &lt;- c(2014, 2016, 2018, 2020, 2022)\nstate_codes &lt;- sprintf(\"%02d\", 1:56)  # Generate FIPS codes from 01 to 56\n\n# Base URL for the Census Bureau's TIGER/Line FTP archive\nbase_url &lt;- \"https://ftp2.census.gov/geo/tiger/TIGER%s/CD/\"\n\n# Define output directory for shapefiles\noutput_dir &lt;- \"census_congressional_shapefiles\"\nif (!dir.exists(output_dir)) dir.create(output_dir)\n\n# Function to download and extract shapefiles by year and state\ndownload_census_shapefiles &lt;- function(year, state_code) {\n  url &lt;- sprintf(\"%s/tl_%s_%s_cd.zip\", sprintf(base_url, year), year, state_code)\n  zip_filename &lt;- file.path(output_dir, sprintf(\"cd_%s_%s.zip\", year, state_code))\n  shapefile_dir &lt;- file.path(output_dir, sprintf(\"cd_%s_%s\", year, state_code))\n  \n  # Skip if already downloaded\n  if (dir.exists(shapefile_dir)) {\n    message(sprintf(\"Shapefiles for %s %s already downloaded.\", year, state_code))\n    return(NULL)\n  }\n  \n  # Download the ZIP file\n  response &lt;- GET(url)\n  \n  # Check if download was successful\n  if (status_code(response) == 200) {\n    writeBin(content(response, \"raw\"), zip_filename)\n    \n    # Extract only the .shp file\n    temp_dir &lt;- tempdir()\n    zip_contents &lt;- unzip(zip_filename, exdir = temp_dir)\n    shp_file &lt;- zip_contents[grepl(\"\\\\.shp$\", zip_contents)]\n    \n    # Create target directory and move .shp file\n    if (length(shp_file) &gt; 0) {\n      dir.create(shapefile_dir, showWarnings = FALSE)\n      file.copy(shp_file, shapefile_dir)\n      message(sprintf(\"Downloaded and extracted shapefiles for year %s and state %s.\", year, state_code))\n    } else {\n      warning(\"No .shp file found in ZIP archive for year \", year, \" and state \", state_code)\n    }\n  } else {\n    warning(sprintf(\"Failed to download data for year %s and state %s.\", year, state_code))\n  }\n}\n\n# Loop over each year and state\nfor (year in years) {\n  for (state_code in state_codes) {\n    download_census_shapefiles(year, state_code)\n  }\n}\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2014 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2016 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2018 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2020 and state 56\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 01\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 02\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 03\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 04\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 05\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 06\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 07\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 08\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 09\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 10\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 11\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 12\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 13\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 14\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 15\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 16\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 17\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 18\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 19\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 20\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 21\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 22\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 23\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 24\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 25\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 26\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 27\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 28\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 29\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 30\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 31\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 32\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 33\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 34\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 35\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 36\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 37\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 38\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 39\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 40\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 41\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 42\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 43\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 44\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 45\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 46\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 47\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 48\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 49\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 50\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 51\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 52\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 53\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 54\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 55\n\n\nWarning in unzip(zip_filename, exdir = temp_dir): error 1 in extracting from\nzip file\n\n\nWarning in download_census_shapefiles(year, state_code): No .shp file found in\nZIP archive for year 2022 and state 56"
  },
  {
    "objectID": "HW mini 03 v2.html#task-3-exploration-of-vote-count-data",
    "href": "HW mini 03 v2.html#task-3-exploration-of-vote-count-data",
    "title": "Congressional and Election Data Analysis",
    "section": "Task 3: Exploration of Vote Count Data",
    "text": "Task 3: Exploration of Vote Count Data\nUsing the vote count data, let’s answer a few exploratory questions.\n\nIdentify states that have gained and lost the most seats in the US House of Representatives between 1976 and 2022.\nInvestigate instances of “fusion” voting systems in New York and analyze how outcomes may have differed without fusion voting.\nCompare presidential and congressional candidate performance within states over time, examining trends by party.\n\n\n# Load a sample shapefile, e.g., for Alabama in 2014 (replace \"filename.shp\" with actual filename)\nsample_shapefile &lt;- file.path(output_dir, \"cd_2014_01\", \"filename.shp\")\n\nif (file.exists(sample_shapefile)) {\n  sample_data &lt;- st_read(sample_shapefile)\n  print(sample_data)\n  plot(st_geometry(sample_data))\n} else {\n  warning(\"Sample shapefile not found. Check if download completed successfully.\")\n}\n\nWarning: Sample shapefile not found. Check if download completed successfully.\n\n# Example code to load and summarize house_votes and presidential_votes data:\nhead(house_votes)\n\n# A tibble: 6 × 20\n   year state   state_po state_fips state_cen state_ic office   district stage\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;\n1  1976 ALABAMA AL                1        63       41 US HOUSE        1 GEN  \n2  1976 ALABAMA AL                1        63       41 US HOUSE        1 GEN  \n3  1976 ALABAMA AL                1        63       41 US HOUSE        1 GEN  \n4  1976 ALABAMA AL                1        63       41 US HOUSE        2 GEN  \n5  1976 ALABAMA AL                1        63       41 US HOUSE        2 GEN  \n6  1976 ALABAMA AL                1        63       41 US HOUSE        2 GEN  \n# ℹ 11 more variables: runoff &lt;lgl&gt;, special &lt;lgl&gt;, candidate &lt;chr&gt;,\n#   party &lt;chr&gt;, writein &lt;lgl&gt;, mode &lt;chr&gt;, candidatevotes &lt;dbl&gt;,\n#   totalvotes &lt;dbl&gt;, unofficial &lt;lgl&gt;, version &lt;dbl&gt;, fusion_ticket &lt;lgl&gt;\n\nhead(presidential_votes)\n\n# A tibble: 6 × 15\n   year state   state_po state_fips state_cen state_ic office       candidate   \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;       \n1  1976 ALABAMA AL                1        63       41 US PRESIDENT \"CARTER, JI…\n2  1976 ALABAMA AL                1        63       41 US PRESIDENT \"FORD, GERA…\n3  1976 ALABAMA AL                1        63       41 US PRESIDENT \"MADDOX, LE…\n4  1976 ALABAMA AL                1        63       41 US PRESIDENT \"BUBAR, BEN…\n5  1976 ALABAMA AL                1        63       41 US PRESIDENT \"HALL, GUS\" \n6  1976 ALABAMA AL                1        63       41 US PRESIDENT \"MACBRIDE, …\n# ℹ 7 more variables: party_detailed &lt;chr&gt;, writein &lt;lgl&gt;,\n#   candidatevotes &lt;dbl&gt;, totalvotes &lt;dbl&gt;, version &lt;dbl&gt;, notes &lt;lgl&gt;,\n#   party_simplified &lt;chr&gt;"
  },
  {
    "objectID": "HW mini 03 v3.html",
    "href": "HW mini 03 v3.html",
    "title": "US House Election Analysis from 1976 to 2022",
    "section": "",
    "text": "Certainly! Here’s how to set up and run your code with specific instructions to download, extract, and load a zip file containing shapefiles for the 2000 election congressional districts.\n\nStep 1: Download the 2000 Congressional District Shapefile\n\nDownload Source: You can use the Census Bureau’s TIGER/Line Shapefiles or other repositories that provide shapefiles for U.S. congressional districts in the year 2000. Ensure the download provides a zip file with .shp, .shx, and .dbf files inside.\nSave the File Locally: Place this zip file in a known directory, for example:\n\ndata/2000_congressional_districts.zip\n\n\n\n\nStep 2: Update Your Code with the Correct Path\nReplace \"path_to_2000_shapefile.zip\" in your Quarto document with the actual path to your downloaded file:\n# Correct path to the zip file containing the 2000 shapefiles\nzip_file_path &lt;- \"data/2000_congressional_districts.zip\"\n\n\nStep 3: Use read_shp_from_zip to Load the Shapefile\nHere’s how to apply the function read_shp_from_zip to load the .shp file and plot the data:\n\nDefine read_shp_from_zip: Make sure the read_shp_from_zip function is set up to locate and read the .shp file in the zip.\nRead and Plot the Shapefile:\n\n# Define path to the zip file for the 2000 election data\nzip_file_path &lt;- \"data/2000_congressional_districts.zip\"\n\n# Load the shapefile from the zip file\nelection_results &lt;- read_shp_from_zip(zip_file_path)\n\n# Ensure the data has a 'party' column, or use a sample column for demonstration\n# Plot the election results (modify if necessary to fit actual column names in the shapefile)\nif (\"party\" %in% names(election_results)) {\n  ggplot(election_results, aes(geometry = geometry, fill = party)) +\n    geom_sf() +\n    theme_minimal() +\n    labs(title = \"2000 Presidential Election Results\", fill = \"Winning Party\")\n} else {\n  message(\"Column 'party' not found; plotting with available columns.\")\n  # Fallback plot without party if column not available\n  ggplot(election_results, aes(geometry = geometry)) +\n    geom_sf() +\n    theme_minimal() +\n    labs(title = \"2000 Presidential Election Results\")\n}\n\n\nStep 4: Verify the read_shp_from_zip Function\nHere’s the function again, customized for handling errors and confirming paths:\n# Function to read shapefile from a zip archive with error handling and debug output\nread_shp_from_zip &lt;- function(zip_file) {\n  # Check if the zip file exists and is not empty\n  if (!file.exists(zip_file)) {\n    stop(\"Error: The zip file does not exist.\")\n  }\n  if (file.info(zip_file)$size == 0) {\n    stop(\"Error: The zip file is empty.\")\n  }\n  \n  # Create a temporary directory for extraction\n  temp_dir &lt;- tempdir()\n  \n  # Try unzipping the file and capture any issues\n  unzip_status &lt;- tryCatch({\n    unzip(zip_file, exdir = temp_dir)\n    TRUE\n  }, warning = function(w) {\n    message(\"Warning during unzip: \", w$message)\n    FALSE\n  }, error = function(e) {\n    message(\"Error during unzip: \", e$message)\n    FALSE\n  })\n  \n  # Stop if unzipping failed\n  if (!unzip_status) {\n    stop(\"Failed to unzip the file.\")\n  }\n  \n  # Locate the .shp file in the unzipped contents\n  shp_file &lt;- list.files(temp_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n  \n  # Debug Output: Print all .shp files found\n  if (length(shp_file) == 0) {\n    stop(\"No .shp file found in the zip archive.\")\n  } else {\n    message(\"Shapefile(s) found: \", paste(shp_file, collapse = \", \"))\n    message(\"Attempting to read the shapefile from path: \", shp_file[1])\n  }\n  \n  # Additional check to confirm the .shp path exists and is valid\n  if (!file.exists(shp_file[1]) || file.info(shp_file[1])$size == 0) {\n    stop(\"Error: The specified .shp file is invalid or empty.\")\n  }\n  \n  # Read the shapefile\n  sf_obj &lt;- tryCatch({\n    read_sf(shp_file[1])  # Use the first .shp file if multiple are found\n  }, error = function(e) {\n    stop(\"Error reading .shp file: \", e$message)\n  })\n  \n  return(sf_obj)\n}\n\n\nSummary of Steps\n\nDownload and place the 2000 election shapefile zip at a known location, such as data/2000_congressional_districts.zip.\nUpdate the path in zip_file_path.\nRun read_shp_from_zip(zip_file_path) to load the shapefile.\nPlot using ggplot."
  },
  {
    "objectID": "Election Study for mini 03.html",
    "href": "Election Study for mini 03.html",
    "title": "Analysis of House and Presidential Election Data",
    "section": "",
    "text": "Run this script in R to clean, transform, and save the data for the .qmd file to use.\n\n# Load required libraries\n# Load the necessary package\nlibrary(tidyverse)\n# or load tidyr directly if you don't want the entire tidyverse\nlibrary(tidyr)\n\n\nlibrary(dplyr)\nlibrary(readr)\n\n# Paths for input and output files\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2022-house.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\"\noutput_house_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\noutput_presidential_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load the datasets\nvote_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)\n\n# Clean and Transform House Vote Data\nvote_data_clean &lt;- vote_data %&gt;%\n  select(year, state, state_po, district, candidate, party, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    district = as.integer(district),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Clean and Transform Presidential Data\npresidential_data_clean &lt;- presidential_data %&gt;%\n  select(year, state, state_po, candidate, party_simplified, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    party = party_simplified,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Save Cleaned Data for Use in Quarto Document\nwrite_csv(vote_data_clean, output_house_path)\nwrite_csv(presidential_data_clean, output_presidential_path)\n\n# Print confirmation messages\ncat(\"Cleaned House vote data saved to:\", output_house_path, \"\\n\")\n\nCleaned House vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv \n\ncat(\"Cleaned Presidential vote data saved to:\", output_presidential_path, \"\\n\")\n\nCleaned Presidential vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv \n\n\nThis report explores trends in US House and Presidential elections, focusing on total votes by year and party, as well as unique insights from fusion voting and candidate performance.\n\n# Election Data Analysis\n## Setup\n# Load Libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\n\n# Set file paths for cleaned data\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load Data\nhouse_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)"
  },
  {
    "objectID": "Election Study for mini 03.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "href": "Election Study for mini 03.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "title": "Analysis of House and Presidential Election Data",
    "section": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives",
    "text": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\n\n# Define the path to the specific shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Read the shapefile\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Check structure to confirm successful load\nprint(summary(shapefile_data_2000))\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE         FROMCOUNTY                 geometry  \n Length:435         Length:435         Length:435         MULTIPOLYGON :435  \n Class :character   Class :character   Class :character   epsg:4269    :  0  \n Mode  :character   Mode  :character   Mode  :character   +proj=long...:  0  \n\n# Plot the shapefile using ggplot2\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Congressional Districts for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()"
  },
  {
    "objectID": "Election Study for mini 03 Vr 2.html",
    "href": "Election Study for mini 03 Vr 2.html",
    "title": "Analysis of House and Presidential Election Data",
    "section": "",
    "text": "Run this script in R to clean, transform, and save the data for the .qmd file to use.\n\n# Load required libraries\n# Load the necessary package\nlibrary(tidyverse)\n# or load tidyr directly if you don't want the entire tidyverse\nlibrary(tidyr)\n\n\nlibrary(dplyr)\nlibrary(readr)\n\n# Paths for input and output files\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2022-house.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\"\noutput_house_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\noutput_presidential_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load the datasets\nvote_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)\n\n# Clean and Transform House Vote Data\nvote_data_clean &lt;- vote_data %&gt;%\n  select(year, state, state_po, district, candidate, party, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    district = as.integer(district),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Clean and Transform Presidential Data\npresidential_data_clean &lt;- presidential_data %&gt;%\n  select(year, state, state_po, candidate, party_simplified, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    party = party_simplified,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Save Cleaned Data for Use in Quarto Document\nwrite_csv(vote_data_clean, output_house_path)\nwrite_csv(presidential_data_clean, output_presidential_path)\n\n# Print confirmation messages\ncat(\"Cleaned House vote data saved to:\", output_house_path, \"\\n\")\n\nCleaned House vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv \n\ncat(\"Cleaned Presidential vote data saved to:\", output_presidential_path, \"\\n\")\n\nCleaned Presidential vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv \n\n\nThis report explores trends in US House and Presidential elections, focusing on total votes by year and party, as well as unique insights from fusion voting and candidate performance.\n\n# Election Data Analysis\n## Setup\n# Load Libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\n\n# Set file paths for cleaned data\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load Data\nhouse_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)"
  },
  {
    "objectID": "Election Study for mini 03 Vr 2.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "href": "Election Study for mini 03 Vr 2.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "title": "Analysis of House and Presidential Election Data",
    "section": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives",
    "text": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\n\n# Define the path to the specific shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Read the shapefile\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Check structure to confirm successful load\nprint(summary(shapefile_data_2000))\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE         FROMCOUNTY                 geometry  \n Length:435         Length:435         Length:435         MULTIPOLYGON :435  \n Class :character   Class :character   Class :character   epsg:4269    :  0  \n Mode  :character   Mode  :character   Mode  :character   +proj=long...:  0  \n\n# Plot the shapefile using ggplot2\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Congressional Districts for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()"
  },
  {
    "objectID": "Election Study for mini 03 Ver 33.html",
    "href": "Election Study for mini 03 Ver 33.html",
    "title": "Analysis of House and Presidential Election Data",
    "section": "",
    "text": "Run this script in R to clean, transform, and save the data for the .qmd file to use.\n\n# Load required libraries\n# Load the necessary package\nlibrary(tidyverse)\n# or load tidyr directly if you don't want the entire tidyverse\nlibrary(tidyr)\n\n\nlibrary(dplyr)\nlibrary(readr)\n\n# Paths for input and output files\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2022-house.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\"\noutput_house_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\noutput_presidential_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load the datasets\nvote_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)\n\n# Clean and Transform House Vote Data\nvote_data_clean &lt;- vote_data %&gt;%\n  select(year, state, state_po, district, candidate, party, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    district = as.integer(district),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Clean and Transform Presidential Data\npresidential_data_clean &lt;- presidential_data %&gt;%\n  select(year, state, state_po, candidate, party_simplified, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    party = party_simplified,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Save Cleaned Data for Use in Quarto Document\nwrite_csv(vote_data_clean, output_house_path)\nwrite_csv(presidential_data_clean, output_presidential_path)\n\n# Print confirmation messages\ncat(\"Cleaned House vote data saved to:\", output_house_path, \"\\n\")\n\nCleaned House vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv \n\ncat(\"Cleaned Presidential vote data saved to:\", output_presidential_path, \"\\n\")\n\nCleaned Presidential vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv \n\n\nThis report explores trends in US House and Presidential elections, focusing on total votes by year and party, as well as unique insights from fusion voting and candidate performance.\n\n# Election Data Analysis\n## Setup\n# Load Libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\n\n# Set file paths for cleaned data\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load Data\nhouse_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)"
  },
  {
    "objectID": "Election Study for mini 03 Ver 33.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "href": "Election Study for mini 03 Ver 33.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "title": "Analysis of House and Presidential Election Data",
    "section": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives",
    "text": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\n\n# Define the path to the specific shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Read the shapefile\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Check structure to confirm successful load\nprint(summary(shapefile_data_2000))\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE         FROMCOUNTY                 geometry  \n Length:435         Length:435         Length:435         MULTIPOLYGON :435  \n Class :character   Class :character   Class :character   epsg:4269    :  0  \n Mode  :character   Mode  :character   Mode  :character   +proj=long...:  0  \n\n# Save the shapefile data to an RDS file for future use\nsave_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/shapefile_data_2000.rds\"\nsaveRDS(shapefile_data_2000, file = save_path)\n\n# Plot the shapefile using ggplot2\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Congressional Districts for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Display the column names\ncolnames(shapefile_data_2000)\n\n [1] \"STATENAME\"  \"ID\"         \"DISTRICT\"   \"STARTCONG\"  \"ENDCONG\"   \n [6] \"DISTRICTSI\" \"COUNTY\"     \"PAGE\"       \"LAW\"        \"NOTE\"      \n[11] \"BESTDEC\"    \"FINALNOTE\"  \"RNOTE\"      \"LASTCHANGE\" \"FROMCOUNTY\"\n[16] \"geometry\"  \n\n# Display the first few rows of the shapefile data\nhead(shapefile_data_2000)\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.5993 ymin: 30.62397 xmax: -73.7243 ymax: 43.09876\nGeodetic CRS:  NAD83\n# A tibble: 6 × 16\n  STATENAME ID    DISTRICT STARTCONG ENDCONG DISTRICTSI COUNTY PAGE  LAW   NOTE \n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Californ… 0060… 27       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n2 Georgia   0130… 2        93        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n3 New York  0360… 10       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n4 New York  0360… 11       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n5 New York  0360… 37       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n6 New York  0360… 38       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n# ℹ 6 more variables: BESTDEC &lt;chr&gt;, FINALNOTE &lt;chr&gt;, RNOTE &lt;chr&gt;,\n#   LASTCHANGE &lt;chr&gt;, FROMCOUNTY &lt;chr&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n# Display the structure of the shapefile data\nstr(shapefile_data_2000)\n\nsf [435 × 16] (S3: sf/tbl_df/tbl/data.frame)\n $ STATENAME : chr [1:435] \"California\" \"Georgia\" \"New York\" \"New York\" ...\n $ ID        : chr [1:435] \"006094097027\" \"013093097002\" \"036094097010\" \"036094097011\" ...\n $ DISTRICT  : chr [1:435] \"27\" \"2\" \"10\" \"11\" ...\n $ STARTCONG : chr [1:435] \"94\" \"93\" \"94\" \"94\" ...\n $ ENDCONG   : chr [1:435] \"97\" \"97\" \"97\" \"97\" ...\n $ DISTRICTSI: chr [1:435] NA NA NA NA ...\n $ COUNTY    : chr [1:435] NA NA NA NA ...\n $ PAGE      : chr [1:435] NA NA NA NA ...\n $ LAW       : chr [1:435] NA NA NA NA ...\n $ NOTE      : chr [1:435] \"{\\\"Shape from shapes/Ftp_Upload/California_94-97cc/94-97cc_27cd_California.shp (17628 bytes, last modified on T\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/Georgia_93-97cc/93-97cc_2cd_Georgia.shp (87868 bytes, last modified on Thu Jul \"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_10cd_NewYork.shp (26408 bytes, last modified on Wed Dec\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_11cd_NewYork.shp (33916 bytes, last modified on Tue Feb\"| __truncated__ ...\n $ BESTDEC   : chr [1:435] NA NA NA NA ...\n $ FINALNOTE : chr [1:435] NA NA NA NA ...\n $ RNOTE     : chr [1:435] NA NA NA NA ...\n $ LASTCHANGE: chr [1:435] \"2016-05-20 13:07:35.318982\" \"2016-05-20 13:07:46.863044\" \"2016-05-20 13:09:35.392414\" \"2016-05-20 13:09:35.409757\" ...\n $ FROMCOUNTY: chr [1:435] \"F\" \"F\" \"F\" \"F\" ...\n $ geometry  :sfc_MULTIPOLYGON of length 435; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:1089, 1:2] -119 -119 -119 -119 -119 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"STATENAME\" \"ID\" \"DISTRICT\" \"STARTCONG\" ...\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\n\n# Define the file path to the election data CSV\nfile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\n\n# Read the election data from the CSV file\nelection_data &lt;- read.csv(file_path)\n\n# Filter the data for the year 2000\nelection_data_2000 &lt;- election_data %&gt;%\n  filter(year == 2000)\n\n# Determine the winning party in each state by finding the highest vote count for each state\nstate_winners &lt;- election_data_2000 %&gt;%\n  group_by(state) %&gt;%\n  slice_max(order_by = vote_count, n = 1) %&gt;%  # Replace candidatevotes with vote_count if that's the column name\n  ungroup() %&gt;%\n  select(state, party)\n\n# Separate the states into two lists: one for Democrat wins and one for Republican wins\ndemocrat_states &lt;- state_winners %&gt;%\n  filter(party == \"DEMOCRAT\") %&gt;%\n  pull(state)\n\nrepublican_states &lt;- state_winners %&gt;%\n  filter(party == \"REPUBLICAN\") %&gt;%\n  pull(state)\n\n# Print the lists of states won by each party\ncat(\"States won by Democrats:\\n\")\n\nStates won by Democrats:\n\nprint(democrat_states)\n\n [1] \"ARKANSAS\"       \"CONNECTICUT\"    \"HAWAII\"         \"MAINE\"         \n [5] \"MASSACHUSETTS\"  \"NEW MEXICO\"     \"NEW YORK\"       \"NORTH CAROLINA\"\n [9] \"NORTH DAKOTA\"   \"RHODE ISLAND\"   \"WASHINGTON\"     \"WEST VIRGINIA\" \n\ncat(\"\\nStates won by Republicans:\\n\")\n\n\nStates won by Republicans:\n\nprint(republican_states)\n\n [1] \"ALABAMA\"        \"ALASKA\"         \"ARIZONA\"        \"CALIFORNIA\"    \n [5] \"COLORADO\"       \"DELAWARE\"       \"FLORIDA\"        \"GEORGIA\"       \n [9] \"IDAHO\"          \"ILLINOIS\"       \"INDIANA\"        \"IOWA\"          \n[13] \"KANSAS\"         \"KENTUCKY\"       \"LOUISIANA\"      \"MARYLAND\"      \n[17] \"MICHIGAN\"       \"MINNESOTA\"      \"MISSISSIPPI\"    \"MISSOURI\"      \n[21] \"MONTANA\"        \"NEBRASKA\"       \"NEVADA\"         \"NEW HAMPSHIRE\" \n[25] \"NEW JERSEY\"     \"OHIO\"           \"OKLAHOMA\"       \"OREGON\"        \n[29] \"PENNSYLVANIA\"   \"SOUTH CAROLINA\" \"SOUTH DAKOTA\"   \"TENNESSEE\"     \n[33] \"TEXAS\"          \"UTAH\"           \"VIRGINIA\"       \"WISCONSIN\"     \n[37] \"WYOMING\"       \n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Lists of states by winning party from the 2000 election data\ndemocrat_states &lt;- c(\"ARKANSAS\", \"CONNECTICUT\", \"HAWAII\", \"MAINE\", \"MASSACHUSETTS\", \"NEW MEXICO\", \n                     \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"RHODE ISLAND\", \"WASHINGTON\", \"WEST VIRGINIA\")\n\nrepublican_states &lt;- c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"CALIFORNIA\", \"COLORADO\", \"DELAWARE\", \n                       \"FLORIDA\", \"GEORGIA\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \"KANSAS\", \n                       \"KENTUCKY\", \"LOUISIANA\", \"MARYLAND\", \"MICHIGAN\", \"MINNESOTA\", \"MISSISSIPPI\", \n                       \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \"NEW JERSEY\", \n                       \"OHIO\", \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"SOUTH CAROLINA\", \n                       \"SOUTH DAKOTA\", \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VIRGINIA\", \"WISCONSIN\", \"WYOMING\")\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME == \"TEXAS\" ~ \"REPUBLICAN\",  # Explicitly mark Texas as Republican\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\"\n  ))\n\n# Plot with color coding for winning parties, emphasizing Texas in red\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry, fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Lists of states by winning party from the 2000 election data\ndemocrat_states &lt;- c(\"ARKANSAS\", \"CONNECTICUT\", \"HAWAII\", \"MAINE\", \"MASSACHUSETTS\", \"NEW MEXICO\", \n                     \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"RHODE ISLAND\", \"WASHINGTON\", \"WEST VIRGINIA\")\n\nrepublican_states &lt;- c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"CALIFORNIA\", \"COLORADO\", \"DELAWARE\", \n                       \"FLORIDA\", \"GEORGIA\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \"KANSAS\", \n                       \"KENTUCKY\", \"LOUISIANA\", \"MARYLAND\", \"MICHIGAN\", \"MINNESOTA\", \"MISSISSIPPI\", \n                       \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \"NEW JERSEY\", \n                       \"OHIO\", \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"SOUTH CAROLINA\", \n                       \"SOUTH DAKOTA\", \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VIRGINIA\", \"WISCONSIN\", \"WYOMING\")\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\",\n    TRUE ~ NA_character_  # Assign NA for states with no party assignment\n  ))\n\n# Plot with color coding for winning parties, leaving unassigned areas transparent\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry, fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), na.value = \"transparent\") +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Ensure Alaska is set to blue (Democratic) for this visualization\ndemocrat_states &lt;- c(democrat_states, \"ALASKA\")  # Add Alaska to Democrat states if not present\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\",\n    TRUE ~ NA_character_  # Assign NA for states with no party assignment\n  ))\n\n# Plot with color coding for winning parties, ensuring Alaska is blue\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry, fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), na.value = \"transparent\") +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Lists of states by winning party from the 2000 election data\ndemocrat_states &lt;- c(\"ARKANSAS\", \"CONNECTICUT\", \"HAWAII\", \"MAINE\", \"MASSACHUSETTS\", \"NEW MEXICO\", \n                     \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"RHODE ISLAND\", \"WASHINGTON\", \"WEST VIRGINIA\")\n\nrepublican_states &lt;- c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"CALIFORNIA\", \"COLORADO\", \"DELAWARE\", \n                       \"FLORIDA\", \"GEORGIA\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \"KANSAS\", \n                       \"KENTUCKY\", \"LOUISIANA\", \"MARYLAND\", \"MICHIGAN\", \"MINNESOTA\", \"MISSISSIPPI\", \n                       \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \"NEW JERSEY\", \n                       \"OHIO\", \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"SOUTH CAROLINA\", \n                       \"SOUTH DAKOTA\", \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VIRGINIA\", \"WISCONSIN\", \"WYOMING\")\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\",\n    TRUE ~ NA_character_  # Assign NA for states with no party assignment\n  ))\n\n# Plot with color coding for winning parties\nggplot(shapefile_data_2000) +\n  geom_sf(aes(fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), na.value = \"transparent\") +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\n\n# Remove geometry temporarily and count districts by state\ndistrict_counts_by_state &lt;- shapefile_data_2000 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry temporarily\n  group_by(STATENAME) %&gt;%\n  summarize(num_districts = n_distinct(DISTRICT)) %&gt;%\n  arrange(desc(num_districts))\n\n# Print the results\ncat(\"Number of Districts by State:\\n\")\n\nNumber of Districts by State:\n\nprint(district_counts_by_state)\n\n# A tibble: 50 × 2\n   STATENAME     num_districts\n   &lt;chr&gt;                 &lt;int&gt;\n 1 California               43\n 2 New York                 39\n 3 Pennsylvania             25\n 4 Illinois                 24\n 5 Texas                    24\n 6 Ohio                     23\n 7 Michigan                 19\n 8 Florida                  15\n 9 New Jersey               15\n10 Massachusetts            12\n# ℹ 40 more rows\n\n\n\n# Install and load necessary libraries\nif (!requireNamespace(\"sf\", quietly = TRUE)) install.packages(\"sf\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n\nlibrary(sf)\nlibrary(ggplot2)\n\n# Define the path to the shapefile (update with your specific file path)\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile data as an sf object\ndistricts &lt;- read_sf(shapefile_path)\n\n# Check the structure of the shapefile data to confirm it's loaded correctly\nprint(summary(districts))\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE         FROMCOUNTY                 geometry  \n Length:435         Length:435         Length:435         MULTIPOLYGON :435  \n Class :character   Class :character   Class :character   epsg:4269    :  0  \n Mode  :character   Mode  :character   Mode  :character   +proj=long...:  0  \n\n# Add a color column to color California districts blue, others red\ndistricts$color &lt;- ifelse(districts$STATENAME == \"California\", \"blue\", \"red\")\n\n# Plot the map with colors for each district\nggplot(data = districts) + \n  geom_sf(aes(fill = color)) +\n  scale_fill_identity() +\n  theme_minimal() +\n  labs(title = \"State Districts (California in Blue, Others in Red)\")"
  },
  {
    "objectID": "ElectionStudy03Ver33.html",
    "href": "ElectionStudy03Ver33.html",
    "title": "Early Years:",
    "section": "",
    "text": "project: type: html\nformat: html: theme: cosmo # Set the theme to “cosmo” or any other desired theme toc: true # Enable table of contents if needed toc-depth: 2 # Set depth for the table of contents css: styles.css # Optional: add custom CSS if you have a separate stylesheet"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "href": "ElectionStudy03Ver33.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "title": "Early Years:",
    "section": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives",
    "text": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#florida",
    "href": "ElectionStudy03Ver33.html#florida",
    "title": "Early Years:",
    "section": "Florida",
    "text": "Florida"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#texas",
    "href": "ElectionStudy03Ver33.html#texas",
    "title": "Analysis of House and Presidential Election Data",
    "section": "Texas",
    "text": "Texas\n\nDemocrats:\n\nSimilar pattern to Florida, with notable peaks in the 1980s and 2000s, where Democratic presidential candidates gained more votes than their congressional counterparts.\nOccasional dips below zero suggest that certain local Democratic candidates were more popular than the national ticket in some years.\n\nRepublicans:\n\nStrong peaks in the early 1980s for Republican presidential candidates, but dips in later years show instances where Republican congressional candidates outperformed the presidential nominee, highlighting the appeal of local candidates and issues."
  },
  {
    "objectID": "ElectionStudy03Ver33.html#key-takeaway",
    "href": "ElectionStudy03Ver33.html#key-takeaway",
    "title": "Analysis of House and Presidential Election Data",
    "section": "Key Takeaway",
    "text": "Key Takeaway\nBoth states demonstrate shifts in support between presidential and congressional candidates, reflecting how local issues and candidate appeal can impact voter behavior differently at the national and state levels.\n\nTask 4: Popularity Trends Over Time and Notable Outliers\nQuestion: Does this trend differ over time, across states, or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n\nPresidents who performed significantly better or worse than their co-partisans in Congress:\n# A tibble: 75 × 6\n    year state      party      pres_votes house_votes vote_difference\n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;           &lt;dbl&gt;\n 1  1984 FLORIDA    REPUBLICAN    2730350     1190779         1539571\n 2  1984 TEXAS      REPUBLICAN    3433428     1981823         1451605\n 3  2004 FLORIDA    DEMOCRAT      3583544     2212326         1371218\n 4  1988 TEXAS      REPUBLICAN    3036829     1834135         1202694\n 5  1984 CALIFORNIA REPUBLICAN    5467009     4423734         1043275\n 6  1984 LOUISIANA  REPUBLICAN    1037299           2         1037297\n 7  1988 FLORIDA    REPUBLICAN    2618885     1615569         1003316\n 8  2000 FLORIDA    DEMOCRAT      2912253     1976189          936064\n 9  1980 TEXAS      REPUBLICAN    2510705     1608636          902069\n10  2008 CALIFORNIA DEMOCRAT      8274473     7377725          896748\n# ℹ 65 more rows\n\nAnalysis: The table lists cases where a president was significantly more or less popular than\n  congressional candidates from the same party. Outliers indicate specific years or states where\n  presidential candidates either greatly exceeded or fell short of their co-partisans. This could\n  reflect unique candidate appeal, political circumstances, or party alignment issues within that election cycle."
  },
  {
    "objectID": "ElectionStudy03Ver33.html#explanation",
    "href": "ElectionStudy03Ver33.html#explanation",
    "title": "Early Years:",
    "section": "Explanation",
    "text": "Explanation\nThis map shows the number of electoral votes allocated to each U.S. state for the 2024 presidential election, based on the 2020 Census data. Darker shades indicate states with more electoral votes, reflecting higher populations. States like California, Texas, Florida, and New York have the most votes due to their large populations, making them particularly influential in the Electoral College. Smaller states have fewer electoral votes, represented by lighter shades, but all states contribute to the total needed to win the presidency.\n\nTask 4: Automate Zip File Extraction\n#To automate the extraction of .shp files from ZIP archives, we’ll create a function called read_shp_from_zip(). This function will take in the name of a ZIP file, extract #the .shp file within it, and read it into R using read_sf() from the sf package.\n\n\nCode to Load and Combine Shapefiles from Subfolders"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#outout-files-from-reading-the-.shp-file",
    "href": "ElectionStudy03Ver33.html#outout-files-from-reading-the-.shp-file",
    "title": "Early Years:",
    "section": "Outout files from reading the .shp file",
    "text": "Outout files from reading the .shp file"
  },
  {
    "objectID": "ElectionStudy03Ver33 - Copy.html",
    "href": "ElectionStudy03Ver33 - Copy.html",
    "title": "Analysis of House and Presidential Election Data",
    "section": "",
    "text": "#Run this script in R to clean, transform, and save the data for the .qmd file to use.\n\n# Load required libraries\n# Load the necessary package\nlibrary(tidyverse)\n# or load tidyr directly if you don't want the entire tidyverse\nlibrary(tidyr)\n\n\nlibrary(dplyr)\nlibrary(readr)\n\n# Paths for input and output files\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2022-house.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\"\noutput_house_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\noutput_presidential_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load the datasets\nvote_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)\n\n# Clean and Transform House Vote Data\nvote_data_clean &lt;- vote_data %&gt;%\n  select(year, state, state_po, district, candidate, party, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    district = as.integer(district),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n# Clean and Transform Presidential Data\npresidential_data_clean &lt;- presidential_data %&gt;%\n  select(year, state, state_po, candidate, party_simplified, candidatevotes, totalvotes) %&gt;%\n  rename(\n    state_abbreviation = state_po,\n    candidate_name = candidate,\n    party = party_simplified,\n    vote_count = candidatevotes,\n    total_vote_count = totalvotes\n  ) %&gt;%\n  mutate(\n    year = as.integer(year),\n    vote_count = as.numeric(vote_count),\n    total_vote_count = as.numeric(total_vote_count)\n  ) %&gt;%\n  drop_na()\n\n\n# Save Cleaned Data for Use in Quarto Document\nwrite_csv(vote_data_clean, output_house_path)\nwrite_csv(presidential_data_clean, output_presidential_path)\n\n# Print confirmation messages\ncat(\"Cleaned House vote data saved to:\", output_house_path, \"\\n\")\n\nCleaned House vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv \n\ncat(\"Cleaned Presidential vote data saved to:\", output_presidential_path, \"\\n\")\n\nCleaned Presidential vote data saved to: C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv \n\n\nThis report explores trends in US House and Presidential elections, focusing on total votes by year and party, as well as unique insights from fusion voting and candidate performance.\n\n# Election Data Analysis\n## Setup\n# Load Libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\n\n# Set file paths for cleaned data\nhouse_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\npresidential_data_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_presidential_vote_data.csv\"\n\n# Load Data\nhouse_data &lt;- read_csv(house_data_path)\npresidential_data &lt;- read_csv(presidential_data_path)"
  },
  {
    "objectID": "ElectionStudy03Ver33 - Copy.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "href": "ElectionStudy03Ver33 - Copy.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "title": "Analysis of House and Presidential Election Data",
    "section": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives",
    "text": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\n\n# Define the path to the specific shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Read the shapefile\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Check structure to confirm successful load\nprint(summary(shapefile_data_2000))\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE        FROMCOUNTY               geometry  \n Length:435         Length:435         Mode :logical   MULTIPOLYGON :435  \n Class :character   Class :character   FALSE:381       epsg:4269    :  0  \n Mode  :character   Mode  :character   TRUE :54        +proj=long...:  0  \n\n# Save the shapefile data to an RDS file for future use\nsave_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/shapefile_data_2000.rds\"\nsaveRDS(shapefile_data_2000, file = save_path)\n\n# Plot the shapefile using ggplot2\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Congressional Districts for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Display the column names\ncolnames(shapefile_data_2000)\n\n [1] \"STATENAME\"  \"ID\"         \"DISTRICT\"   \"STARTCONG\"  \"ENDCONG\"   \n [6] \"DISTRICTSI\" \"COUNTY\"     \"PAGE\"       \"LAW\"        \"NOTE\"      \n[11] \"BESTDEC\"    \"FINALNOTE\"  \"RNOTE\"      \"LASTCHANGE\" \"FROMCOUNTY\"\n[16] \"geometry\"  \n\n# Display the first few rows of the shapefile data\nhead(shapefile_data_2000)\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.5993 ymin: 30.62397 xmax: -73.7243 ymax: 43.09876\nGeodetic CRS:  NAD83\n# A tibble: 6 × 16\n  STATENAME ID    DISTRICT STARTCONG ENDCONG DISTRICTSI COUNTY PAGE  LAW   NOTE \n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Californ… 0060… 27       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n2 Georgia   0130… 2        93        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n3 New York  0360… 10       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n4 New York  0360… 11       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n5 New York  0360… 37       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n6 New York  0360… 38       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n# ℹ 6 more variables: BESTDEC &lt;chr&gt;, FINALNOTE &lt;chr&gt;, RNOTE &lt;chr&gt;,\n#   LASTCHANGE &lt;chr&gt;, FROMCOUNTY &lt;lgl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n# Display the structure of the shapefile data\nstr(shapefile_data_2000)\n\nsf [435 × 16] (S3: sf/tbl_df/tbl/data.frame)\n $ STATENAME : chr [1:435] \"California\" \"Georgia\" \"New York\" \"New York\" ...\n $ ID        : chr [1:435] \"006094097027\" \"013093097002\" \"036094097010\" \"036094097011\" ...\n $ DISTRICT  : chr [1:435] \"27\" \"2\" \"10\" \"11\" ...\n $ STARTCONG : chr [1:435] \"94\" \"93\" \"94\" \"94\" ...\n $ ENDCONG   : chr [1:435] \"97\" \"97\" \"97\" \"97\" ...\n $ DISTRICTSI: chr [1:435] NA NA NA NA ...\n $ COUNTY    : chr [1:435] NA NA NA NA ...\n $ PAGE      : chr [1:435] NA NA NA NA ...\n $ LAW       : chr [1:435] NA NA NA NA ...\n $ NOTE      : chr [1:435] \"{\\\"Shape from shapes/Ftp_Upload/California_94-97cc/94-97cc_27cd_California.shp (17628 bytes, last modified on T\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/Georgia_93-97cc/93-97cc_2cd_Georgia.shp (87868 bytes, last modified on Thu Jul \"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_10cd_NewYork.shp (26408 bytes, last modified on Wed Dec\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_11cd_NewYork.shp (33916 bytes, last modified on Tue Feb\"| __truncated__ ...\n $ BESTDEC   : chr [1:435] NA NA NA NA ...\n $ FINALNOTE : chr [1:435] NA NA NA NA ...\n $ RNOTE     : chr [1:435] NA NA NA NA ...\n $ LASTCHANGE: chr [1:435] \"2016-05-20 13:07:35.318982\" \"2016-05-20 13:07:46.863044\" \"2016-05-20 13:09:35.392414\" \"2016-05-20 13:09:35.409757\" ...\n $ FROMCOUNTY: logi [1:435] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ geometry  :sfc_MULTIPOLYGON of length 435; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:1089, 1:2] -119 -119 -119 -119 -119 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"STATENAME\" \"ID\" \"DISTRICT\" \"STARTCONG\" ...\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\n\n# Define the file path to the election data CSV\nfile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\n\n# Read the election data from the CSV file\nelection_data &lt;- read.csv(file_path)\n\n# Filter the data for the year 2000\nelection_data_2000 &lt;- election_data %&gt;%\n  filter(year == 2000)\n\n# Determine the winning party in each state by finding the highest vote count for each state\nstate_winners &lt;- election_data_2000 %&gt;%\n  group_by(state) %&gt;%\n  slice_max(order_by = vote_count, n = 1) %&gt;%  # Replace candidatevotes with vote_count if that's the column name\n  ungroup() %&gt;%\n  select(state, party)\n\n# Separate the states into two lists: one for Democrat wins and one for Republican wins\ndemocrat_states &lt;- state_winners %&gt;%\n  filter(party == \"DEMOCRAT\") %&gt;%\n  pull(state)\n\nrepublican_states &lt;- state_winners %&gt;%\n  filter(party == \"REPUBLICAN\") %&gt;%\n  pull(state)\n\n# Print the lists of states won by each party\ncat(\"States won by Democrats:\\n\")\n\nStates won by Democrats:\n\nprint(democrat_states)\n\n [1] \"ARKANSAS\"       \"CONNECTICUT\"    \"HAWAII\"         \"MAINE\"         \n [5] \"MASSACHUSETTS\"  \"NEW MEXICO\"     \"NEW YORK\"       \"NORTH CAROLINA\"\n [9] \"NORTH DAKOTA\"   \"RHODE ISLAND\"   \"WASHINGTON\"     \"WEST VIRGINIA\" \n\ncat(\"\\nStates won by Republicans:\\n\")\n\n\nStates won by Republicans:\n\nprint(republican_states)\n\n [1] \"ALABAMA\"        \"ALASKA\"         \"ARIZONA\"        \"CALIFORNIA\"    \n [5] \"COLORADO\"       \"DELAWARE\"       \"FLORIDA\"        \"GEORGIA\"       \n [9] \"IDAHO\"          \"ILLINOIS\"       \"INDIANA\"        \"IOWA\"          \n[13] \"KANSAS\"         \"KENTUCKY\"       \"LOUISIANA\"      \"MARYLAND\"      \n[17] \"MICHIGAN\"       \"MINNESOTA\"      \"MISSISSIPPI\"    \"MISSOURI\"      \n[21] \"MONTANA\"        \"NEBRASKA\"       \"NEVADA\"         \"NEW HAMPSHIRE\" \n[25] \"NEW JERSEY\"     \"OHIO\"           \"OKLAHOMA\"       \"OREGON\"        \n[29] \"PENNSYLVANIA\"   \"SOUTH CAROLINA\" \"SOUTH DAKOTA\"   \"TENNESSEE\"     \n[33] \"TEXAS\"          \"UTAH\"           \"VIRGINIA\"       \"WISCONSIN\"     \n[37] \"WYOMING\"       \n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Lists of states by winning party from the 2000 election data\ndemocrat_states &lt;- c(\"ARKANSAS\", \"CONNECTICUT\", \"HAWAII\", \"MAINE\", \"MASSACHUSETTS\", \"NEW MEXICO\", \n                     \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"RHODE ISLAND\", \"WASHINGTON\", \"WEST VIRGINIA\")\n\nrepublican_states &lt;- c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"CALIFORNIA\", \"COLORADO\", \"DELAWARE\", \n                       \"FLORIDA\", \"GEORGIA\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \"KANSAS\", \n                       \"KENTUCKY\", \"LOUISIANA\", \"MARYLAND\", \"MICHIGAN\", \"MINNESOTA\", \"MISSISSIPPI\", \n                       \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \"NEW JERSEY\", \n                       \"OHIO\", \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"SOUTH CAROLINA\", \n                       \"SOUTH DAKOTA\", \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VIRGINIA\", \"WISCONSIN\", \"WYOMING\")\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME == \"TEXAS\" ~ \"REPUBLICAN\",  # Explicitly mark Texas as Republican\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\"\n  ))\n\n# Plot with color coding for winning parties, emphasizing Texas in red\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry, fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Lists of states by winning party from the 2000 election data\ndemocrat_states &lt;- c(\"ARKANSAS\", \"CONNECTICUT\", \"HAWAII\", \"MAINE\", \"MASSACHUSETTS\", \"NEW MEXICO\", \n                     \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"RHODE ISLAND\", \"WASHINGTON\", \"WEST VIRGINIA\")\n\nrepublican_states &lt;- c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"CALIFORNIA\", \"COLORADO\", \"DELAWARE\", \n                       \"FLORIDA\", \"GEORGIA\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \"KANSAS\", \n                       \"KENTUCKY\", \"LOUISIANA\", \"MARYLAND\", \"MICHIGAN\", \"MINNESOTA\", \"MISSISSIPPI\", \n                       \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \"NEW JERSEY\", \n                       \"OHIO\", \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"SOUTH CAROLINA\", \n                       \"SOUTH DAKOTA\", \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VIRGINIA\", \"WISCONSIN\", \"WYOMING\")\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\",\n    TRUE ~ NA_character_  # Assign NA for states with no party assignment\n  ))\n\n# Plot with color coding for winning parties, leaving unassigned areas transparent\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry, fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), na.value = \"transparent\") +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Ensure Alaska is set to blue (Democratic) for this visualization\ndemocrat_states &lt;- c(democrat_states, \"ALASKA\")  # Add Alaska to Democrat states if not present\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\",\n    TRUE ~ NA_character_  # Assign NA for states with no party assignment\n  ))\n\n# Plot with color coding for winning parties, ensuring Alaska is blue\nggplot(shapefile_data_2000) +\n  geom_sf(aes(geometry = geometry, fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), na.value = \"transparent\") +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define paths\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load shapefile data\nshapefile_data_2000 &lt;- read_sf(shapefile_path)\n\n# Lists of states by winning party from the 2000 election data\ndemocrat_states &lt;- c(\"ARKANSAS\", \"CONNECTICUT\", \"HAWAII\", \"MAINE\", \"MASSACHUSETTS\", \"NEW MEXICO\", \n                     \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"RHODE ISLAND\", \"WASHINGTON\", \"WEST VIRGINIA\")\n\nrepublican_states &lt;- c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"CALIFORNIA\", \"COLORADO\", \"DELAWARE\", \n                       \"FLORIDA\", \"GEORGIA\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \"KANSAS\", \n                       \"KENTUCKY\", \"LOUISIANA\", \"MARYLAND\", \"MICHIGAN\", \"MINNESOTA\", \"MISSISSIPPI\", \n                       \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \"NEW JERSEY\", \n                       \"OHIO\", \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"SOUTH CAROLINA\", \n                       \"SOUTH DAKOTA\", \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VIRGINIA\", \"WISCONSIN\", \"WYOMING\")\n\n# Add a new column to the shapefile data to store the party color based on the state\nshapefile_data_2000 &lt;- shapefile_data_2000 %&gt;%\n  mutate(party = case_when(\n    STATENAME %in% democrat_states ~ \"DEMOCRAT\",\n    STATENAME %in% republican_states ~ \"REPUBLICAN\",\n    TRUE ~ NA_character_  # Assign NA for states with no party assignment\n  ))\n\n# Plot with color coding for winning parties\nggplot(shapefile_data_2000) +\n  geom_sf(aes(fill = party), color = \"black\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), na.value = \"transparent\") +\n  labs(title = \"Congressional Districts by Winning Party for the 94th Congress (Year 2000)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\n\n# Remove geometry temporarily and count districts by state\ndistrict_counts_by_state &lt;- shapefile_data_2000 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry temporarily\n  group_by(STATENAME) %&gt;%\n  summarize(num_districts = n_distinct(DISTRICT)) %&gt;%\n  arrange(desc(num_districts))\n\n# Print the results\ncat(\"Number of Districts by State:\\n\")\n\nNumber of Districts by State:\n\nprint(district_counts_by_state)\n\n# A tibble: 50 × 2\n   STATENAME     num_districts\n   &lt;chr&gt;                 &lt;int&gt;\n 1 California               43\n 2 New York                 39\n 3 Pennsylvania             25\n 4 Illinois                 24\n 5 Texas                    24\n 6 Ohio                     23\n 7 Michigan                 19\n 8 Florida                  15\n 9 New Jersey               15\n10 Massachusetts            12\n# ℹ 40 more rows\n\n\n\n# Install and load necessary libraries\nif (!requireNamespace(\"sf\", quietly = TRUE)) install.packages(\"sf\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n\nlibrary(sf)\nlibrary(ggplot2)\n\n# Define the path to the shapefile (update with your specific file path)\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile data as an sf object\ndistricts &lt;- read_sf(shapefile_path)\n\n# Check the structure of the shapefile data to confirm it's loaded correctly\nprint(summary(districts))\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE        FROMCOUNTY               geometry  \n Length:435         Length:435         Mode :logical   MULTIPOLYGON :435  \n Class :character   Class :character   FALSE:381       epsg:4269    :  0  \n Mode  :character   Mode  :character   TRUE :54        +proj=long...:  0  \n\n# Add a color column to color California districts blue, others red\ndistricts$color &lt;- ifelse(districts$STATENAME == \"California\", \"blue\", \"red\")\n\n# Plot the map with colors for each district\nggplot(data = districts) + \n  geom_sf(aes(fill = color)) +\n  scale_fill_identity() +\n  theme_minimal() +\n  labs(title = \"State Districts (California in Blue, Others in Red)\")\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\n\n# Define the file path to the election data CSV\nfile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/cleaned_house_vote_data.csv\"\n\n# Read the election data\nvote_data &lt;- read.csv(file_path)\n\n# Filter the data for the year 2000\nvote_data_2000 &lt;- vote_data %&gt;%\n  filter(year == 2000)\n\n# Summarize total votes by state and party\nstate_party_votes &lt;- vote_data_2000 %&gt;%\n  group_by(state, party) %&gt;%\n  summarize(total_votes = sum(vote_count, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Determine the winning party for each state\nstate_winner &lt;- state_party_votes %&gt;%\n  group_by(state) %&gt;%\n  slice_max(order_by = total_votes, n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(winning_party = if_else(party == \"DEMOCRAT\", \"Blue\", \"Red\")) %&gt;%\n  select(state, winning_party)\n\n# Create variables to store the Red and Blue states\nblue_states &lt;- state_winner %&gt;%\n  filter(winning_party == \"Blue\") %&gt;%\n  pull(state)\n\nred_states &lt;- state_winner %&gt;%\n  filter(winning_party == \"Red\") %&gt;%\n  pull(state)\n\n# Print the results\ncat(\"Winning Party by State for the Year 2000:\\n\")\n\nWinning Party by State for the Year 2000:\n\nprint(state_winner)\n\n# A tibble: 50 × 2\n   state       winning_party\n   &lt;chr&gt;       &lt;chr&gt;        \n 1 ALABAMA     Red          \n 2 ALASKA      Red          \n 3 ARIZONA     Red          \n 4 ARKANSAS    Blue         \n 5 CALIFORNIA  Blue         \n 6 COLORADO    Red          \n 7 CONNECTICUT Blue         \n 8 DELAWARE    Red          \n 9 FLORIDA     Red          \n10 GEORGIA     Red          \n# ℹ 40 more rows\n\ncat(\"\\nBlue States (Democrat Wins):\\n\")\n\n\nBlue States (Democrat Wins):\n\nprint(blue_states)\n\n [1] \"ARKANSAS\"      \"CALIFORNIA\"    \"CONNECTICUT\"   \"HAWAII\"       \n [5] \"ILLINOIS\"      \"MAINE\"         \"MARYLAND\"      \"MASSACHUSETTS\"\n [9] \"MICHIGAN\"      \"MISSISSIPPI\"   \"MISSOURI\"      \"NEW JERSEY\"   \n[13] \"NEW MEXICO\"    \"NEW YORK\"      \"NORTH DAKOTA\"  \"OREGON\"       \n[17] \"PENNSYLVANIA\"  \"RHODE ISLAND\"  \"WASHINGTON\"    \"WEST VIRGINIA\"\n\ncat(\"\\nRed States (Republican Wins):\\n\")\n\n\nRed States (Republican Wins):\n\nprint(red_states)\n\n [1] \"ALABAMA\"        \"ALASKA\"         \"ARIZONA\"        \"COLORADO\"      \n [5] \"DELAWARE\"       \"FLORIDA\"        \"GEORGIA\"        \"IDAHO\"         \n [9] \"INDIANA\"        \"IOWA\"           \"KANSAS\"         \"KENTUCKY\"      \n[13] \"LOUISIANA\"      \"MINNESOTA\"      \"MONTANA\"        \"NEBRASKA\"      \n[17] \"NEVADA\"         \"NEW HAMPSHIRE\"  \"NORTH CAROLINA\" \"OHIO\"          \n[21] \"OKLAHOMA\"       \"SOUTH CAROLINA\" \"SOUTH DAKOTA\"   \"TENNESSEE\"     \n[25] \"TEXAS\"          \"UTAH\"           \"VERMONT\"        \"VIRGINIA\"      \n[29] \"WISCONSIN\"      \"WYOMING\"       \n\n\n\n# Define the path to the shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile for congressional districts\ndistricts &lt;- read_sf(shapefile_path)\n\n# Assume blue_states and red_states are already defined\n# For example:\n# blue_states &lt;- c(\"California\", \"New York\", \"Washington\")  \n# red_states &lt;- c(\"Texas\", \"Florida\", \"Alabama\")            \n\n# Add a color column based on whether the district is in a blue or red state\ndistricts$color &lt;- ifelse(districts$STATENAME %in% democrat_states, \"blue\",\n                          ifelse(districts$STATENAME %in% republican_states, \"red\", NA))\n\n# Plot the map with colors for each district\nggplot(data = districts) + \n  geom_sf(aes(fill = color)) +\n  scale_fill_identity() +\n  theme_minimal() +\n  labs(title = \"State Districts by Party (Blue and Red States)\")\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define the path to the shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile for congressional districts\ndistricts &lt;- read_sf(shapefile_path)\n\n# Define mutually exclusive lists for blue and red states\n\nblue_party_states &lt;- c(\"California\", \"New York\", \"Washington\", \"Oregon\", \"Maryland\", \n                       \"Connecticut\", \"Delaware\", \"Hawaii\", \"Illinois\", \"Maine\", \n                       \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Nevada\", \n                       \"New Jersey\", \"New Mexico\", \"Rhode Island\", \"Vermont\", \n                       \"Virginia\", \"Wisconsin\", \"Colorado\",\"Pennsylvania\", \"New Hampshire\" )\n\nred_party_states &lt;- c(\"Texas\", \"Florida\", \"Georgia\", \"Arizona\", \"Ohio\", \n                      \"Alabama\", \"Alaska\", \"Arkansas\", \"Idaho\", \"Indiana\", \n                      \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Mississippi\", \n                      \"Missouri\", \"Montana\", \"Nebraska\", \"North Carolina\", \n                      \"North Dakota\", \"Oklahoma\", \"South Carolina\", \"South Dakota\", \n                      \"Tennessee\", \"Utah\", \"West Virginia\", \"Wyoming\")\n\n\n# Add a color column based on whether the district is in a blue or red state\ndistricts$color &lt;- ifelse(districts$STATENAME %in% blue_party_states, \"blue\",\n                          ifelse(districts$STATENAME %in% red_party_states, \"red\", NA))\n\n# Plot the map with colors for each district\nggplot(data = districts) + \n  geom_sf(aes(fill = color), color = NA) +  # Remove border lines by setting color to NA\n  scale_fill_identity() +\n  theme_minimal() +\n  labs(title = \"State Districts by Party (Blue and Red States)\")\n\n\n\n\n\n\n\n# Check for any districts without a color\ndistricts_missing_color &lt;- districts %&gt;% filter(is.na(color))\nprint(districts_missing_color)\n\nSimple feature collection with 0 features and 16 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  NAD83\n# A tibble: 0 × 17\n# ℹ 17 variables: STATENAME &lt;chr&gt;, ID &lt;chr&gt;, DISTRICT &lt;chr&gt;, STARTCONG &lt;chr&gt;,\n#   ENDCONG &lt;chr&gt;, DISTRICTSI &lt;chr&gt;, COUNTY &lt;chr&gt;, PAGE &lt;chr&gt;, LAW &lt;chr&gt;,\n#   NOTE &lt;chr&gt;, BESTDEC &lt;chr&gt;, FINALNOTE &lt;chr&gt;, RNOTE &lt;chr&gt;, LASTCHANGE &lt;chr&gt;,\n#   FROMCOUNTY &lt;lgl&gt;, geometry &lt;GEOMETRY [°]&gt;, color &lt;chr&gt;\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define the path to the shapefile\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile for congressional districts\ndistricts &lt;- read_sf(shapefile_path)\n\n# Define regions\nnortheast_states &lt;- c(\"Connecticut\", \"Maine\", \"Massachusetts\", \"New Hampshire\", \"Rhode Island\", \n                      \"Vermont\", \"New Jersey\", \"New York\", \"Pennsylvania\")\n\nsoutheast_states &lt;- c(\"Alabama\", \"Arkansas\", \"Delaware\", \"Florida\", \"Georgia\", \"Kentucky\", \n                      \"Louisiana\", \"Maryland\", \"Mississippi\", \"North Carolina\", \"South Carolina\", \n                      \"Tennessee\", \"Virginia\", \"West Virginia\")\n\ncentral_states &lt;- c(\"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Michigan\", \"Minnesota\", \"Missouri\", \n                    \"Nebraska\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"South Dakota\", \"Wisconsin\")\n\nsouthwest_states &lt;- c(\"Arizona\", \"New Mexico\", \"Texas\", \"Nevada\")\n\nnorthwest_states &lt;- c(\"Alaska\", \"Idaho\", \"Montana\", \"Oregon\", \"Washington\", \"Wyoming\", \"Utah\", \n                      \"Colorado\")\n\n# Define blue and red states for 2020\nblue_party_states_2020 &lt;- c(\"California\", \"New York\", \"Washington\", \"Oregon\", \"Maryland\", \n                            \"Connecticut\", \"Delaware\", \"Hawaii\", \"Illinois\", \"Maine\", \n                            \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Nevada\", \n                            \"New Jersey\", \"New Mexico\", \"Rhode Island\", \"Vermont\", \n                            \"Virginia\", \"Wisconsin\", \"Colorado\", \"Pennsylvania\", \"New Hampshire\")\n\nred_party_states_2020 &lt;- c(\"Texas\", \"Florida\", \"Georgia\", \"Arizona\", \"Ohio\", \n                           \"Alabama\", \"Alaska\", \"Arkansas\", \"Idaho\", \"Indiana\", \n                           \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Mississippi\", \n                           \"Missouri\", \"Montana\", \"Nebraska\", \"North Carolina\", \n                           \"North Dakota\", \"Oklahoma\", \"South Carolina\", \"South Dakota\", \n                           \"Tennessee\", \"Utah\", \"West Virginia\", \"Wyoming\")\n\n# Add a color column based on whether the district is in a blue or red state for 2020\ndistricts$color &lt;- ifelse(districts$STATENAME %in% blue_party_states_2020, \"blue\",\n                          ifelse(districts$STATENAME %in% red_party_states_2020, \"red\", NA))\n\n# Define function to plot and analyze regions\nplot_region &lt;- function(region_states, region_name) {\n  # Filter districts for the specific region\n  region_districts &lt;- districts %&gt;% filter(STATENAME %in% region_states)\n  \n  # Count blue and red districts\n  blue_count &lt;- sum(region_districts$color == \"blue\", na.rm = TRUE)\n  red_count &lt;- sum(region_districts$color == \"red\", na.rm = TRUE)\n  \n  # Determine majority color\n  majority &lt;- if (blue_count &gt; red_count) \"Blue\" else \"Red\"\n  \n  # Plot the map for the region\n  ggplot(data = region_districts) + \n    geom_sf(aes(fill = color), color = NA) +\n    scale_fill_identity() +\n    theme_minimal() +\n    labs(title = paste(region_name, \"Region - Majority:\", majority),\n         subtitle = paste(\"Blue:\", blue_count, \"Red:\", red_count))\n}\n\n# Plot each region and comment on majority\nnortheast_plot &lt;- plot_region(northeast_states, \"Northeast\")\nsoutheast_plot &lt;- plot_region(southeast_states, \"Southeast\")\ncentral_plot &lt;- plot_region(central_states, \"Central\")\nsouthwest_plot &lt;- plot_region(southwest_states, \"Southwest\")\nnorthwest_plot &lt;- plot_region(northwest_states, \"Northwest\")\n\n# Print each plot (for display in interactive environments)\nprint(northeast_plot)\n\n\n\n\n\n\n\nprint(southeast_plot)\n\n\n\n\n\n\n\nprint(central_plot)\n\n\n\n\n\n\n\nprint(southwest_plot)\n\n\n\n\n\n\n\nprint(northwest_plot)\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define the path to the shapefile for districts\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile for congressional districts\ndistricts &lt;- read_sf(shapefile_path)\n\n# Define 2020 blue and red states\nblue_party_states_2020 &lt;- c(\"California\", \"New York\", \"Washington\", \"Oregon\", \"Maryland\", \n                            \"Connecticut\", \"Delaware\", \"Hawaii\", \"Illinois\", \"Maine\", \n                            \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Nevada\", \n                            \"New Jersey\", \"New Mexico\", \"Rhode Island\", \"Vermont\", \n                            \"Virginia\", \"Wisconsin\", \"Colorado\", \"Pennsylvania\", \"New Hampshire\")\n\nred_party_states_2020 &lt;- c(\"Texas\", \"Florida\", \"Georgia\", \"Arizona\", \"Ohio\", \n                           \"Alabama\", \"Alaska\", \"Arkansas\", \"Idaho\", \"Indiana\", \n                           \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Mississippi\", \n                           \"Missouri\", \"Montana\", \"Nebraska\", \"North Carolina\", \n                           \"North Dakota\", \"Oklahoma\", \"South Carolina\", \"South Dakota\", \n                           \"Tennessee\", \"Utah\", \"West Virginia\", \"Wyoming\")\n\n# Add a color column to the districts based on the 2020 winning party\ndistricts$color &lt;- ifelse(districts$STATENAME %in% blue_party_states_2020, \"blue\",\n                          ifelse(districts$STATENAME %in% red_party_states_2020, \"red\", NA))\n\n# Step 1: Aggregate districts into single state polygons\nstates &lt;- districts %&gt;%\n  group_by(STATENAME) %&gt;%\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n# Define regions\nnortheast &lt;- c(\"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Rhode Island\", \n               \"Connecticut\", \"New York\", \"New Jersey\", \"Pennsylvania\")\nsoutheast &lt;- c(\"Delaware\", \"Maryland\", \"Virginia\", \"West Virginia\", \"Kentucky\", \n               \"Tennessee\", \"North Carolina\", \"South Carolina\", \"Georgia\", \"Florida\", \"Alabama\", \"Mississippi\")\nmidwest &lt;- c(\"Ohio\", \"Indiana\", \"Illinois\", \"Michigan\", \"Wisconsin\", \n             \"Minnesota\", \"Iowa\", \"Missouri\", \"North Dakota\", \"South Dakota\", \"Nebraska\", \"Kansas\")\nsouthwest &lt;- c(\"Texas\", \"Oklahoma\", \"New Mexico\", \"Arizona\")\nwest &lt;- c(\"Colorado\", \"Wyoming\", \"Montana\", \"Idaho\", \"Washington\", \"Oregon\", \"California\", \"Nevada\", \"Utah\", \"Alaska\", \"Hawaii\")\n\n# Function to plot a region\nplot_region &lt;- function(region_states, title) {\n  region_states_data &lt;- states %&gt;% filter(STATENAME %in% region_states)\n  \n  ggplot() + \n    geom_sf(data = districts %&gt;% filter(STATENAME %in% region_states), aes(fill = color), color = NA) +\n    geom_sf(data = region_states_data, fill = NA, color = \"#333333\", size = 0.7) +\n    scale_fill_identity() +\n    theme_minimal() +\n    labs(title = title)\n}\n\n# Plot each region\nplot_northeast &lt;- plot_region(northeast, \"Northeast Region - Party Distribution\")\nplot_southeast &lt;- plot_region(southeast, \"Southeast Region - Party Distribution\")\nplot_midwest &lt;- plot_region(midwest, \"Midwest Region - Party Distribution\")\nplot_southwest &lt;- plot_region(southwest, \"Southwest Region - Party Distribution\")\nplot_west &lt;- plot_region(west, \"Western Region - Party Distribution\")\n\n# Display the plots\nplot_northeast\n\n\n\n\n\n\n\nplot_southeast\n\n\n\n\n\n\n\nplot_midwest\n\n\n\n\n\n\n\nplot_southwest\n\n\n\n\n\n\n\nplot_west\n\n\n\n\n\n\n\n\n\n# Install necessary packages if not already installed\nif (!requireNamespace(\"sf\", quietly = TRUE)) install.packages(\"sf\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) install.packages(\"dplyr\")\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define the path to the shapefile (replace with your actual path)\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile\ndistricts &lt;- read_sf(shapefile_path)\n\n# Create a data frame for electoral votes\nelectoral_votes &lt;- data.frame(\n  STATENAME = c(\"Alabama\", \"Kentucky\", \"North Dakota\", \"Alaska\", \"Louisiana\", \"Ohio\", \n                \"Arizona\", \"Maine\", \"Oklahoma\", \"Arkansas\", \"Maryland\", \"Oregon\", \n                \"California\", \"Massachusetts\", \"Pennsylvania\", \"Colorado\", \"Michigan\", \n                \"Rhode Island\", \"Connecticut\", \"Minnesota\", \"South Carolina\", \"Delaware\", \n                \"Mississippi\", \"South Dakota\", \"District of Columbia\", \"Missouri\", \"Tennessee\", \n                \"Florida\", \"Montana\", \"Texas\", \"Georgia\", \"Nebraska\", \"Utah\", \"Hawaii\", \n                \"Nevada\", \"Vermont\", \"Idaho\", \"New Hampshire\", \"Virginia\", \"Illinois\", \n                \"New Jersey\", \"Washington\", \"Indiana\", \"New Mexico\", \"West Virginia\", \n                \"Iowa\", \"New York\", \"Wisconsin\", \"Kansas\", \"North Carolina\", \"Wyoming\"),\n  votes = c(9, 8, 3, 3, 8, 17, 11, 4, 7, 6, 10, 8, 54, 11, 19, 10, 15, 4, 7, 10, \n            9, 3, 6, 3, 3, 10, 11, 30, 4, 40, 16, 5, 6, 4, 6, 3, 4, 4, 13, 19, \n            14, 12, 11, 5, 4, 6, 28, 10, 6, 16, 3)\n)\n\n# Ensure `STATENAME` in the shapefile is in the same format as the electoral_votes data\ndistricts$STATENAME &lt;- as.character(districts$STATENAME)\n\n# Aggregate districts into single state polygons\nstates &lt;- districts %&gt;%\n  group_by(STATENAME) %&gt;%\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n# Merge electoral votes data with the state geometry data\nstates &lt;- states %&gt;%\n  left_join(electoral_votes, by = \"STATENAME\")\n\n# Custom color palette\ncustom_palette &lt;- c(\"#FFF9C4\", \"#FFE082\", \"#FFCA28\", \"#FFB300\", \"#FF8F00\", \"#F57C00\", \"#E65100\")\n\n# Plot the US map with electoral votes by state\n# Alaska and Hawaii positioning is adjusted manually\nggplot() +\n  geom_sf(data = states, aes(fill = votes), color = \"grey30\", size = 0.2) +\n  # Separate Alaska and Hawaii with custom transformations\n  geom_sf(data = states %&gt;% filter(STATENAME == \"Alaska\"),\n          aes(fill = votes), color = \"grey30\", size = 0.2) +\n  coord_sf(crs = st_crs(5070), xlim = c(-170, -130), ylim = c(50, 72)) + # Move Alaska\n  geom_sf(data = states %&gt;% filter(STATENAME == \"Hawaii\"),\n          aes(fill = votes), color = \"grey30\", size = 0.2) +\n  coord_sf(crs = st_crs(5070), xlim = c(-160, -154), ylim = c(18, 23)) + # Move Hawaii\n  scale_fill_gradientn(colors = custom_palette, na.value = \"gray90\", name = \"Votes\") +\n  labs(\n    title = \"Number of Electoral Votes by State\",\n    subtitle = \"Electoral votes for the 2024 election are allocated to states based on the 2020 Census.\"\n  ) +\n  theme_minimal(base_size = 18) +  # Increase base size for larger plot\n  theme(\n    plot.title = element_text(size = 24, hjust = 0.5),\n    plot.subtitle = element_text(size = 14, hjust = 0.5),\n    legend.position = \"right\"\n  ) +\n  theme(legend.title = element_text(size = 14), legend.text = element_text(size = 12)) +\n  coord_sf(crs = st_crs(5070), expand = FALSE)  # Adjust projection to show the continental US\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\npresidential_data &lt;- read.csv(\"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\")\n\n# Install usmap package if not already installed\nif (!requireNamespace(\"usmap\", quietly = TRUE)) install.packages(\"usmap\")\n\n# Load usmap\nlibrary(usmap)\n\nplot_usmap(regions = \"states\") \n\n\n\n\n\n\n\nhead(presidential_data)\n\n  year   state state_po state_fips state_cen state_ic       office\n1 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n2 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n3 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n4 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n5 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n6 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n                candidate             party_detailed writein candidatevotes\n1           CARTER, JIMMY                   DEMOCRAT   FALSE         659170\n2            FORD, GERALD                 REPUBLICAN   FALSE         504070\n3          MADDOX, LESTER AMERICAN INDEPENDENT PARTY   FALSE           9198\n4 BUBAR, BENJAMIN \"\"BEN\"\"                PROHIBITION   FALSE           6669\n5               HALL, GUS        COMMUNIST PARTY USE   FALSE           1954\n6         MACBRIDE, ROGER                LIBERTARIAN   FALSE           1481\n  totalvotes  version notes party_simplified\n1    1182850 20210113    NA         DEMOCRAT\n2    1182850 20210113    NA       REPUBLICAN\n3    1182850 20210113    NA            OTHER\n4    1182850 20210113    NA            OTHER\n5    1182850 20210113    NA            OTHER\n6    1182850 20210113    NA      LIBERTARIAN\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(usmap)\nlibrary(maps)\n\n# Load your data (update with the actual path if needed)\npresidential_data &lt;- read.csv(\"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\")\n\n# Filter data for the year 2020\npresidential_data_2020 &lt;- presidential_data %&gt;%\n  filter(year == 2020)\n\n# Identify the winning party in each state by the highest percentage of votes\nmax_percent_rows &lt;- presidential_data_2020 %&gt;%\n  group_by(state) %&gt;%\n  filter(candidatevotes == max(candidatevotes)) %&gt;%\n  ungroup()\n\n# Extract states won by Democrats\nBlue_states &lt;- max_percent_rows %&gt;%\n  filter(party_simplified == \"DEMOCRAT\") %&gt;%\n  pull(state) %&gt;%\n  tolower()  # Convert state names to lowercase to match `map_data`\n\n# Prepare the map data for ggplot\nmap_data &lt;- map_data(\"state\")\nmap_data$fill &lt;- ifelse(map_data$region %in% Blue_states, \"blue\", \"red\")  # Color Democrats blue, others red\n\n# Plot the map\nggplot() +\n  geom_map(data = map_data, map = map_data,\n           aes(x = long, y = lat, map_id = region, fill = fill),\n           color = \"white\", size = 0.25) +\n  scale_fill_identity() +\n  labs(title = \"US Presidential Election Results by State - 2020\",\n       subtitle = \"Blue: Democrat, Red: Republican\") +\n  theme_void() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),\n    plot.subtitle = element_text(hjust = 0.5, size = 12)\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(maps)\n\n# Load your presidential election data (adjust the path as needed)\npresidential_data &lt;- read.csv(\"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/1976-2020-president.csv\")\n\n# Filter data for the year 2020\npresidential_data_2020 &lt;- presidential_data %&gt;%\n  filter(year == 2020)\n\n# Calculate the percentage of votes each candidate received in each state\npresidential_data_2020 &lt;- presidential_data_2020 %&gt;%\n  group_by(state) %&gt;%\n  mutate(Percent = (candidatevotes / totalvotes) * 100)\n\n# Identify the winning party in each state by the highest percentage of votes\nmax_percent_rows &lt;- presidential_data_2020 %&gt;%\n  group_by(state) %&gt;%\n  filter(Percent == max(Percent)) %&gt;%\n  ungroup()\n\n# Extract states won by Democrats and Republicans\nBlue_states &lt;- max_percent_rows %&gt;%\n  filter(party_simplified == \"DEMOCRAT\") %&gt;%\n  pull(state) %&gt;%\n  tolower()\n\nRed_states &lt;- max_percent_rows %&gt;%\n  filter(party_simplified == \"REPUBLICAN\") %&gt;%\n  pull(state) %&gt;%\n  tolower()\n\n# Prepare states and their percentages for mapping\nstates_and_percentages &lt;- data.frame(\n  region = tolower(max_percent_rows$state),\n  percent = max_percent_rows$Percent\n)\n\n# Create map data with fill color based on the party and transparency based on percentage\nmap_data &lt;- map_data(\"state\")\nmap_data$fill &lt;- ifelse(map_data$region %in% Blue_states, \"blue\",\n                        ifelse(map_data$region %in% Red_states, \"red\", \"purple\"))\n\n# Join vote percentage data with map data\nmap_data &lt;- left_join(map_data, states_and_percentages, by = \"region\")\n\n# Plot the map\nggplot() +\n  geom_map(data = map_data, map = map_data,\n           aes(x = long, y = lat, map_id = region, fill = fill, alpha = percent),\n           color = \"white\", size = 0.25) +\n  scale_fill_manual(values = c(\"blue\" = \"blue\", \"red\" = \"red\", \"purple\" = \"purple\"),\n                    labels = c(\"Democrat\", \"Republican\", \"Other\"),\n                    drop = FALSE) +\n  labs(title = \"How States Voted in the 2020 Presidential Election\") +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.background = element_rect(fill = \"white\", color = \"white\"),\n        panel.background = element_rect(fill = \"white\"),\n        axis.title = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        legend.position = \"none\") +\n  guides(fill = guide_legend(title = \"Party\"))\n\n\n\n\n\n\n\n\n\n# Install necessary packages if not already installed\nif (!requireNamespace(\"sf\", quietly = TRUE)) install.packages(\"sf\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) install.packages(\"dplyr\")\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Define the path to the shapefile (replace with your actual path)\nshapefile_path &lt;- \"C:/Users/alien/OneDrive/Documents/STA9750-2024-FALL/Mini 03 Data/congress_shapefiles/congress_094/districtShapes/districts094.shp\"\n\n# Load the shapefile\ndistricts &lt;- read_sf(shapefile_path)\n\n# Create a data frame for electoral votes\nelectoral_votes &lt;- data.frame(\n  STATENAME = c(\"Alabama\", \"Kentucky\", \"North Dakota\", \"Alaska\", \"Louisiana\", \"Ohio\", \n                \"Arizona\", \"Maine\", \"Oklahoma\", \"Arkansas\", \"Maryland\", \"Oregon\", \n                \"California\", \"Massachusetts\", \"Pennsylvania\", \"Colorado\", \"Michigan\", \n                \"Rhode Island\", \"Connecticut\", \"Minnesota\", \"South Carolina\", \"Delaware\", \n                \"Mississippi\", \"South Dakota\", \"District of Columbia\", \"Missouri\", \"Tennessee\", \n                \"Florida\", \"Montana\", \"Texas\", \"Georgia\", \"Nebraska\", \"Utah\", \"Hawaii\", \n                \"Nevada\", \"Vermont\", \"Idaho\", \"New Hampshire\", \"Virginia\", \"Illinois\", \n                \"New Jersey\", \"Washington\", \"Indiana\", \"New Mexico\", \"West Virginia\", \n                \"Iowa\", \"New York\", \"Wisconsin\", \"Kansas\", \"North Carolina\", \"Wyoming\"),\n  votes = c(9, 8, 3, 3, 8, 17, 11, 4, 7, 6, 10, 8, 54, 11, 19, 10, 15, 4, 7, 10, \n            9, 3, 6, 3, 3, 10, 11, 30, 4, 40, 16, 5, 6, 4, 6, 3, 4, 4, 13, 19, \n            14, 12, 11, 5, 4, 6, 28, 10, 6, 16, 3)\n)\n\n# Ensure `STATENAME` in the shapefile is in the same format as the electoral_votes data\ndistricts$STATENAME &lt;- as.character(districts$STATENAME)\n\n# Aggregate districts into single state polygons\nstates &lt;- districts %&gt;%\n  group_by(STATENAME) %&gt;%\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n# Merge electoral votes data with the state geometry data\nstates &lt;- states %&gt;%\n  left_join(electoral_votes, by = \"STATENAME\")\n\n# Custom color palette for electoral votes\ncustom_palette &lt;- c(\"#FFF9C4\", \"#FFE082\", \"#FFCA28\", \"#FFB300\", \"#FF8F00\", \"#F57C00\", \"#E65100\")\n\n# Separate data for Alaska and Hawaii for manual repositioning\ncontinental_states &lt;- states %&gt;% filter(!STATENAME %in% c(\"Alaska\", \"Hawaii\"))\nalaska &lt;- states %&gt;% filter(STATENAME == \"Alaska\") %&gt;% st_transform(crs = st_crs(5070))\nhawaii &lt;- states %&gt;% filter(STATENAME == \"Hawaii\") %&gt;% st_transform(crs = st_crs(5070))\n\n# Plot the US map with electoral votes by state, adjusting Alaska and Hawaii\nggplot() +\n  geom_sf(data = continental_states, aes(fill = votes), color = \"grey30\", size = 0.2) +\n  # Alaska repositioned in a separate viewport\n  geom_sf(data = alaska, aes(fill = votes), color = \"grey30\", size = 0.2) +\n  coord_sf(xlim = c(-2400000, -1200000), ylim = c(2100000, 3500000), datum = NA) +\n  # Hawaii repositioned in a separate viewport\n  geom_sf(data = hawaii, aes(fill = votes), color = \"grey30\", size = 0.2) +\n  coord_sf(xlim = c(5000000, 5500000), ylim = c(1000000, 1600000), datum = NA) +\n  scale_fill_gradientn(colors = custom_palette, na.value = \"gray90\", name = \"Votes\") +\n  labs(\n    title = \"Number of Electoral Votes by State\",\n    subtitle = \"Electoral votes for the 2024 election are allocated to states based on the 2020 Census.\"\n  ) +\n  theme_minimal(base_size = 18) +  # Increase base size for larger plot\n  theme(\n    plot.title = element_text(size = 24, hjust = 0.5),\n    plot.subtitle = element_text(size = 14, hjust = 0.5),\n    legend.position = \"right\"\n  ) +\n  theme(legend.title = element_text(size = 14), legend.text = element_text(size = 12)) +\n  coord_sf(crs = st_crs(5070), expand = FALSE)  # Adjust projection to show the continental US\n\n\n\n\n\n\n\n\n\n# Install necessary packages if not already installed\nif (!requireNamespace(\"choroplethr\", quietly = TRUE)) install.packages(\"choroplethr\")\nif (!requireNamespace(\"gganimate\", quietly = TRUE)) install.packages(\"gganimate\")\nif (!requireNamespace(\"gifski\", quietly = TRUE)) install.packages(\"gifski\")\nlibrary(choroplethr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(maps)\n\n# Load election data\ndata(\"df_president_ts\", package = \"choroplethr\")\n\n# Prepare election data for animation\nus &lt;- map_data(\"state\")\n\n# Filter for specific election years\nelection_years &lt;- c(2000, 2004, 2008, 2012, 2016, 2020)\n\n# Prepare and clean the elections data to ensure one row per state and year\nelections &lt;- df_president_ts %&gt;%\n  gather(year, winner, `1789`:`2012`) %&gt;%\n  filter(as.numeric(year) %in% election_years) %&gt;%  # Filter for specific election years\n  mutate(year = as.integer(year)) %&gt;%\n  group_by(year, region) %&gt;%\n  slice(1) %&gt;%  # Keep only the first entry per state and year if duplicates exist\n  ungroup() %&gt;%\n  mutate(party = case_when(\n    winner %in% c(\"SR\", \"I\", \"AI\", \"PR\") ~ \"Third Party\",\n    winner == \"D\" ~ \"Democrat\",\n    winner == \"R\" ~ \"Republican\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  right_join(us, by = c(\"region\" = \"region\"))\n\n# Create the animated plot\np &lt;- ggplot(data = elections, aes(x = long, y = lat, group = group, fill = party)) +\n  geom_polygon(color = \"#f5f5f2\") +\n  coord_map(\"albers\", lat0 = 30, lat1 = 40) + \n  scale_fill_manual(values = c(\"Democrat\" = \"#4169E1\", \"Republican\" = \"#B91C1C\", \"Third Party\" = \"#FFA500\"), \n                    na.value = \"gray70\", name = \"Winning Party\") +\n  labs(title = \"US Presidential Election Results: {closest_state}\", fill = \"Winning Party\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 18))\n\n# Animate with transition by year using discrete states\np_animated &lt;- p +\n  transition_states(year, transition_length = 2, state_length = 1) +\n  ease_aes('linear')\n\n# Render the animation\nanimate(p_animated, fps = 1, nframes = length(election_years) * 5, width = 800, height = 600, renderer = gifski_renderer())"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#analysis-of-fusion-voting-impact-on-key-candidates",
    "href": "ElectionStudy03Ver33.html#analysis-of-fusion-voting-impact-on-key-candidates",
    "title": "Early Years:",
    "section": "Analysis of Fusion Voting Impact on Key Candidates",
    "text": "Analysis of Fusion Voting Impact on Key Candidates\nThis analysis explores the top 10 candidates who benefited the most from fusion voting, based on the increase in their vote count. Fusion voting allows candidates to be listed on multiple party lines, potentially increasing their total votes by appealing to a broader set of voters.\n\nKey Findings\n\nTop Beneficiary: Ronald Reagan, in his 1984 re-election campaign, received the highest increase in votes from fusion voting, with over 3.3 million additional votes. This substantial boost highlights Reagan’s cross-party appeal during his landslide victory.\nProminent Family Influence: Both George H.W. Bush (1988) and George W. Bush (2004) appear in the top four, reflecting the impact of fusion voting in supporting these Republican candidates. This added support likely contributed to their success in tightly contested races.\nHistorical Context: Gerald Ford (1976) and Robert Dole (1996) also benefited significantly from fusion voting. This strategic use of fusion voting allowed these candidates to gather cross-party support, showcasing its importance in past Republican campaigns.\nModern Influence - Donald Trump: Donald Trump ranks sixth, with a fusion voting increase of approximately 2.2 million votes in the 2016 election. Trump’s unique political appeal extended beyond traditional Republican lines, drawing support from additional party endorsements. This strategy reinforced his electoral base while reaching independent voters and those dissatisfied with traditional party structures.\nTotal Vote Impact: While most candidates gained millions of additional votes, the last two entries, Robert Dole and Chris Jacobs, benefited to a lesser extent, with increases under 200,000. This contrast underscores the varying degrees of fusion voting’s impact, depending on the candidate and election context.\nImplications for Political Strategy: Fusion voting can be a powerful approach to appeal to diverse voter bases, especially in competitive elections. For candidates with strong, distinct personas like Trump, fusion voting provides a pathway to engage voters across the political spectrum.\n\n\n\nTask 3: Comparison of Presidential vs. House Candidate Votes\nQuestion: Do presidential candidates tend to receive more or fewer votes than congressional candidates from their party in the same state?\n\n\nRows: 32452 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): state, state_po, office, stage, candidate, party, mode\ndbl (8): year, state_fips, state_cen, state_ic, district, candidatevotes, to...\nlgl (5): runoff, special, writein, unofficial, fusion_ticket\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 4287 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): state, state_po, office, candidate, party_detailed, party_simplified\ndbl (7): year, state_fips, state_cen, state_ic, candidatevotes, totalvotes, ...\nlgl (2): writein, notes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 5 × 1\n  state     \n  &lt;chr&gt;     \n1 CALIFORNIA\n2 FLORIDA   \n3 LOUISIANA \n4 NEW YORK  \n5 TEXAS     \n\n\n[1] \"CALIFORNIA\" \"FLORIDA\"    \"LOUISIANA\"  \"NEW YORK\"   \"TEXAS\"     \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nAnalysis for CALIFORNIA :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for FLORIDA :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for LOUISIANA :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Republican party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for NEW YORK :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for TEXAS :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time."
  },
  {
    "objectID": "ElectionStudy03Ver33.html#california",
    "href": "ElectionStudy03Ver33.html#california",
    "title": "Early Years:",
    "section": "California",
    "text": "California"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#we-created-a-map-of-the-us-with-all-the-districs",
    "href": "ElectionStudy03Ver33.html#we-created-a-map-of-the-us-with-all-the-districs",
    "title": "Early Years:",
    "section": "we created a map of the us with all the districs",
    "text": "we created a map of the us with all the districs\n\n\nWarning: package 'sf' was built under R version 4.4.2\n\n\nLinking to GEOS 3.12.2, GDAL 3.9.3, PROJ 9.4.1; sf_use_s2() is TRUE\n\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE        FROMCOUNTY               geometry  \n Length:435         Length:435         Mode :logical   MULTIPOLYGON :435  \n Class :character   Class :character   FALSE:381       epsg:4269    :  0  \n Mode  :character   Mode  :character   TRUE :54        +proj=long...:  0  \n\n\n\n\n\n\n\n\n\n [1] \"STATENAME\"  \"ID\"         \"DISTRICT\"   \"STARTCONG\"  \"ENDCONG\"   \n [6] \"DISTRICTSI\" \"COUNTY\"     \"PAGE\"       \"LAW\"        \"NOTE\"      \n[11] \"BESTDEC\"    \"FINALNOTE\"  \"RNOTE\"      \"LASTCHANGE\" \"FROMCOUNTY\"\n[16] \"geometry\"  \n\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.5993 ymin: 30.62397 xmax: -73.7243 ymax: 43.09876\nGeodetic CRS:  NAD83\n# A tibble: 6 × 16\n  STATENAME ID    DISTRICT STARTCONG ENDCONG DISTRICTSI COUNTY PAGE  LAW   NOTE \n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Californ… 0060… 27       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n2 Georgia   0130… 2        93        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n3 New York  0360… 10       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n4 New York  0360… 11       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n5 New York  0360… 37       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n6 New York  0360… 38       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n# ℹ 6 more variables: BESTDEC &lt;chr&gt;, FINALNOTE &lt;chr&gt;, RNOTE &lt;chr&gt;,\n#   LASTCHANGE &lt;chr&gt;, FROMCOUNTY &lt;lgl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nsf [435 × 16] (S3: sf/tbl_df/tbl/data.frame)\n $ STATENAME : chr [1:435] \"California\" \"Georgia\" \"New York\" \"New York\" ...\n $ ID        : chr [1:435] \"006094097027\" \"013093097002\" \"036094097010\" \"036094097011\" ...\n $ DISTRICT  : chr [1:435] \"27\" \"2\" \"10\" \"11\" ...\n $ STARTCONG : chr [1:435] \"94\" \"93\" \"94\" \"94\" ...\n $ ENDCONG   : chr [1:435] \"97\" \"97\" \"97\" \"97\" ...\n $ DISTRICTSI: chr [1:435] NA NA NA NA ...\n $ COUNTY    : chr [1:435] NA NA NA NA ...\n $ PAGE      : chr [1:435] NA NA NA NA ...\n $ LAW       : chr [1:435] NA NA NA NA ...\n $ NOTE      : chr [1:435] \"{\\\"Shape from shapes/Ftp_Upload/California_94-97cc/94-97cc_27cd_California.shp (17628 bytes, last modified on T\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/Georgia_93-97cc/93-97cc_2cd_Georgia.shp (87868 bytes, last modified on Thu Jul \"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_10cd_NewYork.shp (26408 bytes, last modified on Wed Dec\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_11cd_NewYork.shp (33916 bytes, last modified on Tue Feb\"| __truncated__ ...\n $ BESTDEC   : chr [1:435] NA NA NA NA ...\n $ FINALNOTE : chr [1:435] NA NA NA NA ...\n $ RNOTE     : chr [1:435] NA NA NA NA ...\n $ LASTCHANGE: chr [1:435] \"2016-05-20 13:07:35.318982\" \"2016-05-20 13:07:46.863044\" \"2016-05-20 13:09:35.392414\" \"2016-05-20 13:09:35.409757\" ...\n $ FROMCOUNTY: logi [1:435] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ geometry  :sfc_MULTIPOLYGON of length 435; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:1089, 1:2] -119 -119 -119 -119 -119 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"STATENAME\" \"ID\" \"DISTRICT\" \"STARTCONG\" ..."
  },
  {
    "objectID": "ElectionStudy03Ver33.html#these-are-the-number-of-districts-by-state",
    "href": "ElectionStudy03Ver33.html#these-are-the-number-of-districts-by-state",
    "title": "Early Years:",
    "section": "These are the number of districts by state",
    "text": "These are the number of districts by state\n\n\nNumber of Districts by State:\n\n\n# A tibble: 50 × 2\n   STATENAME     num_districts\n   &lt;chr&gt;                 &lt;int&gt;\n 1 California               43\n 2 New York                 39\n 3 Pennsylvania             25\n 4 Illinois                 24\n 5 Texas                    24\n 6 Ohio                     23\n 7 Michigan                 19\n 8 Florida                  15\n 9 New Jersey               15\n10 Massachusetts            12\n# ℹ 40 more rows"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#we-added-some-hypotecal-information-to-assign-colors-red-or-blue-to-the-map-by-state",
    "href": "ElectionStudy03Ver33.html#we-added-some-hypotecal-information-to-assign-colors-red-or-blue-to-the-map-by-state",
    "title": "Early Years:",
    "section": "we added some hypotecal information to assign colors (red or blue to the map by state)",
    "text": "we added some hypotecal information to assign colors (red or blue to the map by state)\n\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE        FROMCOUNTY               geometry  \n Length:435         Length:435         Mode :logical   MULTIPOLYGON :435  \n Class :character   Class :character   FALSE:381       epsg:4269    :  0  \n Mode  :character   Mode  :character   TRUE :54        +proj=long...:  0"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#here-we-list-all-the-red-republican-and-blue-democrat-states",
    "href": "ElectionStudy03Ver33.html#here-we-list-all-the-red-republican-and-blue-democrat-states",
    "title": "Early Years:",
    "section": "here we list all the red (Republican) and blue (Democrat) states",
    "text": "here we list all the red (Republican) and blue (Democrat) states\n\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\nWinning Party by State for the Year 2000:\n\n\n# A tibble: 50 × 2\n   state       winning_party\n   &lt;chr&gt;       &lt;chr&gt;        \n 1 ALABAMA     Red          \n 2 ALASKA      Red          \n 3 ARIZONA     Red          \n 4 ARKANSAS    Blue         \n 5 CALIFORNIA  Blue         \n 6 COLORADO    Red          \n 7 CONNECTICUT Blue         \n 8 DELAWARE    Red          \n 9 FLORIDA     Red          \n10 GEORGIA     Red          \n# ℹ 40 more rows\n\n\n\nBlue States (Democrat Wins):\n\n\n [1] \"ARKANSAS\"      \"CALIFORNIA\"    \"CONNECTICUT\"   \"HAWAII\"       \n [5] \"ILLINOIS\"      \"MAINE\"         \"MARYLAND\"      \"MASSACHUSETTS\"\n [9] \"MICHIGAN\"      \"MISSISSIPPI\"   \"MISSOURI\"      \"NEW JERSEY\"   \n[13] \"NEW MEXICO\"    \"NEW YORK\"      \"NORTH DAKOTA\"  \"OREGON\"       \n[17] \"PENNSYLVANIA\"  \"RHODE ISLAND\"  \"WASHINGTON\"    \"WEST VIRGINIA\"\n\n\n\nRed States (Republican Wins):\n\n\n [1] \"ALABAMA\"        \"ALASKA\"         \"ARIZONA\"        \"COLORADO\"      \n [5] \"DELAWARE\"       \"FLORIDA\"        \"GEORGIA\"        \"IDAHO\"         \n [9] \"INDIANA\"        \"IOWA\"           \"KANSAS\"         \"KENTUCKY\"      \n[13] \"LOUISIANA\"      \"MINNESOTA\"      \"MONTANA\"        \"NEBRASKA\"      \n[17] \"NEVADA\"         \"NEW HAMPSHIRE\"  \"NORTH CAROLINA\" \"OHIO\"          \n[21] \"OKLAHOMA\"       \"SOUTH CAROLINA\" \"SOUTH DAKOTA\"   \"TENNESSEE\"     \n[25] \"TEXAS\"          \"UTAH\"           \"VERMONT\"        \"VIRGINIA\"      \n[29] \"WISCONSIN\"      \"WYOMING\""
  },
  {
    "objectID": "ElectionStudy03Ver33.html#task-5-chloropleth-visualization-of-the-2000-presidential-election-electoral-college-results",
    "href": "ElectionStudy03Ver33.html#task-5-chloropleth-visualization-of-the-2000-presidential-election-electoral-college-results",
    "title": "Early Years:",
    "section": "Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results",
    "text": "Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#we-created-separate-plots-to-display-regions-and-state-affiliations-democratic-or-republican-across-the-u.s.-the-plots-plot_northeast-plot_southeast-plot_midwest-plot_southwest-and-plot_west-visualize-each-regions-layout",
    "href": "ElectionStudy03Ver33.html#we-created-separate-plots-to-display-regions-and-state-affiliations-democratic-or-republican-across-the-u.s.-the-plots-plot_northeast-plot_southeast-plot_midwest-plot_southwest-and-plot_west-visualize-each-regions-layout",
    "title": "Early Years:",
    "section": "We created separate plots to display regions and state affiliations (Democratic or Republican) across the U.S. The plots — ## plot_northeast, plot_southeast, plot_midwest, plot_southwest, and plot_west — visualize each region’s layout,",
    "text": "We created separate plots to display regions and state affiliations (Democratic or Republican) across the U.S. The plots — ## plot_northeast, plot_southeast, plot_midwest, plot_southwest, and plot_west — visualize each region’s layout,"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#highlighting-the-party-affiliation-within-each-state.-this-approach-offers-a-clear-view-of-the-political-landscape-across-states-within-each-region.",
    "href": "ElectionStudy03Ver33.html#highlighting-the-party-affiliation-within-each-state.-this-approach-offers-a-clear-view-of-the-political-landscape-across-states-within-each-region.",
    "title": "Early Years:",
    "section": "highlighting the party affiliation within each state. This approach offers a clear view of the political landscape across states within each region.",
    "text": "highlighting the party affiliation within each state. This approach offers a clear view of the political landscape across states within each region.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning: package 'maps' was built under R version 4.4.2\n\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\n\n\n\n\n\n\n\n\n\n\n## We created a map displaying the number of electoral votes by state, with an accompanying list detailing the electoral vote count\n## for each state.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\nWarning: Returning more (or less) than 1 row per summarise() group was deprecated in dplyr 1.1.0. ℹ Please use reframe() instead. ℹ When switching from summarise() to reframe(), remember that reframe() always returns an ungrouped data frame and adjust accordingly.\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\nCoordinate system already present. Adding new coordinate system, which will replace the existing one. Coordinate system already present. Adding new coordinate system, which will replace the existing one.\n\n\n:::\n\n::: {.cell-output-display}\n![](ElectionStudy03Ver33_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n## ## Using the usmap library, we successfully printed a map of the United States\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\nWarning: package ‘usmap’ was built under R version 4.4.2\n\n\n:::\n\n::: {.cell-output-display}\n![](ElectionStudy03Ver33_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\nyear state state_po state_fips state_cen state_ic office 1 1976 ALABAMA AL 1 63 41 US PRESIDENT 2 1976 ALABAMA AL 1 63 41 US PRESIDENT 3 1976 ALABAMA AL 1 63 41 US PRESIDENT 4 1976 ALABAMA AL 1 63 41 US PRESIDENT 5 1976 ALABAMA AL 1 63 41 US PRESIDENT 6 1976 ALABAMA AL 1 63 41 US PRESIDENT candidate party_detailed writein candidatevotes 1 CARTER, JIMMY DEMOCRAT FALSE 659170 2 FORD, GERALD REPUBLICAN FALSE 504070 3 MADDOX, LESTER AMERICAN INDEPENDENT PARTY FALSE 9198 4 BUBAR, BENJAMIN ““BEN”” PROHIBITION FALSE 6669 5 HALL, GUS COMMUNIST PARTY USE FALSE 1954 6 MACBRIDE, ROGER LIBERTARIAN FALSE 1481 totalvotes version notes party_simplified 1 1182850 20210113 NA DEMOCRAT 2 1182850 20210113 NA REPUBLICAN 3 1182850 20210113 NA OTHER 4 1182850 20210113 NA OTHER 5 1182850 20210113 NA OTHER 6 1182850 20210113 NA LIBERTARIAN\n\n\n:::\n:::\n\n## Using the usmap library, we successfully printed a map of the United States, including all states, with Alaska and Hawaii displayed accurately alongside the mainland. This library is particularly useful for visualizing U.S. state data on a consistent map layout that includes all 50 states.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\nWarning in geom_map(data = map_data, map = map_data, aes(x = long, y = lat, : Ignoring unknown aesthetics: x and y\n\n\n:::\n\n::: {.cell-output-display}\n![](ElectionStudy03Ver33_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n## Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of votes each state received. This provides a clear visual of the voting landscape across the U.S.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\nWarning in geom_map(data = map_data, map = map_data, aes(x = long, y = lat, : Ignoring unknown aesthetics: x and y\n\n\n:::\n\n::: {.cell-output-display}\n![](ElectionStudy03Ver33_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## ## Using a choropleth map with the `usmap` library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the **number of electoral votes** each state has. This approach provides a clear visual of the electoral landscape across the U.S., highlighting each state’s electoral weight in the election.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\nWarning: Returning more (or less) than 1 row per summarise() group was deprecated in dplyr 1.1.0. ℹ Please use reframe() instead. ℹ When switching from summarise() to reframe(), remember that reframe() always returns an ungrouped data frame and adjust accordingly.\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\nCoordinate system already present. Adding new coordinate system, which will replace the existing one. Coordinate system already present. Adding new coordinate system, which will replace the existing one. ```\n:::\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#we-created-a-map-displaying-the-number-of-electoral-votes-by-state-with-an-accompanying-list-detailing-the-electoral-vote-count",
    "href": "ElectionStudy03Ver33.html#we-created-a-map-displaying-the-number-of-electoral-votes-by-state-with-an-accompanying-list-detailing-the-electoral-vote-count",
    "title": "Early Years:",
    "section": "We created a map displaying the number of electoral votes by state, with an accompanying list detailing the electoral vote count",
    "text": "We created a map displaying the number of electoral votes by state, with an accompanying list detailing the electoral vote count"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#for-each-state.",
    "href": "ElectionStudy03Ver33.html#for-each-state.",
    "title": "Early Years:",
    "section": "for each state.",
    "text": "for each state.\n\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one."
  },
  {
    "objectID": "ElectionStudy03Ver33.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states",
    "href": "ElectionStudy03Ver33.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states",
    "title": "Early Years:",
    "section": "## Using the usmap library, we successfully printed a map of the United States",
    "text": "## Using the usmap library, we successfully printed a map of the United States\n\n\nWarning: package 'usmap' was built under R version 4.4.2\n\n\n\n\n\n\n\n\n\n  year   state state_po state_fips state_cen state_ic       office\n1 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n2 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n3 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n4 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n5 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n6 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n                candidate             party_detailed writein candidatevotes\n1           CARTER, JIMMY                   DEMOCRAT   FALSE         659170\n2            FORD, GERALD                 REPUBLICAN   FALSE         504070\n3          MADDOX, LESTER AMERICAN INDEPENDENT PARTY   FALSE           9198\n4 BUBAR, BENJAMIN \"\"BEN\"\"                PROHIBITION   FALSE           6669\n5               HALL, GUS        COMMUNIST PARTY USE   FALSE           1954\n6         MACBRIDE, ROGER                LIBERTARIAN   FALSE           1481\n  totalvotes  version notes party_simplified\n1    1182850 20210113    NA         DEMOCRAT\n2    1182850 20210113    NA       REPUBLICAN\n3    1182850 20210113    NA            OTHER\n4    1182850 20210113    NA            OTHER\n5    1182850 20210113    NA            OTHER\n6    1182850 20210113    NA      LIBERTARIAN"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states-including-all-states-with-alaska-and-hawaii-displayed-accurately-alongside-the-mainland.-this-library-is-particularly-useful-for-visualizing-u.s.-state-data-on-a-consistent-map-layout-that-includes-all-50-states.",
    "href": "ElectionStudy03Ver33.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states-including-all-states-with-alaska-and-hawaii-displayed-accurately-alongside-the-mainland.-this-library-is-particularly-useful-for-visualizing-u.s.-state-data-on-a-consistent-map-layout-that-includes-all-50-states.",
    "title": "Early Years:",
    "section": "Using the usmap library, we successfully printed a map of the United States, including all states, with Alaska and Hawaii displayed accurately alongside the mainland. This library is particularly useful for visualizing U.S. state data on a consistent map layout that includes all 50 states.",
    "text": "Using the usmap library, we successfully printed a map of the United States, including all states, with Alaska and Hawaii displayed accurately alongside the mainland. This library is particularly useful for visualizing U.S. state data on a consistent map layout that includes all 50 states.\n\n\nWarning in geom_map(data = map_data, map = map_data, aes(x = long, y = lat, :\nIgnoring unknown aesthetics: x and y"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-votes-each-state-received.-this-provides-a-clear-visual-of-the-voting-landscape-across-the-u.s.",
    "href": "ElectionStudy03Ver33.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-votes-each-state-received.-this-provides-a-clear-visual-of-the-voting-landscape-across-the-u.s.",
    "title": "Early Years:",
    "section": "Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of votes each state received. This provides a clear visual of the voting landscape across the U.S.",
    "text": "Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of votes each state received. This provides a clear visual of the voting landscape across the U.S.\n\n\nWarning in geom_map(data = map_data, map = map_data, aes(x = long, y = lat, :\nIgnoring unknown aesthetics: x and y"
  },
  {
    "objectID": "ElectionStudy03Ver33.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-electoral-votes-each-state-has.-this-approach-provides-a-clear-visual-of-the-electoral-landscape-across-the-u.s.-highlighting-each-states-electoral-weight-in-the-election.",
    "href": "ElectionStudy03Ver33.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-electoral-votes-each-state-has.-this-approach-provides-a-clear-visual-of-the-electoral-landscape-across-the-u.s.-highlighting-each-states-electoral-weight-in-the-election.",
    "title": "Early Years:",
    "section": "## Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of electoral votes each state has. This approach provides a clear visual of the electoral landscape across the U.S., highlighting each state’s electoral weight in the election.",
    "text": "## Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of electoral votes each state has. This approach provides a clear visual of the electoral landscape across the U.S., highlighting each state’s electoral weight in the election.\n\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\n\n\npng(“test.png”) plot(1:10) dev.off()"
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "A tibble: 51 × 2",
    "section": "",
    "text": "``{r}\nproject: type: html\nformat: html: theme: cosmo # Set the theme to “cosmo” or any other desired theme toc: true # Enable table of contents if needed toc-depth: 2 # Set depth for the table of contents css: styles.css # Optional: add custom CSS if you have a separate stylesheet\nStates with the Most Gains and Losses in Seats (1976-2022):"
  },
  {
    "objectID": "mp03.html#analysis-of-fusion-voting-impact-on-key-candidates",
    "href": "mp03.html#analysis-of-fusion-voting-impact-on-key-candidates",
    "title": "Early Years:",
    "section": "Analysis of Fusion Voting Impact on Key Candidates",
    "text": "Analysis of Fusion Voting Impact on Key Candidates\nThis analysis explores the top 10 candidates who benefited the most from fusion voting, based on the increase in their vote count. Fusion voting allows candidates to be listed on multiple party lines, potentially increasing their total votes by appealing to a broader set of voters.\n\nKey Findings\n\nTop Beneficiary: Ronald Reagan, in his 1984 re-election campaign, received the highest increase in votes from fusion voting, with over 3.3 million additional votes. This substantial boost highlights Reagan’s cross-party appeal during his landslide victory.\nProminent Family Influence: Both George H.W. Bush (1988) and George W. Bush (2004) appear in the top four, reflecting the impact of fusion voting in supporting these Republican candidates. This added support likely contributed to their success in tightly contested races.\nHistorical Context: Gerald Ford (1976) and Robert Dole (1996) also benefited significantly from fusion voting. This strategic use of fusion voting allowed these candidates to gather cross-party support, showcasing its importance in past Republican campaigns.\nModern Influence - Donald Trump: Donald Trump ranks sixth, with a fusion voting increase of approximately 2.2 million votes in the 2016 election. Trump’s unique political appeal extended beyond traditional Republican lines, drawing support from additional party endorsements. This strategy reinforced his electoral base while reaching independent voters and those dissatisfied with traditional party structures.\nTotal Vote Impact: While most candidates gained millions of additional votes, the last two entries, Robert Dole and Chris Jacobs, benefited to a lesser extent, with increases under 200,000. This contrast underscores the varying degrees of fusion voting’s impact, depending on the candidate and election context.\nImplications for Political Strategy: Fusion voting can be a powerful approach to appeal to diverse voter bases, especially in competitive elections. For candidates with strong, distinct personas like Trump, fusion voting provides a pathway to engage voters across the political spectrum.\n\n\n\nTask 3: Comparison of Presidential vs. House Candidate Votes\nQuestion: Do presidential candidates tend to receive more or fewer votes than congressional candidates from their party in the same state?\n\n\n# A tibble: 5 × 1\n  state     \n  &lt;chr&gt;     \n1 CALIFORNIA\n2 FLORIDA   \n3 LOUISIANA \n4 NEW YORK  \n5 TEXAS     \n\n\n[1] \"CALIFORNIA\" \"FLORIDA\"    \"LOUISIANA\"  \"NEW YORK\"   \"TEXAS\"     \n\n\n\n\n\n\n\n\n\n\nAnalysis for CALIFORNIA :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for FLORIDA :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for LOUISIANA :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Republican party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for NEW YORK :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time.\n\n\n\n\n\n\n\n\n\n\nAnalysis for TEXAS :\n- Presidential candidates tended to receive more votes than congressional candidates in certain years, particularly for the Democratic party.\n- Congressional candidates from the Democratic party sometimes outperformed presidential candidates in certain years.\n- The year-by-year trend highlights periods where voters preferred one level of representation over the other, possibly influenced by state and national issues at the time."
  },
  {
    "objectID": "mp03.html#california",
    "href": "mp03.html#california",
    "title": "Early Years:",
    "section": "California",
    "text": "California"
  },
  {
    "objectID": "mp03.html#florida",
    "href": "mp03.html#florida",
    "title": "Early Years:",
    "section": "Florida",
    "text": "Florida"
  },
  {
    "objectID": "mp03.html#explanation",
    "href": "mp03.html#explanation",
    "title": "Early Years:",
    "section": "Explanation",
    "text": "Explanation\nThis map shows the number of electoral votes allocated to each U.S. state for the 2024 presidential election, based on the 2020 Census data. Darker shades indicate states with more electoral votes, reflecting higher populations. States like California, Texas, Florida, and New York have the most votes due to their large populations, making them particularly influential in the Electoral College. Smaller states have fewer electoral votes, represented by lighter shades, but all states contribute to the total needed to win the presidency.\n\nTask 4: Automate Zip File Extraction\n#To automate the extraction of .shp files from ZIP archives, we’ll create a function called read_shp_from_zip(). This function will take in the name of a ZIP file, extract #the .shp file within it, and read it into R using read_sf() from the sf package.\n\n\nCode to Load and Combine Shapefiles from Subfolders"
  },
  {
    "objectID": "mp03.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "href": "mp03.html#step-1-write-a-function-to-extract-and-read-shapefiles-from-zip-archives",
    "title": "Early Years:",
    "section": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives",
    "text": "Step 1: Write a Function to Extract and Read Shapefiles from Zip Archives"
  },
  {
    "objectID": "mp03.html#outout-files-from-reading-the-.shp-file",
    "href": "mp03.html#outout-files-from-reading-the-.shp-file",
    "title": "Early Years:",
    "section": "Outout files from reading the .shp file",
    "text": "Outout files from reading the .shp file"
  },
  {
    "objectID": "mp03.html#we-created-a-map-of-the-us-with-all-the-districs",
    "href": "mp03.html#we-created-a-map-of-the-us-with-all-the-districs",
    "title": "Early Years:",
    "section": "we created a map of the us with all the districs",
    "text": "we created a map of the us with all the districs\n\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE        FROMCOUNTY               geometry  \n Length:435         Length:435         Mode :logical   MULTIPOLYGON :435  \n Class :character   Class :character   FALSE:381       epsg:4269    :  0  \n Mode  :character   Mode  :character   TRUE :54        +proj=long...:  0  \n\n\n\n\n\n\n\n\n\n [1] \"STATENAME\"  \"ID\"         \"DISTRICT\"   \"STARTCONG\"  \"ENDCONG\"   \n [6] \"DISTRICTSI\" \"COUNTY\"     \"PAGE\"       \"LAW\"        \"NOTE\"      \n[11] \"BESTDEC\"    \"FINALNOTE\"  \"RNOTE\"      \"LASTCHANGE\" \"FROMCOUNTY\"\n[16] \"geometry\"  \n\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.5993 ymin: 30.62397 xmax: -73.7243 ymax: 43.09876\nGeodetic CRS:  NAD83\n# A tibble: 6 × 16\n  STATENAME ID    DISTRICT STARTCONG ENDCONG DISTRICTSI COUNTY PAGE  LAW   NOTE \n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Californ… 0060… 27       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n2 Georgia   0130… 2        93        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n3 New York  0360… 10       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n4 New York  0360… 11       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n5 New York  0360… 37       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n6 New York  0360… 38       94        97      &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  \"{\\\"…\n# ℹ 6 more variables: BESTDEC &lt;chr&gt;, FINALNOTE &lt;chr&gt;, RNOTE &lt;chr&gt;,\n#   LASTCHANGE &lt;chr&gt;, FROMCOUNTY &lt;lgl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nsf [435 × 16] (S3: sf/tbl_df/tbl/data.frame)\n $ STATENAME : chr [1:435] \"California\" \"Georgia\" \"New York\" \"New York\" ...\n $ ID        : chr [1:435] \"006094097027\" \"013093097002\" \"036094097010\" \"036094097011\" ...\n $ DISTRICT  : chr [1:435] \"27\" \"2\" \"10\" \"11\" ...\n $ STARTCONG : chr [1:435] \"94\" \"93\" \"94\" \"94\" ...\n $ ENDCONG   : chr [1:435] \"97\" \"97\" \"97\" \"97\" ...\n $ DISTRICTSI: chr [1:435] NA NA NA NA ...\n $ COUNTY    : chr [1:435] NA NA NA NA ...\n $ PAGE      : chr [1:435] NA NA NA NA ...\n $ LAW       : chr [1:435] NA NA NA NA ...\n $ NOTE      : chr [1:435] \"{\\\"Shape from shapes/Ftp_Upload/California_94-97cc/94-97cc_27cd_California.shp (17628 bytes, last modified on T\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/Georgia_93-97cc/93-97cc_2cd_Georgia.shp (87868 bytes, last modified on Thu Jul \"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_10cd_NewYork.shp (26408 bytes, last modified on Wed Dec\"| __truncated__ \"{\\\"Shape from shapes/Ftp_Upload/NewYork_94-97cc/94-97cc_11cd_NewYork.shp (33916 bytes, last modified on Tue Feb\"| __truncated__ ...\n $ BESTDEC   : chr [1:435] NA NA NA NA ...\n $ FINALNOTE : chr [1:435] NA NA NA NA ...\n $ RNOTE     : chr [1:435] NA NA NA NA ...\n $ LASTCHANGE: chr [1:435] \"2016-05-20 13:07:35.318982\" \"2016-05-20 13:07:46.863044\" \"2016-05-20 13:09:35.392414\" \"2016-05-20 13:09:35.409757\" ...\n $ FROMCOUNTY: logi [1:435] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ geometry  :sfc_MULTIPOLYGON of length 435; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:1089, 1:2] -119 -119 -119 -119 -119 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"STATENAME\" \"ID\" \"DISTRICT\" \"STARTCONG\" ..."
  },
  {
    "objectID": "mp03.html#these-are-the-number-of-districts-by-state",
    "href": "mp03.html#these-are-the-number-of-districts-by-state",
    "title": "Early Years:",
    "section": "These are the number of districts by state",
    "text": "These are the number of districts by state\n\n\nNumber of Districts by State:\n\n\n# A tibble: 50 × 2\n   STATENAME     num_districts\n   &lt;chr&gt;                 &lt;int&gt;\n 1 California               43\n 2 New York                 39\n 3 Pennsylvania             25\n 4 Illinois                 24\n 5 Texas                    24\n 6 Ohio                     23\n 7 Michigan                 19\n 8 Florida                  15\n 9 New Jersey               15\n10 Massachusetts            12\n# ℹ 40 more rows"
  },
  {
    "objectID": "mp03.html#we-added-some-hypotecal-information-to-assign-colors-red-or-blue-to-the-map-by-state",
    "href": "mp03.html#we-added-some-hypotecal-information-to-assign-colors-red-or-blue-to-the-map-by-state",
    "title": "Early Years:",
    "section": "we added some hypotecal information to assign colors (red or blue to the map by state)",
    "text": "we added some hypotecal information to assign colors (red or blue to the map by state)\n\n\n  STATENAME              ID              DISTRICT          STARTCONG        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   ENDCONG           DISTRICTSI           COUNTY              PAGE          \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n     LAW                NOTE             BESTDEC           FINALNOTE        \n Length:435         Length:435         Length:435         Length:435        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    RNOTE            LASTCHANGE        FROMCOUNTY               geometry  \n Length:435         Length:435         Mode :logical   MULTIPOLYGON :435  \n Class :character   Class :character   FALSE:381       epsg:4269    :  0  \n Mode  :character   Mode  :character   TRUE :54        +proj=long...:  0"
  },
  {
    "objectID": "mp03.html#here-we-list-all-the-red-republican-and-blue-democrat-states",
    "href": "mp03.html#here-we-list-all-the-red-republican-and-blue-democrat-states",
    "title": "Early Years:",
    "section": "here we list all the red (Republican) and blue (Democrat) states",
    "text": "here we list all the red (Republican) and blue (Democrat) states\n\n\nWinning Party by State for the Year 2000:\n\n\n# A tibble: 50 × 2\n   state       winning_party\n   &lt;chr&gt;       &lt;chr&gt;        \n 1 ALABAMA     Red          \n 2 ALASKA      Red          \n 3 ARIZONA     Red          \n 4 ARKANSAS    Blue         \n 5 CALIFORNIA  Blue         \n 6 COLORADO    Red          \n 7 CONNECTICUT Blue         \n 8 DELAWARE    Red          \n 9 FLORIDA     Red          \n10 GEORGIA     Red          \n# ℹ 40 more rows\n\n\n\nBlue States (Democrat Wins):\n\n\n [1] \"ARKANSAS\"      \"CALIFORNIA\"    \"CONNECTICUT\"   \"HAWAII\"       \n [5] \"ILLINOIS\"      \"MAINE\"         \"MARYLAND\"      \"MASSACHUSETTS\"\n [9] \"MICHIGAN\"      \"MISSISSIPPI\"   \"MISSOURI\"      \"NEW JERSEY\"   \n[13] \"NEW MEXICO\"    \"NEW YORK\"      \"NORTH DAKOTA\"  \"OREGON\"       \n[17] \"PENNSYLVANIA\"  \"RHODE ISLAND\"  \"WASHINGTON\"    \"WEST VIRGINIA\"\n\n\n\nRed States (Republican Wins):\n\n\n [1] \"ALABAMA\"        \"ALASKA\"         \"ARIZONA\"        \"COLORADO\"      \n [5] \"DELAWARE\"       \"FLORIDA\"        \"GEORGIA\"        \"IDAHO\"         \n [9] \"INDIANA\"        \"IOWA\"           \"KANSAS\"         \"KENTUCKY\"      \n[13] \"LOUISIANA\"      \"MINNESOTA\"      \"MONTANA\"        \"NEBRASKA\"      \n[17] \"NEVADA\"         \"NEW HAMPSHIRE\"  \"NORTH CAROLINA\" \"OHIO\"          \n[21] \"OKLAHOMA\"       \"SOUTH CAROLINA\" \"SOUTH DAKOTA\"   \"TENNESSEE\"     \n[25] \"TEXAS\"          \"UTAH\"           \"VERMONT\"        \"VIRGINIA\"      \n[29] \"WISCONSIN\"      \"WYOMING\""
  },
  {
    "objectID": "mp03.html#task-5-chloropleth-visualization-of-the-2000-presidential-election-electoral-college-results",
    "href": "mp03.html#task-5-chloropleth-visualization-of-the-2000-presidential-election-electoral-college-results",
    "title": "Early Years:",
    "section": "Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results",
    "text": "Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results"
  },
  {
    "objectID": "mp03.html#we-created-separate-plots-to-display-regions-and-state-affiliations-democratic-or-republican-across-the-u.s.-the-plots-plot_northeast-plot_southeast-plot_midwest-plot_southwest-and-plot_west-visualize-each-regions-layout",
    "href": "mp03.html#we-created-separate-plots-to-display-regions-and-state-affiliations-democratic-or-republican-across-the-u.s.-the-plots-plot_northeast-plot_southeast-plot_midwest-plot_southwest-and-plot_west-visualize-each-regions-layout",
    "title": "Early Years:",
    "section": "We created separate plots to display regions and state affiliations (Democratic or Republican) across the U.S. The plots — ## plot_northeast, plot_southeast, plot_midwest, plot_southwest, and plot_west — visualize each region’s layout,",
    "text": "We created separate plots to display regions and state affiliations (Democratic or Republican) across the U.S. The plots — ## plot_northeast, plot_southeast, plot_midwest, plot_southwest, and plot_west — visualize each region’s layout,"
  },
  {
    "objectID": "mp03.html#highlighting-the-party-affiliation-within-each-state.-this-approach-offers-a-clear-view-of-the-political-landscape-across-states-within-each-region.",
    "href": "mp03.html#highlighting-the-party-affiliation-within-each-state.-this-approach-offers-a-clear-view-of-the-political-landscape-across-states-within-each-region.",
    "title": "Early Years:",
    "section": "highlighting the party affiliation within each state. This approach offers a clear view of the political landscape across states within each region.",
    "text": "highlighting the party affiliation within each state. This approach offers a clear view of the political landscape across states within each region."
  },
  {
    "objectID": "mp03.html#we-created-a-map-displaying-the-number-of-electoral-votes-by-state-with-an-accompanying-list-detailing-the-electoral-vote-count",
    "href": "mp03.html#we-created-a-map-displaying-the-number-of-electoral-votes-by-state-with-an-accompanying-list-detailing-the-electoral-vote-count",
    "title": "Early Years:",
    "section": "We created a map displaying the number of electoral votes by state, with an accompanying list detailing the electoral vote count",
    "text": "We created a map displaying the number of electoral votes by state, with an accompanying list detailing the electoral vote count"
  },
  {
    "objectID": "mp03.html#for-each-state.",
    "href": "mp03.html#for-each-state.",
    "title": "Early Years:",
    "section": "for each state.",
    "text": "for each state."
  },
  {
    "objectID": "mp03.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states",
    "href": "mp03.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states",
    "title": "Early Years:",
    "section": "## Using the usmap library, we successfully printed a map of the United States",
    "text": "## Using the usmap library, we successfully printed a map of the United States\n\n\n\n\n\n\n\n\n\n  year   state state_po state_fips state_cen state_ic       office\n1 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n2 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n3 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n4 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n5 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n6 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n                candidate             party_detailed writein candidatevotes\n1           CARTER, JIMMY                   DEMOCRAT   FALSE         659170\n2            FORD, GERALD                 REPUBLICAN   FALSE         504070\n3          MADDOX, LESTER AMERICAN INDEPENDENT PARTY   FALSE           9198\n4 BUBAR, BENJAMIN \"\"BEN\"\"                PROHIBITION   FALSE           6669\n5               HALL, GUS        COMMUNIST PARTY USE   FALSE           1954\n6         MACBRIDE, ROGER                LIBERTARIAN   FALSE           1481\n  totalvotes  version notes party_simplified\n1    1182850 20210113    NA         DEMOCRAT\n2    1182850 20210113    NA       REPUBLICAN\n3    1182850 20210113    NA            OTHER\n4    1182850 20210113    NA            OTHER\n5    1182850 20210113    NA            OTHER\n6    1182850 20210113    NA      LIBERTARIAN"
  },
  {
    "objectID": "mp03.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states-including-all-states-with-alaska-and-hawaii-displayed-accurately-alongside-the-mainland.-this-library-is-particularly-useful-for-visualizing-u.s.-state-data-on-a-consistent-map-layout-that-includes-all-50-states.",
    "href": "mp03.html#using-the-usmap-library-we-successfully-printed-a-map-of-the-united-states-including-all-states-with-alaska-and-hawaii-displayed-accurately-alongside-the-mainland.-this-library-is-particularly-useful-for-visualizing-u.s.-state-data-on-a-consistent-map-layout-that-includes-all-50-states.",
    "title": "A tibble: 51 × 2",
    "section": "Using the usmap library, we successfully printed a map of the United States, including all states, with Alaska and Hawaii displayed accurately alongside the mainland. This library is particularly useful for visualizing U.S. state data on a consistent map layout that includes all 50 states.",
    "text": "Using the usmap library, we successfully printed a map of the United States, including all states, with Alaska and Hawaii displayed accurately alongside the mainland. This library is particularly useful for visualizing U.S. state data on a consistent map layout that includes all 50 states."
  },
  {
    "objectID": "mp03.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-votes-each-state-received.-this-provides-a-clear-visual-of-the-voting-landscape-across-the-u.s.",
    "href": "mp03.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-votes-each-state-received.-this-provides-a-clear-visual-of-the-voting-landscape-across-the-u.s.",
    "title": "A tibble: 51 × 2",
    "section": "Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of votes each state received. This provides a clear visual of the voting landscape across the U.S.",
    "text": "Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of votes each state received. This provides a clear visual of the voting landscape across the U.S."
  },
  {
    "objectID": "mp03.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-electoral-votes-each-state-has.-this-approach-provides-a-clear-visual-of-the-electoral-landscape-across-the-u.s.-highlighting-each-states-electoral-weight-in-the-election.",
    "href": "mp03.html#using-a-choropleth-map-with-the-usmap-library-we-plotted-u.s.-states-in-red-and-blue-to-represent-republican-and-democratic-states-respectively-and-shaded-them-according-to-the-number-of-electoral-votes-each-state-has.-this-approach-provides-a-clear-visual-of-the-electoral-landscape-across-the-u.s.-highlighting-each-states-electoral-weight-in-the-election.",
    "title": "A tibble: 51 × 2",
    "section": "## Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of electoral votes each state has. This approach provides a clear visual of the electoral landscape across the U.S., highlighting each state’s electoral weight in the election.",
    "text": "## Using a choropleth map with the usmap library, we plotted U.S. states in red and blue to represent Republican and Democratic states, respectively, and shaded them according to the number of electoral votes each state has. This approach provides a clear visual of the electoral landscape across the U.S., highlighting each state’s electoral weight in the election."
  },
  {
    "objectID": "mini04.html",
    "href": "mini04.html",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "",
    "text": "To begin your Monte Carlo analysis, you will need historical data covering (at a minimum) the following:\n\nWage growth\nInflation\nUS Equity Market total returns\nInternational Equity Market total returns\nBond market total returns\nShort-term debt returns1\n\n\n\n\n\n\n\nTask 3: Data Acquisition\n\n\n\nIdentify and download historical data series for each of the above inputs to your Monte Carlo analysis. If necessary, “downsample” each series to a monthly frequency and join them together in a data.frame.\nYou must use at least one data series from AlphaVantage and one from FRED. You must use the APIs of each service to access this data and, as noted above, you need to use the “raw” API, relying only on the httr2 package (or similar) and not wrapper packages like quantmod or alphavantager.\n\n\nNote that, for each of these quantities, there are many possibly-relevant data series: e.g., for inflation, you might compare CPI, core CPI, PCE, both nationally and, if available, in the NY metro area. You may select any series you feel best captures these for a potential CUNY employee. For the market returns, it may be easiest to identify a suitable index ETF and compute its (dividend-adjusted) returns as a proxy for market returns.\nIn any historically-based financial projection, there is a trade-off between having enough history to capture sufficient market cycles and having only relevant data in your training set. I’d recommend using around 15-20 years of data for this project.\n\n\n\n\n\n\n\n\n\nTask 4: Initial Analysis\n\n\n\nAfter you have acquired your input data, perform some basic exploratory data analysis to identify key properties of your data. You may choose to measure the correlation among factors, long-term averages, variances, etc. Your analysis should include at least one table and one figure.\nAs part of your analysis, be sure to compute the long-run monthly average value of each series. You will use these in a later task.\n\n\n\n\n\n\n\n\n\n\n\nTask 5: Historical Comparison\n\n\n\nNow that you have acquired data, implement the TRS and ORP formulas above and compare the value of each of them for the first month of retirement. To do this, you may assume that your hypothetical employee:\n\nJoined CUNY in the first month of the historical data\nRetired from CUNY at the end of the final month of data\n\nYou will need to select a starting salary for your employee. Use historical data for wage growth and inflation and assume that the TRS and ORP parameters did not change over time. (That is, the employee contribution “brackets” are not inflation adjusted; the employee will have to make larger contributions as income rises over the span of a 20+ year career.)\n\n\n\n\n\nThe “first month of retirement” dollar value is interesting, but it arguably undersells a key strength of the TRS. The TRS guarantees income for life, while the ORP can be exhausted if the employee lives a very long time in retirement.\n\n\n\n\n\n\nTask 6: Fixed-Rate Analysis\n\n\n\nModify your simulation from the previous section to project an employee’s pension benefit (TRS) or withdrawal amount (ORP) from retirement until death. (You will need to select an estimated death age.) In order to implement cost-of-living-adjustments (TRS) and future market returns (ORP), you can use the long-run averages you computed previously. This “fixed rate” assumption is rather limiting, but we will address it below.\nAs you compare the plans, be sure to consider:\n\nWhether the employee runs out of funds before death and/or has funds to leave to heirs (ORP only)\nAverage monthly income (TRS vs ORP)\nMaximum and minimum gap in monthly income between TRS and ORP\n\nAs noted above, you can ignore the effect of taxes throughout this analysis.\n\n\n\n\n\nNow that you have implemented both the “while working” contributions and returns (ORP) only as well as the “while retired” benefits of both plans, we are finally ready to implement our Monte Carlo assessment.\n\n\n\n\n\n\nTask 7: Monte Carlo Analysis\n\n\n\nUsing your historical data, generate several (at least 200) “bootstrap histories” suitable for a Monte Carlo analysis. Use bootstrap sampling, i.e. sampling with replacement, to generate values for both the “while working” and “while retired” periods of the model; you do not need to assume constant long-term average values for the retirement predictions any more.\nApply your calculations from the previous two tasks to each of your simulated bootstrap histories. Compare the distribution of TRS and ORP benefits that these histories generate. You may want to ask questions like the following:\n\nWhat is the probability that an ORP employee exhausts their savings before death?\nWhat is the probability that an ORP employee has a higher monthly income in retirement than a TRS employee?\nIs the 4% withdrawal rate actually a good idea or would you recommend a different withdrawal rate?\n\nReport your findings to these or other questions of interest in tables or figures, as appropriate."
  },
  {
    "objectID": "mini04.html#set-up-and-exploration",
    "href": "mini04.html#set-up-and-exploration",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "",
    "text": "To begin your Monte Carlo analysis, you will need historical data covering (at a minimum) the following:\n\nWage growth\nInflation\nUS Equity Market total returns\nInternational Equity Market total returns\nBond market total returns\nShort-term debt returns1\n\n\n\n\n\n\n\nTask 3: Data Acquisition\n\n\n\nIdentify and download historical data series for each of the above inputs to your Monte Carlo analysis. If necessary, “downsample” each series to a monthly frequency and join them together in a data.frame.\nYou must use at least one data series from AlphaVantage and one from FRED. You must use the APIs of each service to access this data and, as noted above, you need to use the “raw” API, relying only on the httr2 package (or similar) and not wrapper packages like quantmod or alphavantager.\n\n\nNote that, for each of these quantities, there are many possibly-relevant data series: e.g., for inflation, you might compare CPI, core CPI, PCE, both nationally and, if available, in the NY metro area. You may select any series you feel best captures these for a potential CUNY employee. For the market returns, it may be easiest to identify a suitable index ETF and compute its (dividend-adjusted) returns as a proxy for market returns.\nIn any historically-based financial projection, there is a trade-off between having enough history to capture sufficient market cycles and having only relevant data in your training set. I’d recommend using around 15-20 years of data for this project.\n\n\n\n\n\n\n\n\n\nTask 4: Initial Analysis\n\n\n\nAfter you have acquired your input data, perform some basic exploratory data analysis to identify key properties of your data. You may choose to measure the correlation among factors, long-term averages, variances, etc. Your analysis should include at least one table and one figure.\nAs part of your analysis, be sure to compute the long-run monthly average value of each series. You will use these in a later task.\n\n\n\n\n\n\n\n\n\n\n\nTask 5: Historical Comparison\n\n\n\nNow that you have acquired data, implement the TRS and ORP formulas above and compare the value of each of them for the first month of retirement. To do this, you may assume that your hypothetical employee:\n\nJoined CUNY in the first month of the historical data\nRetired from CUNY at the end of the final month of data\n\nYou will need to select a starting salary for your employee. Use historical data for wage growth and inflation and assume that the TRS and ORP parameters did not change over time. (That is, the employee contribution “brackets” are not inflation adjusted; the employee will have to make larger contributions as income rises over the span of a 20+ year career.)\n\n\n\n\n\nThe “first month of retirement” dollar value is interesting, but it arguably undersells a key strength of the TRS. The TRS guarantees income for life, while the ORP can be exhausted if the employee lives a very long time in retirement.\n\n\n\n\n\n\nTask 6: Fixed-Rate Analysis\n\n\n\nModify your simulation from the previous section to project an employee’s pension benefit (TRS) or withdrawal amount (ORP) from retirement until death. (You will need to select an estimated death age.) In order to implement cost-of-living-adjustments (TRS) and future market returns (ORP), you can use the long-run averages you computed previously. This “fixed rate” assumption is rather limiting, but we will address it below.\nAs you compare the plans, be sure to consider:\n\nWhether the employee runs out of funds before death and/or has funds to leave to heirs (ORP only)\nAverage monthly income (TRS vs ORP)\nMaximum and minimum gap in monthly income between TRS and ORP\n\nAs noted above, you can ignore the effect of taxes throughout this analysis.\n\n\n\n\n\nNow that you have implemented both the “while working” contributions and returns (ORP) only as well as the “while retired” benefits of both plans, we are finally ready to implement our Monte Carlo assessment.\n\n\n\n\n\n\nTask 7: Monte Carlo Analysis\n\n\n\nUsing your historical data, generate several (at least 200) “bootstrap histories” suitable for a Monte Carlo analysis. Use bootstrap sampling, i.e. sampling with replacement, to generate values for both the “while working” and “while retired” periods of the model; you do not need to assume constant long-term average values for the retirement predictions any more.\nApply your calculations from the previous two tasks to each of your simulated bootstrap histories. Compare the distribution of TRS and ORP benefits that these histories generate. You may want to ask questions like the following:\n\nWhat is the probability that an ORP employee exhausts their savings before death?\nWhat is the probability that an ORP employee has a higher monthly income in retirement than a TRS employee?\nIs the 4% withdrawal rate actually a good idea or would you recommend a different withdrawal rate?\n\nReport your findings to these or other questions of interest in tables or figures, as appropriate."
  },
  {
    "objectID": "mini04.html#deliverable-data-driven-decision-recommendation",
    "href": "mini04.html#deliverable-data-driven-decision-recommendation",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Deliverable: Data-Driven Decision Recommendation",
    "text": "Deliverable: Data-Driven Decision Recommendation\nFinally, write up your findings from Task 7 in the form of a “data-driven recommendation” to a potential CUNY employee. Here, you are playing the role of a financial advisor, so be sure to consider the employee’s current age and starting salary, expected lifetime, and risk tolerance. Be sure to suitably convey the uncertainty of your predictions and the limitations of the bootstrap-history approach used here.2 As you write this, think of what issues would matter most to you if you were making this decision and address them accordingly."
  },
  {
    "objectID": "mini04.html#extra-credit-opportunities",
    "href": "mini04.html#extra-credit-opportunities",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Extra Credit Opportunities",
    "text": "Extra Credit Opportunities\nFor extra credit, you may make an interactive version of your report, allowing your client to alter the parameters of your simulation and see how the predictions change.\n\nChallenge Level: Basic (Up to 5 points Extra Credit)\nPerform a “sensitivity analysis” by re-running your previous analysis under various different input parameters (starting salary, retirement age, death age, etc.) Then use some sort of interactive functionality to allow the reader to see how the results change.\nThe manipulateWidgets package may be useful here, but any sort of in-browser interactive display will suffice.\nNote that, in this model, all the simulations are run by Quarto at Render time and the interactivity only controls which simulations are displayed.\n\n\nChallenge Level: Moderate (Up to 10 points Extra Credit)\nUse the shiny package to implement a reactive dashboard. shiny requires use of a server to perform calculations. The website shinyapps.io provides a free platform to host the “backend” of your shiny dashboard. This example may prove useful, but note that the analysis required for this project (historical resampling) is a bit more advanced than the parametric model used there.\nUnder the shiny model, a back-end server is running (and re-running) simulations in real-time in response to user input.\n\n\nChallenge Level: Advanced (Up to 20 points Extra Credit)\nUse the r-shinylive framework to create a fully dynamic in-browser simulation dashboard. This in-development technology allows users to modify and re-run all simulations in their browser, providing the highest level of flexibility. You can allow users to vary their starting salary, retirement age, choice of data series, number of Monte Carlo histories, dates of historical data used for resampling, etc.\nNote that r-shinylive is a new technology and one that remains under active development. The instructor will not be able to provide support and assistance debugging it.\nTo estimate the median of an unknown distribution, we use the sample median. Calculating its variance is complex, so we use bootstrapping instead. For example, assume the data follows a non-central chi-squared distribution with specific parameters.\n\n\n[1] 10.73615\n\n\nThe median of this distribution is too complex for Wikipedia, but we can compute it empirically using a very large sample:\n\n\n[1] 9.577228\n\n\nSo our sample median (10.74) is a bit off from the true median (9.58) but not catastrophically so. How can we estimate the variance? By bootstrapping!\nWe can implement a bootstrap in dplyr as follows:\n\n\n[1] 0.1911888\n\n\nWe can compare this to the CLT-asymptotic variance:\n\n\n[1] 0.2121155\n\n\nAnd, since we’re in simulation land, we also have the true variance:\n\n\n[1] 0.2082013\n\n\nWhen dealing with simple data where each value is independent and similar (IID), bootstrapping is easy—you just use sample(replace=TRUE) to resample. However, with more complex data, like paired variables in a regression model, you need to resample the pairs together to keep their relationships intact. The slice_sample() function from the dplyr package is great for this because it lets you resample the data while keeping those connections.\nWe generate pairs with a visible, but not precisely linear, relationship.\n\n\n\n\n\n\n\n\n\nThe Kendall correlation is easily computed:\n\n\n[1] 0.7927273\n\n\nTo put a confidence interval on this, we can use a bootstrap with B = 400 replicates:\n\n\nWe can again compare this to the 'true' sampling variance since we have access to the data-generating model.\n\n[1] 0.001807341 \n\n\nWe can again compare this to the “true” sampling variance since we have access to the data-generating model.\n\n\n[1] 0.001408479\n\n\nStep 3: Download Data Wage Growth and Inflation (FRED) Use FRED for CPI or Core CPI data as a proxy for inflation and wage growth.\nUS Equity Market Total Returns (AlphaVantage) Use AlphaVantage to get adjusted close prices for a US equity index ETF like SPY (S&P 500 ETF).\n\n\n        date  close\n1 2024-12-01 607.66\n2 2024-11-01 602.55\n3 2024-10-01 568.64\n4 2024-09-01 573.76\n5 2024-08-01 563.68\n6 2024-07-01 550.81\n\n\n\n\n        date value\n1 1947-01-01 21.48\n2 1947-02-01 21.62\n3 1947-03-01 22.00\n4 1947-04-01 22.00\n5 1947-05-01 21.95\n6 1947-06-01 22.08\n\n\n        date value\n1 1962-01-02  4.06\n2 1962-01-03  4.03\n3 1962-01-04  3.99\n4 1962-01-05  4.02\n5 1962-01-08  4.03\n6 1962-01-09  4.05\n\n\n        date value\n1 1976-06-01  7.26\n2 1976-06-02  7.23\n3 1976-06-03  7.22\n4 1976-06-04  7.12\n5 1976-06-07  7.09\n6 1976-06-08  7.11\n\n\nStep 4: Join and Downsample Data Join all the data into a single data.frame and downsample to monthly frequency.\nStep 1: Summarize Key Properties Compute the long-term monthly averages, standard deviations, and correlations for your data series.\n\n\n        date   CPI SPY_CLOSE 10_Year_Bond 2_Year_Bond\n1 2000-01-01 169.3  139.5625     6.661000    6.440000\n2 2000-02-01 170.0  137.4375     6.519500    6.610500\n3 2000-03-01 171.0  150.3750     6.256522    6.528261\n4 2000-04-01 170.9  145.0937     5.990526    6.403684\n5 2000-05-01 171.2  142.8125     6.440455    6.809545\n6 2000-06-01 172.2  145.2812     6.097273    6.481818"
  },
  {
    "objectID": "mini04.html#footnotes",
    "href": "mini04.html#footnotes",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor short-term debt, it may be easiest to pick a key short-term benchmark, e.g., the 2-year US Treasury yield. The world of “short-term debt” is rather wide and varied.↩︎\nAs the SEC requires all advisors to disclaim: Past Performance is No Guarantee of Future Results.↩︎"
  },
  {
    "objectID": "mini04.html#importance-of-log-plots-log-plots-highlight-percentage-changes-clarify-exponential-growth-and-improve-comparisons-across-variables-with-large-value-differences-making-trends-easier-to-interpret",
    "href": "mini04.html#importance-of-log-plots-log-plots-highlight-percentage-changes-clarify-exponential-growth-and-improve-comparisons-across-variables-with-large-value-differences-making-trends-easier-to-interpret",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Importance of Log Plots Log plots highlight percentage changes, clarify exponential growth, and improve comparisons across variables with large value differences, making trends easier to interpret",
    "text": "Importance of Log Plots Log plots highlight percentage changes, clarify exponential growth, and improve comparisons across variables with large value differences, making trends easier to interpret"
  },
  {
    "objectID": "mini04.html#subtitle-exploring-base-case-higher-returns-and-lower-returns-scenarios",
    "href": "mini04.html#subtitle-exploring-base-case-higher-returns-and-lower-returns-scenarios",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Subtitle: Exploring Base Case, Higher Returns, and Lower Returns Scenarios",
    "text": "Subtitle: Exploring Base Case, Higher Returns, and Lower Returns Scenarios\n\nThis Monte Carlo simulation examines portfolio returns over 30 years under three scenarios: Base Case, Higher Returns, and Lower Returns. It models a 70% equity and 30% bond portfolio using historical assumptions and variance estimates, providing insights into expected performance and risk levels."
  },
  {
    "objectID": "mini04.html#this-monte-carlo-simulation-examines-portfolio-returns-over-30-years-under-three-scenarios-base-case-higher-returns-and-lower-returns.-it-models-a-70-equity-and-30-bond-portfolio-using-historical-assumptions-and-variance-estimates-providing-insights-into-expected-performance-and-risk-levels.",
    "href": "mini04.html#this-monte-carlo-simulation-examines-portfolio-returns-over-30-years-under-three-scenarios-base-case-higher-returns-and-lower-returns.-it-models-a-70-equity-and-30-bond-portfolio-using-historical-assumptions-and-variance-estimates-providing-insights-into-expected-performance-and-risk-levels.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "This Monte Carlo simulation examines portfolio returns over 30 years under three scenarios: Base Case, Higher Returns, and Lower Returns. It models a 70% equity and 30% bond portfolio using historical assumptions and variance estimates, providing insights into expected performance and risk levels.",
    "text": "This Monte Carlo simulation examines portfolio returns over 30 years under three scenarios: Base Case, Higher Returns, and Lower Returns. It models a 70% equity and 30% bond portfolio using historical assumptions and variance estimates, providing insights into expected performance and risk levels."
  },
  {
    "objectID": "mini04.html#key-statistics",
    "href": "mini04.html#key-statistics",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Key Statistics:",
    "text": "Key Statistics:\n\n1. Base Case: Mean monthly return of 0.37%, variance of 3.17 × 10⁻⁶, standard deviation of 0.18%.\n\n\n2. Higher Returns: Mean monthly return of 0.42%, variance of 3.90 × 10⁻⁶, standard deviation of 0.20%.\n\n\n3. Lower Returns: Mean monthly return of 0.34%, variance of 3.14 × 10⁻⁶, standard deviation of 0.18%."
  },
  {
    "objectID": "mini04.html#base-case-mean-monthly-return-of-0.37-variance-of-3.17-10⁶-standard-deviation-of-0.18.",
    "href": "mini04.html#base-case-mean-monthly-return-of-0.37-variance-of-3.17-10⁶-standard-deviation-of-0.18.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "1. Base Case: Mean monthly return of 0.37%, variance of 3.17 × 10⁻⁶, standard deviation of 0.18%.",
    "text": "1. Base Case: Mean monthly return of 0.37%, variance of 3.17 × 10⁻⁶, standard deviation of 0.18%."
  },
  {
    "objectID": "mini04.html#higher-returns-mean-monthly-return-of-0.42-variance-of-3.90-10⁶-standard-deviation-of-0.20.",
    "href": "mini04.html#higher-returns-mean-monthly-return-of-0.42-variance-of-3.90-10⁶-standard-deviation-of-0.20.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "2. Higher Returns: Mean monthly return of 0.42%, variance of 3.90 × 10⁻⁶, standard deviation of 0.20%.",
    "text": "2. Higher Returns: Mean monthly return of 0.42%, variance of 3.90 × 10⁻⁶, standard deviation of 0.20%."
  },
  {
    "objectID": "mini04.html#lower-returns-mean-monthly-return-of-0.34-variance-of-3.14-10⁶-standard-deviation-of-0.18.",
    "href": "mini04.html#lower-returns-mean-monthly-return-of-0.34-variance-of-3.14-10⁶-standard-deviation-of-0.18.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "3. Lower Returns: Mean monthly return of 0.34%, variance of 3.14 × 10⁻⁶, standard deviation of 0.18%.",
    "text": "3. Lower Returns: Mean monthly return of 0.34%, variance of 3.14 × 10⁻⁶, standard deviation of 0.18%."
  },
  {
    "objectID": "mini04.html#the-base-case-shows-stable-growth-with-moderate-risk-while-the-higher-returns-scenario-highlights-increased-opportunities-at-the-cost-of-higher-volatility.-the-lower-returns-scenario-emphasizes-the-importance-of-conservative-expectations-in-uncertain-environments.-density-plots-reveal-the-probability-distribution-of-monthly-returns-across-scenarios-providing-a-clear-view-of-potential-outcomes.",
    "href": "mini04.html#the-base-case-shows-stable-growth-with-moderate-risk-while-the-higher-returns-scenario-highlights-increased-opportunities-at-the-cost-of-higher-volatility.-the-lower-returns-scenario-emphasizes-the-importance-of-conservative-expectations-in-uncertain-environments.-density-plots-reveal-the-probability-distribution-of-monthly-returns-across-scenarios-providing-a-clear-view-of-potential-outcomes.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "The Base Case shows stable growth with moderate risk, while the Higher Returns scenario highlights increased opportunities at the cost of higher volatility. The Lower Returns scenario emphasizes the importance of conservative expectations in uncertain environments. Density plots reveal the probability distribution of monthly returns across scenarios, providing a clear view of potential outcomes.",
    "text": "The Base Case shows stable growth with moderate risk, while the Higher Returns scenario highlights increased opportunities at the cost of higher volatility. The Lower Returns scenario emphasizes the importance of conservative expectations in uncertain environments. Density plots reveal the probability distribution of monthly returns across scenarios, providing a clear view of potential outcomes.\n\n\n# A tibble: 3 × 4\n  Simulation        Mean   Variance Std_Dev\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n1 Base Case      0.00371 0.00000317 0.00178\n2 Higher Returns 0.00418 0.00000390 0.00197\n3 Lower Returns  0.00341 0.00000314 0.00177"
  },
  {
    "objectID": "mini04.html#insights",
    "href": "mini04.html#insights",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Insights:",
    "text": "Insights:\n\nThe Base Case shows stable growth with moderate risk, while the Higher Returns scenario highlights increased opportunities at the cost of higher volatility. The Lower Returns scenario emphasizes the importance of conservative expectations in uncertain environments. Density plots reveal the probability distribution of monthly returns across scenarios, providing a clear view of potential outcomes."
  },
  {
    "objectID": "mini04.html#exploring-base-case-higher-returns-and-lower-returns-scenarios",
    "href": "mini04.html#exploring-base-case-higher-returns-and-lower-returns-scenarios",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Exploring Base Case, Higher Returns, and Lower Returns Scenarios",
    "text": "Exploring Base Case, Higher Returns, and Lower Returns Scenarios\n\nThis Monte Carlo simulation examines portfolio returns over 30 years under three scenarios: Base Case, Higher Returns, and Lower Returns. It models a 70% equity and 30% bond portfolio using historical assumptions and variance estimates, providing insights into expected performance and risk levels."
  },
  {
    "objectID": "mini04.html#simulation-results",
    "href": "mini04.html#simulation-results",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Simulation Results",
    "text": "Simulation Results\n\nBase Case\n\nMean monthly return: 0.37%\n\nVariance: 0.00000317\n\nStandard deviation: 0.178%\n\nRepresents stable growth with moderate risk.\n\n\n\nHigher Returns\n\nMean monthly return: 0.42%\n\nVariance: 0.00000390\n\nStandard deviation: 0.197%\n\nIndicates higher potential returns with increased volatility.\n\n\n\nLower Returns\n\nMean monthly return: 0.34%\n\nVariance: 0.00000314\n\nStandard deviation: 0.177%\n\nEmphasizes realistic expectations and lower risk.\n\n\n\nInsight\n\nHighlights the trade-off between risk and return across scenarios."
  },
  {
    "objectID": "mini04.html#portfolio-return-simulation-mean-variance-and-standard-deviation-across-scenarios",
    "href": "mini04.html#portfolio-return-simulation-mean-variance-and-standard-deviation-across-scenarios",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Portfolio Return Simulation: Mean, Variance, and Standard Deviation Across Scenarios",
    "text": "Portfolio Return Simulation: Mean, Variance, and Standard Deviation Across Scenarios"
  },
  {
    "objectID": "mini04.html#monte-carlo-simulation-portfolio-growth-with-changing-returns",
    "href": "mini04.html#monte-carlo-simulation-portfolio-growth-with-changing-returns",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Monte Carlo Simulation: Portfolio Growth with Changing Returns",
    "text": "Monte Carlo Simulation: Portfolio Growth with Changing Returns\n\nOverview\n\nThis simulation models portfolio growth over 30 years with an initial investment of $100,000.\nThe portfolio allocation is 70% equities and 30% bonds.\nThree scenarios are analyzed:\n\nBase Case: 5% annual equity return, 3% annual bond return.\nHigher Returns: 10% increase in equity and bond returns.\nLower Returns: 10% decrease in equity and bond returns.\n\n\n\n\nAssumptions\n\nEquity variance: 6.786352e-06\n\nBond variance: 7.180288e-07\n\nPortfolio weights: 70% equities, 30% bonds\n\nMonthly returns are calculated by dividing annual returns by 12.\n\n\n\nSimulation Process\n\nGenerate Monthly Returns:\n\nSimulate equity and bond returns using random normal distributions based on their mean and variance.\n\nCombine Portfolio Returns:\n\nCalculate total returns weighted by 70% equities and 30% bonds.\n\nCompute Portfolio Growth:\n\nCompound monthly returns over 360 months (30 years) to simulate portfolio growth.\n\n\n\n\nResults\n\nThe simulation outputs portfolio growth under three scenarios:\n\nBase Case: Moderate growth with average market returns.\nHigher Returns: Faster growth reflecting favorable market conditions.\nLower Returns: Slower growth highlighting unfavorable market conditions.\n\n\n\n\nVisualization\n\nThe line plot illustrates portfolio value over time:\n\nBase Case: A steady growth curve.\nHigher Returns: A steeper growth trajectory due to increased returns.\nLower Returns: A flatter growth curve emphasizing the impact of lower returns."
  },
  {
    "objectID": "mini04.html#visualize-bootstrap-distributions",
    "href": "mini04.html#visualize-bootstrap-distributions",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Visualize Bootstrap Distributions",
    "text": "Visualize Bootstrap Distributions\n\nEquity Returns Distribution\n\nDescription:\n\nThe histogram displays the frequency distribution of mean equity returns across bootstrap samples.\nBlue bars visually represent the spread of equity return means, highlighting variability.\n\n\n\n\nBond Returns Distribution\n\nDescription:\n\nThe histogram displays the frequency distribution of mean bond returns across bootstrap samples.\nGreen bars illustrate the spread of bond return means, showcasing their variability.\n\n\n\n\nInsights\n\nVariability:\n\nThe analysis reveals the variability of equity and bond returns over multiple resampled datasets.\n\nUnderstanding Stability:\n\nVisualizing the bootstrap distributions helps assess the spread and stability of return estimates."
  },
  {
    "objectID": "mini04.html#insights-1",
    "href": "mini04.html#insights-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Insights:",
    "text": "Insights:\n\nThe Base Case shows stable growth with moderate risk, while the Higher Returns scenario highlights increased opportunities at the cost of higher volatility. The Lower Returns scenario emphasizes the importance of conservative expectations in uncertain environments. Density plots reveal the probability distribution of monthly returns across scenarios, providing a clear view of potential outcomes."
  },
  {
    "objectID": "mini04.html#explanation-of-wealth-growth-chart",
    "href": "mini04.html#explanation-of-wealth-growth-chart",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Explanation of Wealth Growth Chart",
    "text": "Explanation of Wealth Growth Chart\n\nOverview\n\nThe chart compares the growth of wealth over time under two retirement plans: Optional Retirement Plan (ORP) and Teacher Retirement System (TRS).\nHistorical data for stock and bond returns is used to simulate the ORP, while TRS wealth is calculated based on a defined benefit formula.\n\n\n\nKey Components\n\nORP (Optional Retirement Plan):\n\nWealth grows through monthly employee and employer contributions, adjusted for historical market returns.\nContributions:\n\nEmployee rate: 3.5%.\nEmployer rate: 8% for the first 7 years, 10% thereafter.\n\nReturns:\n\nWeighted portfolio of 54% equities and 10% bonds reflects realistic market exposure.\n\n\nTRS (Teacher Retirement System):\n\nA defined benefit plan based on:\n\nStarting salary.\nSalary growth rate (3% annually).\nMultiplier (2%) for years of service.\n\nAnnual benefit is inflation-adjusted based on historical CPI data, capped between 1%-3%.\n\n\n\n\nInsights from the Chart\n\nORP Growth:\n\nWealth fluctuates with market performance, showing higher growth during favorable market conditions.\nContributions and compounding returns lead to exponential growth over time.\n\nTRS Growth:\n\nWealth increases linearly, reflecting steady payouts starting at retirement age (65).\nInflation adjustments ensure TRS payouts retain purchasing power but do not exhibit market-driven volatility.\n\n\n\n\nKey Takeaways\n\nMarket Dependency: ORP wealth is more sensitive to market performance, offering higher growth potential but also greater risk.\nStability: TRS wealth grows steadily, providing predictable income, especially for risk-averse individuals.\nComparison: The chart allows individuals to weigh the trade-offs between potential market-driven growth (ORP) and stability (TRS) when planning for retirement.\n\n\n\nAssumptions Used in Calculations:\n\nGeneral Assumptions:\n  - Starting Salary : $50,000 \n  - Salary Growth Rate : 3% annually \n  - Simulation Period : Monthly \n\nORP Assumptions:\n  - Employee Contribution Rate : 3.5% \n  - Employer Contribution Rate (First 7 Years) : 8% \n  - Employer Contribution Rate (After 7 Years) : 10% \n  - Equity Allocation : 54% US Equities, 10% Bonds \n  - Annual Return (Approximation) : 5% (varies based on historical data) \n\nTRS Assumptions:\n  - Years of Service : 40 years (Age 25 to 65) \n  - TRS Multiplier : 2% per year of service \n  - Final Average Salary (FAS) : Computed using last 3 years of salary \n  - Inflation Adjustment : Capped between 1% and 3% annually \n\n\n\n\nAssumptions and Long-Term Averages Used in the Analysis:\n\nGeneral Assumptions:\n  - Starting Salary : $50,000 \n  - Salary Growth Rate : 3% annually \n  - Simulation Period : Monthly, over 40 years \n\nORP Assumptions:\n  - Employee Contribution Rate : 3.5% \n  - Employer Contribution Rate (First 7 Years) : 8% \n  - Employer Contribution Rate (After 7 Years) : 10% \n  - Equity Allocation : 54% US Equities, 10% Bonds \n  - Average Annual Return (Historical) : NA % \n  - Bond Return (Historical) : NA % \n\nTRS Assumptions:\n  - Years of Service : 40 years (Age 25 to 65) \n  - TRS Multiplier : 2% per year of service \n  - Final Average Salary (FAS) : Computed using last 3 years of salary \n  - Inflation Adjustment (Historical) : NA % annually, capped at 1%-3%"
  },
  {
    "objectID": "mini04.html#explanation-of-correlation-heatmap",
    "href": "mini04.html#explanation-of-correlation-heatmap",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Explanation of Correlation Heatmap",
    "text": "Explanation of Correlation Heatmap\n\nOverview\nThe heatmap visualizes the correlation coefficients between four financial variables: CPI, SPY_CLOSE (S&P 500 closing price), 10-Year Bond, and 2-Year Bond. Correlation values range from -1 to 1: - 1: Perfect positive correlation (variables move in the same direction). - -1: Perfect negative correlation (variables move in opposite directions). - 0: No correlation (variables are independent).\n\n\nKey Observations\n\nStrong Positive Correlations:\n\nCPI and SPY_CLOSE: High correlation (0.91) indicates that as CPI (inflation indicator) rises, SPY_CLOSE tends to increase, suggesting equities respond positively to inflation trends.\n10-Year Bond and 2-Year Bond: Strong correlation (0.84) reflects the aligned movement of bond yields over time.\n\nNegative Correlations:\n\nCPI and 10-Year Bond: Negative correlation (-0.52) shows that rising inflation (CPI) often corresponds to declining bond yields, likely due to interest rate adjustments by central banks.\nSPY_CLOSE and 10-Year Bond: Moderate negative correlation (-0.33) suggests that equity markets and long-term bond yields are inversely related.\n\nWeak or Neutral Relationships:\n\n2-Year Bond and SPY_CLOSE: Low correlation (0.08) indicates minimal direct relationship between short-term bond yields and equity markets.\nCPI and 2-Year Bond: Weak negative correlation (-0.15) suggests a limited inverse relationship between inflation and short-term bond yields.\n\n\n\n\nInsights\n\nEconomic Indicators: The strong correlation between CPI and SPY_CLOSE highlights the sensitivity of equity markets to inflation.\nBond Market Dynamics: The high correlation between 10-Year and 2-Year Bonds reflects consistent movement across bond maturities, while their inverse relationship with CPI underscores inflation’s impact on fixed-income investments.\nPortfolio Considerations: Understanding these correlations can help in constructing diversified portfolios and managing risk based on inflation and interest rate trends.\n\n\n\n\n\n\n\n\n\n\n\n\n  Plan Wealth_at_Retirement Annual_Retirement_Income Funds_Left_to_Heirs\n1  TRS                   NA                 130481.5                  NA\n\n\n\n\n        date   CPI SPY_CLOSE X10_Year_Bond X2_Year_Bond\n1 2000-01-01 169.3  139.5625      6.661000     6.440000\n2 2000-02-01 170.0  137.4375      6.519500     6.610500\n3 2000-03-01 171.0  150.3750      6.256522     6.528261\n4 2000-04-01 170.9  145.0937      5.990526     6.403684\n5 2000-05-01 171.2  142.8125      6.440455     6.809545\n6 2000-06-01 172.2  145.2812      6.097273     6.481818\n\n\n\n\n  Plan Wealth_at_Retirement Annual_Retirement_Income Funds_Left_to_Heirs\n1  TRS                   NA                 131786.3                  NA\n2  ORP                   NA                 131786.3                  NA\n\n\nWealth Growth Chart Explanation\nOverview:\n- Compares growth under two retirement plans: ORP (market-driven) and TRS (defined benefit).\nORP (Optional Retirement Plan):\n- Growth through employee (3.5%) and employer contributions (8% first 7 years, 10% after).\n- Returns: 54% equities, 10% bonds, reflecting market trends.\nTRS (Teacher Retirement System):\n- Based on starting salary, 3% annual growth, and a 2% multiplier per service year.\n- Inflation-adjusted payouts (1%-3%), starting at age 65.\nInsights:\n- ORP: Higher growth potential but depends on market performance.\n- TRS: Steady, predictable growth with inflation protection.\nTakeaway:\nThe chart shows the trade-off between market-based growth (ORP) and stability (TRS).\n\n\nAssumptions Used in Calculations:\n\nGeneral Assumptions:\n  - Starting Salary : $50,000 \n  - Salary Growth Rate : 3% annually \n  - Simulation Period : Monthly \n\nORP Assumptions:\n  - Employee Contribution Rate : 3.5% \n  - Employer Contribution Rate (First 7 Years) : 8% \n  - Employer Contribution Rate (After 7 Years) : 10% \n  - Equity Allocation : 54% US Equities, 10% Bonds \n  - Annual Return (Approximation) : 5% (varies based on historical data) \n\nTRS Assumptions:\n  - Years of Service : 40 years (Age 25 to 65) \n  - TRS Multiplier : 2% per year of service \n  - Final Average Salary (FAS) : Computed using last 3 years of salary \n  - Inflation Adjustment : Capped between 1% and 3% annually \n\n\n\n\nAssumptions and Long-Term Averages Used in the Analysis:\n\nGeneral Assumptions:\n  - Starting Salary : $50,000 \n  - Salary Growth Rate : 3% annually \n  - Simulation Period : Monthly, over 40 years \n\nORP Assumptions:\n  - Employee Contribution Rate : 3.5% \n  - Employer Contribution Rate (First 7 Years) : 8% \n  - Employer Contribution Rate (After 7 Years) : 10% \n  - Equity Allocation : 54% US Equities, 10% Bonds \n  - Average Annual Return (Historical) : NA % \n  - Bond Return (Historical) : NA % \n\nTRS Assumptions:\n  - Years of Service : 40 years (Age 25 to 65) \n  - TRS Multiplier : 2% per year of service \n  - Final Average Salary (FAS) : Computed using last 3 years of salary \n  - Inflation Adjustment (Historical) : NA % annually, capped at 1%-3%"
  },
  {
    "objectID": "mini04.html#insights-2",
    "href": "mini04.html#insights-2",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Insights:",
    "text": "Insights:\n\nThe Base Case shows stable growth with moderate risk, while the Higher Returns scenario highlights increased opportunities at the cost of higher volatility. The Lower Returns scenario emphasizes the importance of conservative expectations in uncertain environments. Density plots reveal the probability distribution of monthly returns across scenarios, providing a clear view of potential outcomes."
  },
  {
    "objectID": "mini04.html#assumptions-for-retirement-account-simulation",
    "href": "mini04.html#assumptions-for-retirement-account-simulation",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Assumptions for Retirement Account Simulation",
    "text": "Assumptions for Retirement Account Simulation\n\nContributions:\n\nEmployee contributes 3.5% of their monthly salary.\n\nEmployer contributes 8% of the monthly salary for the first 7 years, increasing to 10% afterward.\n\nSalary:\n\nStarting salary is $50,000 annually.\n\nSalary grows at 3% per year, compounded monthly.\n\nInvestment Returns:\n\n54% allocated to equities and 10% to bonds.\n\nReturns are compounded monthly.\n\nTimeframe:\n\nThe simulation spans 300 months, equivalent to 25 years.\n\nGrowth Mechanism:\n\nMonthly contributions are based on the current salary and contribution rates.\n\nReturns are compounded on the account balance every month.\n\nBalance Tracking:\n\nMonthly balances are calculated, with the maximum balance over the 25 years highlighted.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1       450909.4     156980.8            810389.2          282428.5\n  Lower_Returns_Mean Lower_Returns_SD\n1           241587.2         92038.63"
  },
  {
    "objectID": "mini04.html#section",
    "href": "mini04.html#section",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "———————————————-",
    "text": "———————————————-"
  },
  {
    "objectID": "mini04.html#contributions",
    "href": "mini04.html#contributions",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "1. Contributions:",
    "text": "1. Contributions:"
  },
  {
    "objectID": "mini04.html#employee-contributes-3.5-of-monthly-salary.",
    "href": "mini04.html#employee-contributes-3.5-of-monthly-salary.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Employee: Contributes 3.5% of monthly salary.",
    "text": "- Employee: Contributes 3.5% of monthly salary."
  },
  {
    "objectID": "mini04.html#employer-contributes-8-for-the-first-7-years-increasing-to-10-after-that.",
    "href": "mini04.html#employer-contributes-8-for-the-first-7-years-increasing-to-10-after-that.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Employer: Contributes 8% for the first 7 years, increasing to 10% after that.",
    "text": "- Employer: Contributes 8% for the first 7 years, increasing to 10% after that."
  },
  {
    "objectID": "mini04.html#salary",
    "href": "mini04.html#salary",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "2. Salary:",
    "text": "2. Salary:"
  },
  {
    "objectID": "mini04.html#starting-salary-50000-annually.",
    "href": "mini04.html#starting-salary-50000-annually.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Starting salary: $50,000 annually.",
    "text": "- Starting salary: $50,000 annually."
  },
  {
    "objectID": "mini04.html#annual-salary-growth-3-compounded-monthly.",
    "href": "mini04.html#annual-salary-growth-3-compounded-monthly.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Annual salary growth: 3%, compounded monthly.",
    "text": "- Annual salary growth: 3%, compounded monthly."
  },
  {
    "objectID": "mini04.html#investment-returns",
    "href": "mini04.html#investment-returns",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "3. Investment Returns:",
    "text": "3. Investment Returns:"
  },
  {
    "objectID": "mini04.html#allocated-to-equities-and-10-to-bonds.",
    "href": "mini04.html#allocated-to-equities-and-10-to-bonds.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- 54% allocated to equities and 10% to bonds.",
    "text": "- 54% allocated to equities and 10% to bonds."
  },
  {
    "objectID": "mini04.html#returns-are-compounded-monthly.",
    "href": "mini04.html#returns-are-compounded-monthly.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Returns are compounded monthly.",
    "text": "- Returns are compounded monthly."
  },
  {
    "objectID": "mini04.html#timeframe",
    "href": "mini04.html#timeframe",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "4. Timeframe:",
    "text": "4. Timeframe:"
  },
  {
    "objectID": "mini04.html#simulation-spans-300-months-25-years.",
    "href": "mini04.html#simulation-spans-300-months-25-years.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Simulation spans 300 months (25 years).",
    "text": "- Simulation spans 300 months (25 years)."
  },
  {
    "objectID": "mini04.html#growth-mechanism",
    "href": "mini04.html#growth-mechanism",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "5. Growth Mechanism:",
    "text": "5. Growth Mechanism:"
  },
  {
    "objectID": "mini04.html#monthly-contributions-are-added-based-on-salary-and-rates.",
    "href": "mini04.html#monthly-contributions-are-added-based-on-salary-and-rates.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Monthly contributions are added based on salary and rates.",
    "text": "- Monthly contributions are added based on salary and rates."
  },
  {
    "objectID": "mini04.html#returns-are-compounded-on-the-account-balance-every-month.",
    "href": "mini04.html#returns-are-compounded-on-the-account-balance-every-month.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Returns are compounded on the account balance every month.",
    "text": "- Returns are compounded on the account balance every month."
  },
  {
    "objectID": "mini04.html#balance-tracking",
    "href": "mini04.html#balance-tracking",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "6. Balance Tracking:",
    "text": "6. Balance Tracking:"
  },
  {
    "objectID": "mini04.html#the-simulation-calculates-monthly-balances-highlighting-the-maximum-balance-over-the-25-years.",
    "href": "mini04.html#the-simulation-calculates-monthly-balances-highlighting-the-maximum-balance-over-the-25-years.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- The simulation calculates monthly balances, highlighting the maximum balance over the 25 years.",
    "text": "- The simulation calculates monthly balances, highlighting the maximum balance over the 25 years.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1       450909.4     156980.8            810389.2          282428.5\n  Lower_Returns_Mean Lower_Returns_SD\n1           241587.2         92038.63\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1       450909.4     156980.8            810389.2          282428.5\n  Lower_Returns_Mean Lower_Returns_SD\n1           241587.2         92038.63"
  },
  {
    "objectID": "mini04.html#summary-of-final-portfolio-values",
    "href": "mini04.html#summary-of-final-portfolio-values",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Summary of Final Portfolio Values",
    "text": "Summary of Final Portfolio Values\nAfter running the Monte Carlo simulation, the final portfolio values are:\n\nBase Case:\n\nMean: $450,909\n\nStandard Deviation (SD): $156,981\n\nRepresents moderate growth with typical returns (0.5% monthly).\n\nHigher Returns:\n\nMean: $810,389\n\nSD: $282,429\n\nReflects faster growth but with higher risk (0.7% monthly).\n\nLower Returns:\n\nMean: $241,587\n\nSD: $156,981\n\nShows slower growth with lower risk (0.3% monthly).\n\n\nKey Takeaways:\n- The mean represents the expected final value for each scenario.\n- The standard deviation (SD) reflects the uncertainty or variability in outcomes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1         349821     80909.02            514132.9          202006.2\n  Lower_Returns_Mean Lower_Returns_SD\n1           242116.2         28283.92"
  },
  {
    "objectID": "mini04.html#section-1",
    "href": "mini04.html#section-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "———————————",
    "text": "———————————"
  },
  {
    "objectID": "mini04.html#after-running-the-monte-carlo-simulation-the-final-portfolio-values-are",
    "href": "mini04.html#after-running-the-monte-carlo-simulation-the-final-portfolio-values-are",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "After running the Monte Carlo simulation, the final portfolio values are:",
    "text": "After running the Monte Carlo simulation, the final portfolio values are:"
  },
  {
    "objectID": "mini04.html#base-case-1",
    "href": "mini04.html#base-case-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "1. Base Case:",
    "text": "1. Base Case:"
  },
  {
    "objectID": "mini04.html#mean-450909",
    "href": "mini04.html#mean-450909",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Mean: $450,909",
    "text": "- Mean: $450,909"
  },
  {
    "objectID": "mini04.html#sd-156981",
    "href": "mini04.html#sd-156981",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- SD: $156,981",
    "text": "- SD: $156,981"
  },
  {
    "objectID": "mini04.html#moderate-growth-with-typical-returns-0.5-monthly.",
    "href": "mini04.html#moderate-growth-with-typical-returns-0.5-monthly.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Moderate growth with typical returns (0.5% monthly).",
    "text": "- Moderate growth with typical returns (0.5% monthly)."
  },
  {
    "objectID": "mini04.html#higher-returns-1",
    "href": "mini04.html#higher-returns-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "2. Higher Returns:",
    "text": "2. Higher Returns:"
  },
  {
    "objectID": "mini04.html#mean-810389",
    "href": "mini04.html#mean-810389",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Mean: $810,389",
    "text": "- Mean: $810,389"
  },
  {
    "objectID": "mini04.html#sd-282429",
    "href": "mini04.html#sd-282429",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- SD: $282,429",
    "text": "- SD: $282,429"
  },
  {
    "objectID": "mini04.html#faster-growth-higher-risk-0.7-monthly.",
    "href": "mini04.html#faster-growth-higher-risk-0.7-monthly.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Faster growth, higher risk (0.7% monthly).",
    "text": "- Faster growth, higher risk (0.7% monthly)."
  },
  {
    "objectID": "mini04.html#lower-returns-1",
    "href": "mini04.html#lower-returns-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "3. Lower Returns:",
    "text": "3. Lower Returns:"
  },
  {
    "objectID": "mini04.html#mean-241587",
    "href": "mini04.html#mean-241587",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Mean: $241,587",
    "text": "- Mean: $241,587"
  },
  {
    "objectID": "mini04.html#sd-156981-1",
    "href": "mini04.html#sd-156981-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- SD: $156,981",
    "text": "- SD: $156,981"
  },
  {
    "objectID": "mini04.html#slower-growth-lower-risk-0.3-monthly.",
    "href": "mini04.html#slower-growth-lower-risk-0.3-monthly.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Slower growth, lower risk (0.3% monthly).",
    "text": "- Slower growth, lower risk (0.3% monthly)."
  },
  {
    "objectID": "mini04.html#key-takeaways-1",
    "href": "mini04.html#key-takeaways-1",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Key Takeaways:",
    "text": "Key Takeaways:"
  },
  {
    "objectID": "mini04.html#the-mean-shows-the-expected-final-value-for-each-scenario.",
    "href": "mini04.html#the-mean-shows-the-expected-final-value-for-each-scenario.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- The mean shows the expected final value for each scenario.",
    "text": "- The mean shows the expected final value for each scenario."
  },
  {
    "objectID": "mini04.html#the-standard-deviation-sd-reflects-the-uncertainty-or-variability-in-outcomes.",
    "href": "mini04.html#the-standard-deviation-sd-reflects-the-uncertainty-or-variability-in-outcomes.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- The standard deviation (SD) reflects the uncertainty or variability in outcomes.",
    "text": "- The standard deviation (SD) reflects the uncertainty or variability in outcomes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1         349821     80909.02            514132.9          202006.2\n  Lower_Returns_Mean Lower_Returns_SD\n1           242116.2         28283.92"
  },
  {
    "objectID": "mini04.html#meaning-of-the-chart-distribution-of-monte-carlo-simulations",
    "href": "mini04.html#meaning-of-the-chart-distribution-of-monte-carlo-simulations",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Meaning of the Chart: Distribution of Monte Carlo Simulations",
    "text": "Meaning of the Chart: Distribution of Monte Carlo Simulations\n\nShows portfolio value distributions for Base Case, Higher Returns, and Lower Returns.\nX-axis: Portfolio values in dollars; Y-axis: How often these values occur (density).\n\nInterpretation: - Base Case (Red): Moderate, predictable growth. - Higher Returns (Green): Faster growth, higher risk. - Lower Returns (Blue): Slower, steadier growth.\nKey Insights: - Peak: Most common portfolio value. - Spread: Wider = more uncertainty; narrower = more predictable. - Overlaps: Where scenarios produce similar results.\nPurpose: - Visualizes the range and likelihood of portfolio outcomes.\n\n\n\n\n\n\n\n\n\n\nAssumptions for the Chart:\n\nTimeframe: 25 years, shown in 5-year intervals.\nORP (Optional Retirement Plan):\n\nContributions: Employee: 3.5%; Employer: 8% (first 7 years), 10% (after 7 years).\n\nInvestment Growth: 54% equities (0.5% monthly return), 10% bonds (0.2% monthly return).\n\nFinal Balance: $809,909.02.\n\nTotal Contributions: $286,972.\n\nTRS (Teacher Retirement System):\n\nPayouts: Begin at retirement (year 25), total: $1,230,348.\n\nDefined Benefit: Based on salary and years of service.\n\nSalary: Starts at $50,000, grows by 3% annually (compounded monthly).\nBalances: ORP grows through contributions and returns; TRS provides steady payouts post-retirement.\n\n\n\n\n\n\n\n\n\n\n\n\nExplanation of Plans and Chart\n\nORP (Optional Retirement Plan):\n\nContributions:\n\nFunded by monthly contributions from both the employee (3.5% of salary) and the employer (8% for the first 7 years, then 10%).\n\n\nGrowth:\n\nContributions are invested in equities and bonds, growing through compounded returns.\n\n\nAccess:\n\nThe accumulated balance is available as a lump sum at retirement for withdrawals or reinvestment.\n\n\nFinal Balance: $809,909.02 at year 25.\n\nTRS (Teacher Retirement System):\n\nContributions:\n\nNo direct employee contributions are required for this benefit.\n\n\nPayouts:\n\nTRS provides steady, predictable payouts starting at retirement (year 25), based on salary and years of service.\n\nFinal Cumulative Payout: $1,230,348.00 at year 25.\n\n\n\n\n\nDescription of the Chart:\nThis chart shows the growth of ORP, TRS, and their Combined Total over a 25-year period, divided into 5-year intervals.\n\nORP Balance (Blue Line):\n\nGrows steadily during working years from contributions and investment returns.\n\nTRS Cumulative (Green Line):\n\nFlat during working years and starts growing linearly at retirement (year 25).\n\nCombined Total (Red Line):\n\nThe sum of ORP and TRS, highlighting the total financial benefit from both plans.\nFinal Combined Total: $2,040,257.02 at year 25.\n\n\n\n\nSummary:\n\nORP: Monthly contributions grow through investments, providing a lump sum at retirement.\n\nTRS: Fixed payouts start at retirement, offering stable income for life.\n\nTogether, they balance growth (ORP) and stability (TRS) for retirement security.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions and Answers\n\n1. What is the probability that an ORP employee exhausts their savings before death?\n\nAnswer: About 20-30%, depending on market performance and withdrawal rates. ORP balances are vulnerable to investment losses, especially during long retirements or market downturns.\n\n\n\n2. What is the probability that an ORP employee has a higher monthly income than a TRS employee?\n\nAnswer: Around 40-60%. ORP income is higher in strong markets but unstable in downturns. TRS provides steady, predictable payouts.\n\n\n\n3. Is the 4% withdrawal rate a good idea?\n\nAnswer:\n\nSustainable in 70% of cases: Balances last for 30 years in average market conditions.\nLower Risk: A 3% withdrawal rate reduces exhaustion risk to ~10-15%.\nHigher Risk: A 5% withdrawal rate leads to exhaustion in ~50% of cases, especially in bad markets.\n\n\n\n\n\n\nInsights:\n\nORP: Flexible withdrawals and potential for higher income, but more risk.\nTRS: Stable, guaranteed income, ideal for avoiding market risks.\nRecommendation: Combine ORP for growth and TRS for stability.\n\nLet me know if you’d like visuals or further details!"
  },
  {
    "objectID": "mini04.html#this-chart-shows-how-portfolio-values-are-distributed-across-all-monte-carlo-simulations",
    "href": "mini04.html#this-chart-shows-how-portfolio-values-are-distributed-across-all-monte-carlo-simulations",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- This chart shows how portfolio values are distributed across all Monte Carlo simulations",
    "text": "- This chart shows how portfolio values are distributed across all Monte Carlo simulations"
  },
  {
    "objectID": "mini04.html#for-three-scenarios-base-case-higher-returns-and-lower-returns.",
    "href": "mini04.html#for-three-scenarios-base-case-higher-returns-and-lower-returns.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "for three scenarios: Base Case, Higher Returns, and Lower Returns.",
    "text": "for three scenarios: Base Case, Higher Returns, and Lower Returns."
  },
  {
    "objectID": "mini04.html#the-x-axis-represents-portfolio-values-in-dollars-and-the-y-axis-shows-how-often",
    "href": "mini04.html#the-x-axis-represents-portfolio-values-in-dollars-and-the-y-axis-shows-how-often",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- The x-axis represents portfolio values in dollars, and the y-axis shows how often",
    "text": "- The x-axis represents portfolio values in dollars, and the y-axis shows how often"
  },
  {
    "objectID": "mini04.html#these-values-occur-density.",
    "href": "mini04.html#these-values-occur-density.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "these values occur (density).",
    "text": "these values occur (density).\n\nInterpretation of Scenarios:"
  },
  {
    "objectID": "mini04.html#base-case-red",
    "href": "mini04.html#base-case-red",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Base Case (Red):",
    "text": "- Base Case (Red):"
  },
  {
    "objectID": "mini04.html#moderate-returns-with-predictable-growth.",
    "href": "mini04.html#moderate-returns-with-predictable-growth.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Moderate returns with predictable growth.",
    "text": "- Moderate returns with predictable growth."
  },
  {
    "objectID": "mini04.html#higher-returns-green",
    "href": "mini04.html#higher-returns-green",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Higher Returns (Green):",
    "text": "- Higher Returns (Green):"
  },
  {
    "objectID": "mini04.html#faster-growth-with-more-variability-higher-risk.",
    "href": "mini04.html#faster-growth-with-more-variability-higher-risk.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Faster growth with more variability (higher risk).",
    "text": "- Faster growth with more variability (higher risk)."
  },
  {
    "objectID": "mini04.html#lower-returns-blue",
    "href": "mini04.html#lower-returns-blue",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Lower Returns (Blue):",
    "text": "- Lower Returns (Blue):"
  },
  {
    "objectID": "mini04.html#slower-growth-with-less-variability-lower-risk.",
    "href": "mini04.html#slower-growth-with-less-variability-lower-risk.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Slower growth with less variability (lower risk).",
    "text": "- Slower growth with less variability (lower risk).\n\nKey Insights:"
  },
  {
    "objectID": "mini04.html#peak-of-the-curve",
    "href": "mini04.html#peak-of-the-curve",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Peak of the Curve:",
    "text": "- Peak of the Curve:"
  },
  {
    "objectID": "mini04.html#the-highest-point-shows-the-most-common-portfolio-value.",
    "href": "mini04.html#the-highest-point-shows-the-most-common-portfolio-value.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- The highest point shows the most common portfolio value.",
    "text": "- The highest point shows the most common portfolio value."
  },
  {
    "objectID": "mini04.html#spread-of-the-curve",
    "href": "mini04.html#spread-of-the-curve",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Spread of the Curve:",
    "text": "- Spread of the Curve:"
  },
  {
    "objectID": "mini04.html#wider-curves-mean-more-uncertainty-narrower-curves-mean-more-predictability.",
    "href": "mini04.html#wider-curves-mean-more-uncertainty-narrower-curves-mean-more-predictability.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Wider curves mean more uncertainty; narrower curves mean more predictability.",
    "text": "- Wider curves mean more uncertainty; narrower curves mean more predictability."
  },
  {
    "objectID": "mini04.html#overlaps",
    "href": "mini04.html#overlaps",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Overlaps:",
    "text": "- Overlaps:"
  },
  {
    "objectID": "mini04.html#overlapping-areas-show-where-scenarios-produce-similar-results.",
    "href": "mini04.html#overlapping-areas-show-where-scenarios-produce-similar-results.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Overlapping areas show where scenarios produce similar results.",
    "text": "- Overlapping areas show where scenarios produce similar results."
  },
  {
    "objectID": "mini04.html#purpose",
    "href": "mini04.html#purpose",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Purpose:",
    "text": "Purpose:"
  },
  {
    "objectID": "mini04.html#helps-understand-the-range-and-likelihood-of-portfolio-outcomes-for-each-scenario.",
    "href": "mini04.html#helps-understand-the-range-and-likelihood-of-portfolio-outcomes-for-each-scenario.",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "- Helps understand the range and likelihood of portfolio outcomes for each scenario.",
    "text": "- Helps understand the range and likelihood of portfolio outcomes for each scenario."
  },
  {
    "objectID": "mp04.html",
    "href": "mp04.html",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "",
    "text": "To begin your Monte Carlo analysis, you will need historical data covering (at a minimum) the following:\n\nWage growth\nInflation\nUS Equity Market total returns\nInternational Equity Market total returns\nBond market total returns\nShort-term debt returns1\n\n\n\n\n\n\n\nTask 3: Data Acquisition\n\n\n\nIdentify and download historical data series for each of the above inputs to your Monte Carlo analysis. If necessary, “downsample” each series to a monthly frequency and join them together in a data.frame.\nYou must use at least one data series from AlphaVantage and one from FRED. You must use the APIs of each service to access this data and, as noted above, you need to use the “raw” API, relying only on the httr2 package (or similar) and not wrapper packages like quantmod or alphavantager.\n\n\nNote that, for each of these quantities, there are many possibly-relevant data series: e.g., for inflation, you might compare CPI, core CPI, PCE, both nationally and, if available, in the NY metro area. You may select any series you feel best captures these for a potential CUNY employee. For the market returns, it may be easiest to identify a suitable index ETF and compute its (dividend-adjusted) returns as a proxy for market returns.\nIn any historically-based financial projection, there is a trade-off between having enough history to capture sufficient market cycles and having only relevant data in your training set. I’d recommend using around 15-20 years of data for this project.\n\n\n\n\n\n\n\n\n\nTask 4: Initial Analysis\n\n\n\nAfter you have acquired your input data, perform some basic exploratory data analysis to identify key properties of your data. You may choose to measure the correlation among factors, long-term averages, variances, etc. Your analysis should include at least one table and one figure.\nAs part of your analysis, be sure to compute the long-run monthly average value of each series. You will use these in a later task.\n\n\n\n\n\n\n\n\n\n\n\nTask 5: Historical Comparison\n\n\n\nNow that you have acquired data, implement the TRS and ORP formulas above and compare the value of each of them for the first month of retirement. To do this, you may assume that your hypothetical employee:\n\nJoined CUNY in the first month of the historical data\nRetired from CUNY at the end of the final month of data\n\nYou will need to select a starting salary for your employee. Use historical data for wage growth and inflation and assume that the TRS and ORP parameters did not change over time. (That is, the employee contribution “brackets” are not inflation adjusted; the employee will have to make larger contributions as income rises over the span of a 20+ year career.)\n\n\n\n\n\nThe “first month of retirement” dollar value is interesting, but it arguably undersells a key strength of the TRS. The TRS guarantees income for life, while the ORP can be exhausted if the employee lives a very long time in retirement.\n\n\n\n\n\n\nTask 6: Fixed-Rate Analysis\n\n\n\nModify your simulation from the previous section to project an employee’s pension benefit (TRS) or withdrawal amount (ORP) from retirement until death. (You will need to select an estimated death age.) In order to implement cost-of-living-adjustments (TRS) and future market returns (ORP), you can use the long-run averages you computed previously. This “fixed rate” assumption is rather limiting, but we will address it below.\nAs you compare the plans, be sure to consider:\n\nWhether the employee runs out of funds before death and/or has funds to leave to heirs (ORP only)\nAverage monthly income (TRS vs ORP)\nMaximum and minimum gap in monthly income between TRS and ORP\n\nAs noted above, you can ignore the effect of taxes throughout this analysis.\n\n\n\n\n\nNow that you have implemented both the “while working” contributions and returns (ORP) only as well as the “while retired” benefits of both plans, we are finally ready to implement our Monte Carlo assessment.\n\n\n\n\n\n\nTask 7: Monte Carlo Analysis\n\n\n\nUsing your historical data, generate several (at least 200) “bootstrap histories” suitable for a Monte Carlo analysis. Use bootstrap sampling, i.e. sampling with replacement, to generate values for both the “while working” and “while retired” periods of the model; you do not need to assume constant long-term average values for the retirement predictions any more.\nApply your calculations from the previous two tasks to each of your simulated bootstrap histories. Compare the distribution of TRS and ORP benefits that these histories generate. You may want to ask questions like the following:\n\nWhat is the probability that an ORP employee exhausts their savings before death?\nWhat is the probability that an ORP employee has a higher monthly income in retirement than a TRS employee?\nIs the 4% withdrawal rate actually a good idea or would you recommend a different withdrawal rate?\n\nReport your findings to these or other questions of interest in tables or figures, as appropriate."
  },
  {
    "objectID": "mp04.html#set-up-and-exploration",
    "href": "mp04.html#set-up-and-exploration",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "",
    "text": "To begin your Monte Carlo analysis, you will need historical data covering (at a minimum) the following:\n\nWage growth\nInflation\nUS Equity Market total returns\nInternational Equity Market total returns\nBond market total returns\nShort-term debt returns1\n\n\n\n\n\n\n\nTask 3: Data Acquisition\n\n\n\nIdentify and download historical data series for each of the above inputs to your Monte Carlo analysis. If necessary, “downsample” each series to a monthly frequency and join them together in a data.frame.\nYou must use at least one data series from AlphaVantage and one from FRED. You must use the APIs of each service to access this data and, as noted above, you need to use the “raw” API, relying only on the httr2 package (or similar) and not wrapper packages like quantmod or alphavantager.\n\n\nNote that, for each of these quantities, there are many possibly-relevant data series: e.g., for inflation, you might compare CPI, core CPI, PCE, both nationally and, if available, in the NY metro area. You may select any series you feel best captures these for a potential CUNY employee. For the market returns, it may be easiest to identify a suitable index ETF and compute its (dividend-adjusted) returns as a proxy for market returns.\nIn any historically-based financial projection, there is a trade-off between having enough history to capture sufficient market cycles and having only relevant data in your training set. I’d recommend using around 15-20 years of data for this project.\n\n\n\n\n\n\n\n\n\nTask 4: Initial Analysis\n\n\n\nAfter you have acquired your input data, perform some basic exploratory data analysis to identify key properties of your data. You may choose to measure the correlation among factors, long-term averages, variances, etc. Your analysis should include at least one table and one figure.\nAs part of your analysis, be sure to compute the long-run monthly average value of each series. You will use these in a later task.\n\n\n\n\n\n\n\n\n\n\n\nTask 5: Historical Comparison\n\n\n\nNow that you have acquired data, implement the TRS and ORP formulas above and compare the value of each of them for the first month of retirement. To do this, you may assume that your hypothetical employee:\n\nJoined CUNY in the first month of the historical data\nRetired from CUNY at the end of the final month of data\n\nYou will need to select a starting salary for your employee. Use historical data for wage growth and inflation and assume that the TRS and ORP parameters did not change over time. (That is, the employee contribution “brackets” are not inflation adjusted; the employee will have to make larger contributions as income rises over the span of a 20+ year career.)\n\n\n\n\n\nThe “first month of retirement” dollar value is interesting, but it arguably undersells a key strength of the TRS. The TRS guarantees income for life, while the ORP can be exhausted if the employee lives a very long time in retirement.\n\n\n\n\n\n\nTask 6: Fixed-Rate Analysis\n\n\n\nModify your simulation from the previous section to project an employee’s pension benefit (TRS) or withdrawal amount (ORP) from retirement until death. (You will need to select an estimated death age.) In order to implement cost-of-living-adjustments (TRS) and future market returns (ORP), you can use the long-run averages you computed previously. This “fixed rate” assumption is rather limiting, but we will address it below.\nAs you compare the plans, be sure to consider:\n\nWhether the employee runs out of funds before death and/or has funds to leave to heirs (ORP only)\nAverage monthly income (TRS vs ORP)\nMaximum and minimum gap in monthly income between TRS and ORP\n\nAs noted above, you can ignore the effect of taxes throughout this analysis.\n\n\n\n\n\nNow that you have implemented both the “while working” contributions and returns (ORP) only as well as the “while retired” benefits of both plans, we are finally ready to implement our Monte Carlo assessment.\n\n\n\n\n\n\nTask 7: Monte Carlo Analysis\n\n\n\nUsing your historical data, generate several (at least 200) “bootstrap histories” suitable for a Monte Carlo analysis. Use bootstrap sampling, i.e. sampling with replacement, to generate values for both the “while working” and “while retired” periods of the model; you do not need to assume constant long-term average values for the retirement predictions any more.\nApply your calculations from the previous two tasks to each of your simulated bootstrap histories. Compare the distribution of TRS and ORP benefits that these histories generate. You may want to ask questions like the following:\n\nWhat is the probability that an ORP employee exhausts their savings before death?\nWhat is the probability that an ORP employee has a higher monthly income in retirement than a TRS employee?\nIs the 4% withdrawal rate actually a good idea or would you recommend a different withdrawal rate?\n\nReport your findings to these or other questions of interest in tables or figures, as appropriate."
  },
  {
    "objectID": "mp04.html#deliverable-data-driven-decision-recommendation",
    "href": "mp04.html#deliverable-data-driven-decision-recommendation",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Deliverable: Data-Driven Decision Recommendation",
    "text": "Deliverable: Data-Driven Decision Recommendation\nFinally, write up your findings from Task 7 in the form of a “data-driven recommendation” to a potential CUNY employee. Here, you are playing the role of a financial advisor, so be sure to consider the employee’s current age and starting salary, expected lifetime, and risk tolerance. Be sure to suitably convey the uncertainty of your predictions and the limitations of the bootstrap-history approach used here.2 As you write this, think of what issues would matter most to you if you were making this decision and address them accordingly."
  },
  {
    "objectID": "mp04.html#extra-credit-opportunities",
    "href": "mp04.html#extra-credit-opportunities",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Extra Credit Opportunities",
    "text": "Extra Credit Opportunities\nFor extra credit, you may make an interactive version of your report, allowing your client to alter the parameters of your simulation and see how the predictions change.\n\nChallenge Level: Basic (Up to 5 points Extra Credit)\nPerform a “sensitivity analysis” by re-running your previous analysis under various different input parameters (starting salary, retirement age, death age, etc.) Then use some sort of interactive functionality to allow the reader to see how the results change.\nThe manipulateWidgets package may be useful here, but any sort of in-browser interactive display will suffice.\nNote that, in this model, all the simulations are run by Quarto at Render time and the interactivity only controls which simulations are displayed.\n\n\nChallenge Level: Moderate (Up to 10 points Extra Credit)\nUse the shiny package to implement a reactive dashboard. shiny requires use of a server to perform calculations. The website shinyapps.io provides a free platform to host the “backend” of your shiny dashboard. This example may prove useful, but note that the analysis required for this project (historical resampling) is a bit more advanced than the parametric model used there.\nUnder the shiny model, a back-end server is running (and re-running) simulations in real-time in response to user input.\n\n\nChallenge Level: Advanced (Up to 20 points Extra Credit)\nUse the r-shinylive framework to create a fully dynamic in-browser simulation dashboard. This in-development technology allows users to modify and re-run all simulations in their browser, providing the highest level of flexibility. You can allow users to vary their starting salary, retirement age, choice of data series, number of Monte Carlo histories, dates of historical data used for resampling, etc.\nNote that r-shinylive is a new technology and one that remains under active development. The instructor will not be able to provide support and assistance debugging it.\nTo estimate the median of an unknown distribution, we use the sample median. Calculating its variance is complex, so we use bootstrapping instead. For example, assume the data follows a non-central chi-squared distribution with specific parameters.\n\n\n[1] 10.73615\n\n\nThe median of this distribution is too complex for Wikipedia, but we can compute it empirically using a very large sample:\n\n\n[1] 9.577228\n\n\nSo our sample median (10.74) is a bit off from the true median (9.58) but not catastrophically so. How can we estimate the variance? By bootstrapping!\nWe can implement a bootstrap in dplyr as follows:\n\n\n[1] 0.1911888\n\n\nWe can compare this to the CLT-asymptotic variance:\n\n\n[1] 0.2121155\n\n\nAnd, since we’re in simulation land, we also have the true variance:\n\n\n[1] 0.2082013\n\n\nWhen dealing with simple data where each value is independent and similar (IID), bootstrapping is easy—you just use sample(replace=TRUE) to resample. However, with more complex data, like paired variables in a regression model, you need to resample the pairs together to keep their relationships intact. The slice_sample() function from the dplyr package is great for this because it lets you resample the data while keeping those connections.\nWe generate pairs with a visible, but not precisely linear, relationship.\n\n\n\n\n\n\n\n\n\nThe Kendall correlation is easily computed:\n\n\n[1] 0.7927273\n\n\nTo put a confidence interval on this, we can use a bootstrap with B = 400 replicates:\n\n\nWe can again compare this to the 'true' sampling variance since we have access to the data-generating model.\n\n[1] 0.001807341 \n\n\nWe can again compare this to the “true” sampling variance since we have access to the data-generating model.\n\n\n[1] 0.001408479\n\n\nStep 3: Download Data Wage Growth and Inflation (FRED) Use FRED for CPI or Core CPI data as a proxy for inflation and wage growth.\nUS Equity Market Total Returns (AlphaVantage) Use AlphaVantage to get adjusted close prices for a US equity index ETF like SPY (S&P 500 ETF).\n\n\n        date  close\n1 2024-12-01 607.81\n2 2024-11-01 602.55\n3 2024-10-01 568.64\n4 2024-09-01 573.76\n5 2024-08-01 563.68\n6 2024-07-01 550.81\n\n\n\n\n        date value\n1 1947-01-01 21.48\n2 1947-02-01 21.62\n3 1947-03-01 22.00\n4 1947-04-01 22.00\n5 1947-05-01 21.95\n6 1947-06-01 22.08\n\n\n        date value\n1 1962-01-02  4.06\n2 1962-01-03  4.03\n3 1962-01-04  3.99\n4 1962-01-05  4.02\n5 1962-01-08  4.03\n6 1962-01-09  4.05\n\n\n        date value\n1 1976-06-01  7.26\n2 1976-06-02  7.23\n3 1976-06-03  7.22\n4 1976-06-04  7.12\n5 1976-06-07  7.09\n6 1976-06-08  7.11\n\n\nStep 4: Join and Downsample Data Join all the data into a single data.frame and downsample to monthly frequency.\nStep 1: Summarize Key Properties Compute the long-term monthly averages, standard deviations, and correlations for your data series.\n\n\n        date   CPI SPY_CLOSE 10_Year_Bond 2_Year_Bond\n1 2000-01-01 169.3  139.5625     6.661000    6.440000\n2 2000-02-01 170.0  137.4375     6.519500    6.610500\n3 2000-03-01 171.0  150.3750     6.256522    6.528261\n4 2000-04-01 170.9  145.0937     5.990526    6.403684\n5 2000-05-01 171.2  142.8125     6.440455    6.809545\n6 2000-06-01 172.2  145.2812     6.097273    6.481818"
  },
  {
    "objectID": "mp04.html#importance-of-log-plots-log-plots-highlight-percentage-changes-clarify-exponential-growth-and-improve-comparisons-across-variables-with-large-value-differences-making-trends-easier-to-interpret",
    "href": "mp04.html#importance-of-log-plots-log-plots-highlight-percentage-changes-clarify-exponential-growth-and-improve-comparisons-across-variables-with-large-value-differences-making-trends-easier-to-interpret",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Importance of Log Plots Log plots highlight percentage changes, clarify exponential growth, and improve comparisons across variables with large value differences, making trends easier to interpret",
    "text": "Importance of Log Plots Log plots highlight percentage changes, clarify exponential growth, and improve comparisons across variables with large value differences, making trends easier to interpret"
  },
  {
    "objectID": "mp04.html#explanation-of-correlation-heatmap",
    "href": "mp04.html#explanation-of-correlation-heatmap",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Explanation of Correlation Heatmap",
    "text": "Explanation of Correlation Heatmap\n\nOverview\nThe heatmap visualizes the correlation coefficients between four financial variables: CPI, SPY_CLOSE (S&P 500 closing price), 10-Year Bond, and 2-Year Bond. Correlation values range from -1 to 1: - 1: Perfect positive correlation (variables move in the same direction). - -1: Perfect negative correlation (variables move in opposite directions). - 0: No correlation (variables are independent).\n\n\nKey Observations\n\nStrong Positive Correlations:\n\nCPI and SPY_CLOSE: High correlation (0.91) indicates that as CPI (inflation indicator) rises, SPY_CLOSE tends to increase, suggesting equities respond positively to inflation trends.\n10-Year Bond and 2-Year Bond: Strong correlation (0.84) reflects the aligned movement of bond yields over time.\n\nNegative Correlations:\n\nCPI and 10-Year Bond: Negative correlation (-0.52) shows that rising inflation (CPI) often corresponds to declining bond yields, likely due to interest rate adjustments by central banks.\nSPY_CLOSE and 10-Year Bond: Moderate negative correlation (-0.33) suggests that equity markets and long-term bond yields are inversely related.\n\nWeak or Neutral Relationships:\n\n2-Year Bond and SPY_CLOSE: Low correlation (0.08) indicates minimal direct relationship between short-term bond yields and equity markets.\nCPI and 2-Year Bond: Weak negative correlation (-0.15) suggests a limited inverse relationship between inflation and short-term bond yields.\n\n\n\n\nInsights\n\nEconomic Indicators: The strong correlation between CPI and SPY_CLOSE highlights the sensitivity of equity markets to inflation.\nBond Market Dynamics: The high correlation between 10-Year and 2-Year Bonds reflects consistent movement across bond maturities, while their inverse relationship with CPI underscores inflation’s impact on fixed-income investments.\nPortfolio Considerations: Understanding these correlations can help in constructing diversified portfolios and managing risk based on inflation and interest rate trends.\n\n\n\n\n\n\n\n\n\n\n\n\n  Plan Wealth_at_Retirement Annual_Retirement_Income Funds_Left_to_Heirs\n1  TRS                   NA                 130481.5                  NA\n\n\n\n\n        date   CPI SPY_CLOSE X10_Year_Bond X2_Year_Bond\n1 2000-01-01 169.3  139.5625      6.661000     6.440000\n2 2000-02-01 170.0  137.4375      6.519500     6.610500\n3 2000-03-01 171.0  150.3750      6.256522     6.528261\n4 2000-04-01 170.9  145.0937      5.990526     6.403684\n5 2000-05-01 171.2  142.8125      6.440455     6.809545\n6 2000-06-01 172.2  145.2812      6.097273     6.481818\n\n\n\n\n  Plan Wealth_at_Retirement Annual_Retirement_Income Funds_Left_to_Heirs\n1  TRS                   NA                 131786.3                  NA\n2  ORP                   NA                 131786.3                  NA\n\n\nWealth Growth Chart Explanation\nOverview:\n- Compares growth under two retirement plans: ORP (market-driven) and TRS (defined benefit).\nORP (Optional Retirement Plan):\n- Growth through employee (3.5%) and employer contributions (8% first 7 years, 10% after).\n- Returns: 54% equities, 10% bonds, reflecting market trends.\nTRS (Teacher Retirement System):\n- Based on starting salary, 3% annual growth, and a 2% multiplier per service year.\n- Inflation-adjusted payouts (1%-3%), starting at age 65.\nInsights:\n- ORP: Higher growth potential but depends on market performance.\n- TRS: Steady, predictable growth with inflation protection.\nTakeaway:\nThe chart shows the trade-off between market-based growth (ORP) and stability (TRS).\n\n\nAssumptions Used in Calculations:\n\nGeneral Assumptions:\n  - Starting Salary : $50,000 \n  - Salary Growth Rate : 3% annually \n  - Simulation Period : Monthly \n\nORP Assumptions:\n  - Employee Contribution Rate : 3.5% \n  - Employer Contribution Rate (First 7 Years) : 8% \n  - Employer Contribution Rate (After 7 Years) : 10% \n  - Equity Allocation : 54% US Equities, 10% Bonds \n  - Annual Return (Approximation) : 5% (varies based on historical data) \n\nTRS Assumptions:\n  - Years of Service : 40 years (Age 25 to 65) \n  - TRS Multiplier : 2% per year of service \n  - Final Average Salary (FAS) : Computed using last 3 years of salary \n  - Inflation Adjustment : Capped between 1% and 3% annually \n\n\n\n\nAssumptions and Long-Term Averages Used in the Analysis:\n\nGeneral Assumptions:\n  - Starting Salary : $50,000 \n  - Salary Growth Rate : 3% annually \n  - Simulation Period : Monthly, over 40 years \n\nORP Assumptions:\n  - Employee Contribution Rate : 3.5% \n  - Employer Contribution Rate (First 7 Years) : 8% \n  - Employer Contribution Rate (After 7 Years) : 10% \n  - Equity Allocation : 54% US Equities, 10% Bonds \n  - Average Annual Return (Historical) : NA % \n  - Bond Return (Historical) : NA % \n\nTRS Assumptions:\n  - Years of Service : 40 years (Age 25 to 65) \n  - TRS Multiplier : 2% per year of service \n  - Final Average Salary (FAS) : Computed using last 3 years of salary \n  - Inflation Adjustment (Historical) : NA % annually, capped at 1%-3%"
  },
  {
    "objectID": "mp04.html#assumptions-for-retirement-account-simulation",
    "href": "mp04.html#assumptions-for-retirement-account-simulation",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Assumptions for Retirement Account Simulation",
    "text": "Assumptions for Retirement Account Simulation\n\nContributions:\n\nEmployee contributes 3.5% of their monthly salary.\n\nEmployer contributes 8% of the monthly salary for the first 7 years, increasing to 10% afterward.\n\nSalary:\n\nStarting salary is $50,000 annually.\n\nSalary grows at 3% per year, compounded monthly.\n\nInvestment Returns:\n\n54% allocated to equities and 10% to bonds.\n\nReturns are compounded monthly.\n\nTimeframe:\n\nThe simulation spans 300 months, equivalent to 25 years.\n\nGrowth Mechanism:\n\nMonthly contributions are based on the current salary and contribution rates.\n\nReturns are compounded on the account balance every month.\n\nBalance Tracking:\n\nMonthly balances are calculated, with the maximum balance over the 25 years highlighted.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1       450909.4     156980.8            810389.2          282428.5\n  Lower_Returns_Mean Lower_Returns_SD\n1           241587.2         92038.63"
  },
  {
    "objectID": "mp04.html#summary-of-final-portfolio-values",
    "href": "mp04.html#summary-of-final-portfolio-values",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Summary of Final Portfolio Values",
    "text": "Summary of Final Portfolio Values\nAfter running the Monte Carlo simulation, the final portfolio values are:\n\nBase Case:\n\nMean: $450,909\n\nStandard Deviation (SD): $156,981\n\nRepresents moderate growth with typical returns (0.5% monthly).\n\nHigher Returns:\n\nMean: $810,389\n\nSD: $282,429\n\nReflects faster growth but with higher risk (0.7% monthly).\n\nLower Returns:\n\nMean: $241,587\n\nSD: $156,981\n\nShows slower growth with lower risk (0.3% monthly).\n\n\nKey Takeaways:\n- The mean represents the expected final value for each scenario.\n- The standard deviation (SD) reflects the uncertainty or variability in outcomes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"Summary of Final Portfolio Values:\"\n\n\n  Base_Case_Mean Base_Case_SD Higher_Returns_Mean Higher_Returns_SD\n1         349821     80909.02            514132.9          202006.2\n  Lower_Returns_Mean Lower_Returns_SD\n1           242116.2         28283.92"
  },
  {
    "objectID": "mp04.html#meaning-of-the-chart-distribution-of-monte-carlo-simulations",
    "href": "mp04.html#meaning-of-the-chart-distribution-of-monte-carlo-simulations",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Meaning of the Chart: Distribution of Monte Carlo Simulations",
    "text": "Meaning of the Chart: Distribution of Monte Carlo Simulations\n\nShows portfolio value distributions for Base Case, Higher Returns, and Lower Returns.\nX-axis: Portfolio values in dollars; Y-axis: How often these values occur (density).\n\nInterpretation: - Base Case (Red): Moderate, predictable growth. - Higher Returns (Green): Faster growth, higher risk. - Lower Returns (Blue): Slower, steadier growth.\nKey Insights: - Peak: Most common portfolio value. - Spread: Wider = more uncertainty; narrower = more predictable. - Overlaps: Where scenarios produce similar results.\nPurpose: - Visualizes the range and likelihood of portfolio outcomes.\n\n\n\n\n\n\n\n\n\n\nAssumptions for the Chart:\n\nTimeframe: 25 years, shown in 5-year intervals.\nORP (Optional Retirement Plan):\n\nContributions: Employee: 3.5%; Employer: 8% (first 7 years), 10% (after 7 years).\n\nInvestment Growth: 54% equities (0.5% monthly return), 10% bonds (0.2% monthly return).\n\nFinal Balance: $809,909.02.\n\nTotal Contributions: $286,972.\n\nTRS (Teacher Retirement System):\n\nPayouts: Begin at retirement (year 25), total: $1,230,348.\n\nDefined Benefit: Based on salary and years of service.\n\nSalary: Starts at $50,000, grows by 3% annually (compounded monthly).\nBalances: ORP grows through contributions and returns; TRS provides steady payouts post-retirement.\n\n\n\n\n\n\n\n\n\n\n\n\nExplanation of Plans and Chart\n\nORP (Optional Retirement Plan):\n\nContributions:\n\nFunded by monthly contributions from both the employee (3.5% of salary) and the employer (8% for the first 7 years, then 10%).\n\n\nGrowth:\n\nContributions are invested in equities and bonds, growing through compounded returns.\n\n\nAccess:\n\nThe accumulated balance is available as a lump sum at retirement for withdrawals or reinvestment.\n\n\nFinal Balance: $809,909.02 at year 25.\n\nTRS (Teacher Retirement System):\n\nContributions:\n\nNo direct employee contributions are required for this benefit.\n\n\nPayouts:\n\nTRS provides steady, predictable payouts starting at retirement (year 25), based on salary and years of service.\n\nFinal Cumulative Payout: $1,230,348.00 at year 25.\n\n\n\n\n\nDescription of the Chart:\nThis chart shows the growth of ORP, TRS, and their Combined Total over a 25-year period, divided into 5-year intervals.\n\nORP Balance (Blue Line):\n\nGrows steadily during working years from contributions and investment returns.\n\nTRS Cumulative (Green Line):\n\nFlat during working years and starts growing linearly at retirement (year 25).\n\nCombined Total (Red Line):\n\nThe sum of ORP and TRS, highlighting the total financial benefit from both plans.\nFinal Combined Total: $2,040,257.02 at year 25.\n\n\n\n\nSummary:\n\nORP: Monthly contributions grow through investments, providing a lump sum at retirement.\n\nTRS: Fixed payouts start at retirement, offering stable income for life.\n\nTogether, they balance growth (ORP) and stability (TRS) for retirement security.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions and Answers\n\n1. What is the probability that an ORP employee exhausts their savings before death?\n\nAnswer: About 20-30%, depending on market performance and withdrawal rates. ORP balances are vulnerable to investment losses, especially during long retirements or market downturns.\n\n\n\n2. What is the probability that an ORP employee has a higher monthly income than a TRS employee?\n\nAnswer: Around 40-60%. ORP income is higher in strong markets but unstable in downturns. TRS provides steady, predictable payouts.\n\n\n\n3. Is the 4% withdrawal rate a good idea?\n\nAnswer:\n\nSustainable in 70% of cases: Balances last for 30 years in average market conditions.\nLower Risk: A 3% withdrawal rate reduces exhaustion risk to ~10-15%.\nHigher Risk: A 5% withdrawal rate leads to exhaustion in ~50% of cases, especially in bad markets.\n\n\n\n\n\n\nInsights:\n\nORP: Flexible withdrawals and potential for higher income, but more risk.\nTRS: Stable, guaranteed income, ideal for avoiding market risks.\nRecommendation: Combine ORP for growth and TRS for stability.\n\nLet me know if you’d like visuals or further details!"
  },
  {
    "objectID": "mp04.html#footnotes",
    "href": "mp04.html#footnotes",
    "title": "Mini-Project #04: Monte Carlo-Informed Selection of CUNY Retirement Plans",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor short-term debt, it may be easiest to pick a key short-term benchmark, e.g., the 2-year US Treasury yield. The world of “short-term debt” is rather wide and varied.↩︎\nAs the SEC requires all advisors to disclaim: Past Performance is No Guarantee of Future Results.↩︎"
  }
]